Project Name,Package Name,Type Name,Method Name,Implementation Smell,Cause of the Smell,Method start line no
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitingDisabledNoWaitTimeGiven,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 124.,40
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitingDisabledNoWaitTimeGiven,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,40
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitingDisabledNoWaitTimeGiven,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 124.,40
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitingDisabledNoWaitTimeGiven,Magic Number,The method contains a magic number: 3600000,40
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitingDisabledNoWaitTimeGiven,Magic Number,The method contains a magic number: 10L,40
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,waitTimesReturnedForMultipleClusters,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount1`rateLimiterForBytes1`rateLimiterForCount2`rateLimiterForBytes2`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 222.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,waitTimesReturnedForMultipleClusters,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,waitTimesReturnedForMultipleClusters,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount1`rateLimiterForBytes1`rateLimiterForCount2`rateLimiterForBytes2`countLimiterGlobal`bytesLimiterGlobal);" is 168.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,waitTimesReturnedForMultipleClusters,Magic Number,The method contains a magic number: 3600000,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,waitTimesReturnedForMultipleClusters,Magic Number,The method contains a magic number: 10L,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,waitTimesReturnedForMultipleClusters,Magic Number,The method contains a magic number: 10L,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Long Statement,The length of the statement "RateLimitExceededException e=assertThrows(RateLimitExceededException.class`() -> produceRateLimiters.rateLimit("clusterId"`10L));" is 129.,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 124.,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Magic Number,The method contains a magic number: 3600000,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Magic Number,The method contains a magic number: 10L,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnCountExceptionThrown,Magic Number,The method contains a magic number: 10L,159
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Long Statement,The length of the statement "RateLimitExceededException e=assertThrows(RateLimitExceededException.class`() -> produceRateLimiters.rateLimit("clusterId"`10L));" is 129.,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 124.,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Magic Number,The method contains a magic number: 3600000,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Magic Number,The method contains a magic number: 10L,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,rateLimitedOnBytesExceptionThrown,Magic Number,The method contains a magic number: 10L,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 124.,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Magic Number,The method contains a magic number: 20,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Magic Number,The method contains a magic number: 10L,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Magic Number,The method contains a magic number: 50,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,cacheExpiresforeRateLimit,Magic Number,The method contains a magic number: 10L,302
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalCountLimitHit,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount1`rateLimiterForBytes1`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 180.,372
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalCountLimitHit,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,372
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalCountLimitHit,Long Statement,The length of the statement "RateLimitExceededException e=assertThrows(RateLimitExceededException.class`() -> produceRateLimiters.rateLimit("clusterId1"`10L));" is 130.,372
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalCountLimitHit,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount1`rateLimiterForBytes1`countLimiterGlobal`bytesLimiterGlobal);" is 126.,372
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalCountLimitHit,Magic Number,The method contains a magic number: 3600000,372
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalCountLimitHit,Magic Number,The method contains a magic number: 10L,372
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalBytesLimitHit,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount1`rateLimiterForBytes1`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 180.,429
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalBytesLimitHit,Long Statement,The length of the statement "ProduceRateLimiters produceRateLimiters=new ProduceRateLimiters(countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))));" is 326.,429
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalBytesLimitHit,Long Statement,The length of the statement "RateLimitExceededException e=assertThrows(RateLimitExceededException.class`() -> produceRateLimiters.rateLimit("clusterId1"`10L));" is 130.,429
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalBytesLimitHit,Long Statement,The length of the statement "verify(countLimitProvider`bytesLimitProvider`rateLimiterForCount1`rateLimiterForBytes1`countLimiterGlobal`bytesLimiterGlobal);" is 126.,429
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalBytesLimitHit,Magic Number,The method contains a magic number: 3600000,429
confluentinc_kafka-rest,io.confluent.kafkarest.resources,ProduceRateLimitersTest,globalBytesLimitHit,Magic Number,The method contains a magic number: 10L,429
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceBinary,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithoutSchema(EmbeddedFormat.BINARY`topicName`Optional.empty()`request);" is 123.,63
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceBinary,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,63
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceJson,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithoutSchema(EmbeddedFormat.JSON`topicName`Optional.empty()`request);" is 121.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceJson,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceAvro,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,101
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceJsonSchema,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithSchema(EmbeddedFormat.JSONSCHEMA`topicName`Optional.empty()`request);" is 124.,120
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceJsonSchema,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,120
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceProtobuf,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithSchema(EmbeddedFormat.PROTOBUF`topicName`Optional.empty()`request);" is 122.,139
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToTopicAction,produceProtobuf,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,139
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResource,list,Long Statement,The length of the statement "CompletableFuture<List<String>> response=topicManager.listLocalTopics().thenApply(topics -> topics.stream().map(Topic::getName).collect(Collectors.toList()));" is 158.,59
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResource,getTopic,Long Statement,The length of the statement "CompletableFuture<Topic> topicFuture=topicManager.getLocalTopic(topicName).thenApply(topic -> topic.orElseThrow(Errors::topicNotFoundException));" is 145.,73
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResource,getTopic,Long Statement,The length of the statement "CompletableFuture<GetTopicResponse> response=topicFuture.thenCompose(topic -> topicConfigManager.listTopicConfigs(topic.getClusterId()`topicName)).thenCombine(topicFuture`(configs`topic) -> GetTopicResponse.fromTopic(topic`configs));" is 233.,73
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,BrokersResource,list,Long Statement,The length of the statement "CompletableFuture<BrokerList> response=brokerManager.get().listLocalBrokers().thenApply(brokers -> new BrokerList(brokers.stream().map(Broker::getBrokerId).collect(Collectors.toList())));" is 187.,52
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceBinary,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithoutSchema(EmbeddedFormat.BINARY`topicName`Optional.of(partitionId)`request);" is 131.,63
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceBinary,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,63
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceJson,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithoutSchema(EmbeddedFormat.JSON`topicName`Optional.of(partitionId)`request);" is 129.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceJson,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceAvro,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithSchema(EmbeddedFormat.AVRO`topicName`Optional.of(partitionId)`request);" is 126.,101
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceAvro,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,101
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceJsonSchema,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithSchema(EmbeddedFormat.JSONSCHEMA`topicName`Optional.of(partitionId)`request);" is 132.,120
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceJsonSchema,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,120
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceProtobuf,Long Statement,The length of the statement "CompletableFuture<ProduceResponse> response=produceWithSchema(EmbeddedFormat.PROTOBUF`topicName`Optional.of(partitionId)`request);" is 130.,139
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ProduceToPartitionAction,produceProtobuf,Long Statement,The length of the statement "AsyncResponseBuilder.<ProduceResponse>from(Response.ok()).entity(response).status(ProduceResponse::getRequestStatus).asyncResume(asyncResponse);" is 144.,139
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,produceWithoutSchema,Long Statement,The length of the statement "List<SerializedKeyAndValue> serialized=serialize(format`topicName`partition`Optional.empty()`Optional.empty()`request.getRecords());" is 132.,67
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,produceWithSchema,Long Statement,The length of the statement "Optional<RegisteredSchema> valueSchema=getSchema(format`topicName`request.getValueSchemaId()`request.getValueSchema()`false);" is 125.,87
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,getSchema,Complex Conditional,The conditional expression format.requiresSchema() && (schemaId.isPresent() || schema.isPresent()) is complex.,111
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,getSchema,Long Parameter List,The method has 5 parameters. ,111
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,getSchema,Long Statement,The length of the statement "return Optional.of(schemaManager.get().getSchema(topicName`schema.map(unused -> format)`Optional.empty()`Optional.empty()`schemaId`Optional.empty()`schema`isKey));" is 163.,111
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,serialize,Long Parameter List,The method has 6 parameters. ,135
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,serialize,Long Statement,The length of the statement "return records.stream().map(record -> SerializedKeyAndValue.create(record.getPartition().map(Optional::of).orElse(partition)`recordSerializer.get().serialize(format`topicName`keySchema`record.getKey().orElse(NullNode.getInstance())`true)`recordSerializer.get().serialize(format`topicName`valueSchema`record.getValue().orElse(NullNode.getInstance())`false))).collect(Collectors.toList());" is 387.,135
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,doProduce,Long Statement,The length of the statement "return serialized.stream().map(record -> produceController.get().produce(""`topicName`record.getPartitionId()`ImmutableMultimap.of()`record.getKey()`record.getValue()`Instant.now())).collect(Collectors.toList());" is 212.,166
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,produceResultsToResponse,Long Statement,The length of the statement "CompletableFuture<List<PartitionOffset>> offsetsFuture=CompletableFutures.allAsList(resultFutures.stream().map(future -> future.thenApply(result -> new PartitionOffset(result.getPartitionId()`result.getOffset()`null`null))).map(future -> future.exceptionally(throwable -> new PartitionOffset(null`null`errorCodeFromProducerException(throwable.getCause())`throwable.getCause().getMessage()))).collect(Collectors.toList()));" is 422.,184
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,AbstractProduceAction,produceResultsToResponse,Long Statement,The length of the statement "return offsetsFuture.thenApply(offsets -> new ProduceResponse(offsets`keySchema.map(RegisteredSchema::getSchemaId).orElse(null)`valueSchema.map(RegisteredSchema::getSchemaId).orElse(null)));" is 190.,184
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordBinary,Long Parameter List,The method has 5 parameters. ,167
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordBinary,Long Statement,The length of the statement "readRecords(asyncResponse`group`instance`Duration.ofMillis(timeoutMs)`maxBytes`BinaryKafkaConsumerState.class`BinaryConsumerRecord::fromConsumerRecord);" is 152.,167
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordJson,Long Parameter List,The method has 5 parameters. ,188
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordJson,Long Statement,The length of the statement "readRecords(asyncResponse`group`instance`Duration.ofMillis(timeoutMs)`maxBytes`JsonKafkaConsumerState.class`JsonConsumerRecord::fromConsumerRecord);" is 148.,188
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordAvro,Long Parameter List,The method has 5 parameters. ,209
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordAvro,Long Statement,The length of the statement "readRecords(asyncResponse`group`instance`Duration.ofMillis(timeoutMs)`maxBytes`SchemaKafkaConsumerState.class`SchemaConsumerRecord::fromConsumerRecord);" is 152.,209
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordJsonSchema,Long Parameter List,The method has 5 parameters. ,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordJsonSchema,Long Statement,The length of the statement "readRecords(asyncResponse`group`instance`Duration.ofMillis(timeoutMs)`maxBytes`SchemaKafkaConsumerState.class`SchemaConsumerRecord::fromConsumerRecord);" is 152.,230
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordProtobuf,Long Parameter List,The method has 5 parameters. ,251
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecordProtobuf,Long Statement,The length of the statement "readRecords(asyncResponse`group`instance`Duration.ofMillis(timeoutMs)`maxBytes`SchemaKafkaConsumerState.class`SchemaConsumerRecord::fromConsumerRecord);" is 152.,251
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,commitOffsets,Long Parameter List,The method has 5 parameters. ,272
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,commitOffsets,Long Statement,The length of the statement "context.get().getKafkaConsumerManager().commitOffsets(group`instance`async`offsetCommitRequest`new KafkaConsumerManager.CommitCallback(){" is 137.,272
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecords,Long Parameter List,The method has 7 parameters. ,391
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,ConsumersResource,readRecords,Long Statement,The length of the statement "context.get().getKafkaConsumerManager().readRecords(group`instance`consumerStateType`timeout`maxBytes`new ConsumerReadCallback<ClientKeyT`ClientValueT>(){" is 154.,391
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,PartitionsResource,list,Long Statement,The length of the statement "CompletableFuture<List<GetPartitionResponse>> response=partitionManager.get().listLocalPartitions(topic).thenApply(partitions -> partitions.stream().map(GetPartitionResponse::fromPartition).collect(Collectors.toList()));" is 220.,54
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,PartitionsResource,getPartition,Long Statement,The length of the statement "CompletableFuture<GetPartitionResponse> response=partitionManager.get().getLocalPartition(topic`partitionId).thenApply(partition -> partition.orElseThrow(Errors::partitionNotFoundException)).thenApply(GetPartitionResponse::fromPartition);" is 238.,71
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,PartitionsResource,getOffsets,Long Statement,The length of the statement "CompletableFuture<TopicPartitionOffsetResponse> response=partitionManager.get().getLocalPartition(topic`partitionId).thenApply(partition -> partition.orElseThrow(Errors::partitionNotFoundException)).thenApply(partition -> new TopicPartitionOffsetResponse(partition.getEarliestOffset()`partition.getLatestOffset()));" is 315.,89
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceTest,testGetTopic,Long Statement,The length of the statement "expect(topicConfigManager.listTopicConfigs(CLUSTER_ID`TOPIC_1.getName())).andReturn(completedFuture(Arrays.asList(CONFIG_1`CONFIG_2`CONFIG_3)));" is 144.,384
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceTest,testGetInvalidTopic,Long Statement,The length of the statement "assertErrorResponse(Response.Status.NOT_FOUND`response`Errors.TOPIC_NOT_FOUND_ERROR_CODE`Errors.TOPIC_NOT_FOUND_MESSAGE`Versions.KAFKA_V2_JSON);" is 144.,402
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.AVRO)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(RAW_KEY_SCHEMA)`true)).andStubReturn(registeredKeySchema);" is 213.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.AVRO)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(RAW_VALUE_SCHEMA)`false)).andStubReturn(registeredValueSchema);" is 218.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(1)`Optional.empty()`Optional.empty()`true)).andStubReturn(registeredKeySchema);" is 184.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(2)`Optional.empty()`Optional.empty()`false)).andStubReturn(registeredValueSchema);" is 187.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(recordSerializer.serialize(EmbeddedFormat.AVRO`TopicsResourceAvroProduceTest.TOPIC_NAME`Optional.of(registeredKeySchema)`record.getKey().orElse(NullNode.getInstance())`true)).andReturn(Optional.of(serializedKey));" is 220.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(recordSerializer.serialize(EmbeddedFormat.AVRO`TopicsResourceAvroProduceTest.TOPIC_NAME`Optional.of(registeredValueSchema)`record.getValue().orElse(NullNode.getInstance())`false)).andReturn(Optional.of(serializedValue));" is 227.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "expect(produceController.produce(eq("")`eq(TopicsResourceAvroProduceTest.TOPIC_NAME)`eq(record.getPartition())`eq(ImmutableMultimap.of())`eq(Optional.of(serializedKey))`eq(Optional.of(serializedValue))`isA(Instant.class))).andReturn(CompletableFuture.completedFuture(ProduceResult.fromRecordMetadata(results.get(i))));" is 318.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Long Statement,The length of the statement "Response response=request("/topics/" + TOPIC_NAME`Versions.KAFKA_V2_JSON).post(Entity.entity(request`Versions.KAFKA_V2_JSON_AVRO));" is 131.,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Magic Number,The method contains a magic number: 2,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,produceToTopic,Magic Number,The method contains a magic number: 2,114
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,testProduceToTopicWithPartitionAndKey,Magic Number,The method contains a magic number: 2,213
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceAvroProduceTest,testProduceToTopicWithPartitionAndKey,Magic Number,The method contains a magic number: 2,213
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,RootResourceTest,testInvalidEntityContentType,Long Statement,The length of the statement "Response response=request("/"`Versions.KAFKA_V2_JSON + "` " + Versions.GENERIC_REQUEST).post(Entity.entity(""`"text/plain"));" is 125.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,RootResourceTest,testInvalidEntityContentType,Long Statement,The length of the statement "assertErrorResponse(unsupportedMediaType`response`unsupportedMediaType.getStatusCode()`"HTTP " + unsupportedMediaType.getStatusCode() + " "+ unsupportedMediaType.getReasonPhrase()`Versions.KAFKA_V2_JSON);" is 204.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,BrokersResourceTest,testList,Magic Number,The method contains a magic number: 2,67
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,BrokersResourceTest,testList,Magic Number,The method contains a magic number: 3,67
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,BrokersResourceTest,testAuthenticationError,Long Statement,The length of the statement "expect(brokerManager.listLocalBrokers()).andReturn(failedFuture(new SaslAuthenticationException(Errors.SASL_AUTHENTICATION_FAILED.message())));" is 143.,80
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,BrokersResourceTest,testAuthenticationError,Long Statement,The length of the statement "assertErrorResponse(Response.Status.UNAUTHORIZED`response`io.confluent.kafkarest.Errors.KAFKA_AUTHENTICATION_ERROR_CODE`Errors.SASL_AUTHENTICATION_FAILED.message()`Versions.KAFKA_V2_JSON);" is 188.,80
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,produceToTopic,Long Statement,The length of the statement "Optional<ByteString> serializedValue=record.getValue().map(value -> ByteString.copyFromUtf8(String.valueOf(record.getValue())));" is 128.,158
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,produceToTopic,Long Statement,The length of the statement "expect(recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`record.getKey().orElse(NullNode.getInstance())`true)).andReturn(serializedKey);" is 163.,158
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,produceToTopic,Long Statement,The length of the statement "expect(recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`record.getValue().orElse(NullNode.getInstance())`false)).andReturn(serializedValue);" is 168.,158
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,produceToTopic,Long Statement,The length of the statement "expect(produceController.produce(eq("")`eq(TOPIC_NAME)`eq(record.getPartition())`eq(ImmutableMultimap.of())`eq(serializedKey)`eq(serializedValue)`isA(Instant.class))).andReturn(results.get(i).thenApply(ProduceResult::fromRecordMetadata));" is 238.,158
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,produceToTopic,Long Statement,The length of the statement "Response response=request("/topics/" + TOPIC_NAME`Versions.KAFKA_V2_JSON).post(Entity.entity(request`Versions.KAFKA_V2_JSON_BINARY));" is 133.,158
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicByPartition,Long Identifier,The length of the field PRODUCE_RECORDS_WITH_PARTITIONS is 31.,231
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicWithPartitionAndKey,Long Identifier,The length of the field PRODUCE_RECORDS_WITH_PARTITIONS_AND_KEYS is 40.,236
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicWithNullValues,Long Identifier,The length of the field PRODUCE_RECORDS_WITH_NULL_VALUES is 32.,241
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceInvalidRequest,Long Statement,The length of the statement "Response response=request("/topics/topic1"`Versions.KAFKA_V2_JSON).post(Entity.entity("{}"`Versions.KAFKA_V2_JSON_BINARY));" is 123.,246
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceInvalidRequest,Long Statement,The length of the statement "assertErrorResponse(ConstraintViolationExceptionMapper.UNPROCESSABLE_ENTITY`response`ConstraintViolationExceptionMapper.UNPROCESSABLE_ENTITY_CODE`null`Versions.KAFKA_V2_JSON);" is 175.,246
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicException,Long Statement,The length of the statement "assertErrorResponse(Response.Status.INTERNAL_SERVER_ERROR`rawResponse`RestServerErrorException.DEFAULT_ERROR_CODE`AbstractProduceAction.UNEXPECTED_PRODUCER_EXCEPTION`Versions.KAFKA_V2_JSON);" is 190.,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicGenericException,Long Identifier,The length of the field PRODUCE_GENERIC_EXCEPTION_RESULTS is 33.,280
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaException,Long Identifier,The length of the field PRODUCE_KAFKA_EXCEPTION_RESULTS is 31.,286
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaRetriableException,Long Identifier,The length of the field PRODUCE_KAFKA_RETRIABLE_EXCEPTION_RESULTS is 41.,291
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaRetriableException,Long Identifier,The length of the field KAFKA_RETRIABLE_EXCEPTION_RESULTS is 33.,291
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaAuthorizationException,Long Identifier,The length of the field PRODUCE_KAFKA_AUTHORIZATION_EXCEPTION_RESULTS is 45.,297
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaAuthorizationException,Long Identifier,The length of the field KAFKA_AUTHORIZATION_EXCEPTION_RESULTS is 37.,297
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaAuthorizationException,Long Statement,The length of the statement "testProduceSecurityException(PRODUCE_KAFKA_AUTHORIZATION_EXCEPTION_RESULTS`KAFKA_AUTHORIZATION_EXCEPTION_RESULTS`Response.Status.FORBIDDEN);" is 140.,297
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaAuthenticationException,Long Identifier,The length of the field PRODUCE_KAFKA_AUTHENTICATION_EXCEPTION_RESULTS is 46.,305
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaAuthenticationException,Long Identifier,The length of the field KAFKA_AUTHENTICATION_EXCEPTION_RESULTS is 38.,305
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v2,TopicsResourceBinaryProduceTest,testProduceToTopicKafkaAuthenticationException,Long Statement,The length of the statement "testProduceSecurityException(PRODUCE_KAFKA_AUTHENTICATION_EXCEPTION_RESULTS`KAFKA_AUTHENTICATION_EXCEPTION_RESULTS`Response.Status.UNAUTHORIZED);" is 145.,305
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigsResource,listClusterConfigs,Long Statement,The length of the statement "CompletableFuture<ListClusterConfigsResponse> response=clusterConfigManager.get().listClusterConfigs(clusterId`configType).thenApply(configs -> ListClusterConfigsResponse.create(ClusterConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`String.format("%s-configs"`configType.name().toLowerCase()))).build()).setData(configs.stream().sorted(Comparator.comparing(ClusterConfig::getType).thenComparing(ClusterConfig::getName)).map(this::toClusterConfigData).collect(Collectors.toList())).build()));" is 570.,73
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigsResource,getClusterConfig,Long Statement,The length of the statement "CompletableFuture<GetClusterConfigResponse> response=clusterConfigManager.get().getClusterConfig(clusterId`configType`name).thenApply(config -> config.orElseThrow(NotFoundException::new)).thenApply(config -> GetClusterConfigResponse.create(toClusterConfigData(config)));" is 270.,111
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigsResource,upsertClusterConfig,Long Parameter List,The method has 5 parameters. ,131
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigsResource,toClusterConfigData,Long Statement,The length of the statement "return ClusterConfigData.fromClusterConfig(clusterConfig).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterConfig.getClusterId()`String.format("%s-configs"`clusterConfig.getType().name().toLowerCase())`clusterConfig.getName())).setResourceName(crnFactory.create("kafka"`clusterConfig.getClusterId()`String.format("%s-config"`clusterConfig.getType().name().toLowerCase())`clusterConfig.getName())).build()).build();" is 454.,171
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceRateLimiters,ProduceRateLimiters,Long Identifier,The length of the parameter produceRateLimitCacheExpiryConfig is 33.,43
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceRateLimiters,ProduceRateLimiters,Long Parameter List,The method has 6 parameters. ,43
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceRateLimiters,ProduceRateLimiters,Long Statement,The length of the statement "countCache=CacheBuilder.newBuilder().expireAfterAccess(produceRateLimitCacheExpiryConfig).build(new RequestRateLimiterCacheLoader(countLimiterProvider));" is 153.,43
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceRateLimiters,ProduceRateLimiters,Long Statement,The length of the statement "bytesCache=CacheBuilder.newBuilder().expireAfterAccess(produceRateLimitCacheExpiryConfig).build(new RequestRateLimiterCacheLoader(bytesLimiterProvider));" is 153.,43
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResource,ConsumerGroupLagSummariesResource,Long Identifier,The length of the parameter consumerGroupLagSummaryManager is 30.,51
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResource,ConsumerGroupLagSummariesResource,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,51
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResource,getConsumerGroupLagSummary,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,61
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResource,getConsumerGroupLagSummary,Long Statement,The length of the statement "CompletableFuture<GetConsumerGroupLagSummaryResponse> response=consumerGroupLagSummaryManager.get().getConsumerGroupLagSummary(clusterId`consumerGroupId).thenApply(groupLagSummary -> groupLagSummary.orElseThrow(NotFoundException::new)).thenApply(groupLagSummary -> GetConsumerGroupLagSummaryResponse.create(toConsumerGroupLagSummaryData(groupLagSummary)));" is 356.,61
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResource,toConsumerGroupLagSummaryData,Long Statement,The length of the statement "return ConsumerGroupLagSummaryData.fromConsumerGroupLagSummary(groupLagSummary).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`groupLagSummary.getClusterId()`"consumer-groups"`groupLagSummary.getConsumerGroupId()`"lag-summary")).setResourceName(crnFactory.create("kafka"`groupLagSummary.getClusterId()`"consumer-group"`groupLagSummary.getConsumerGroupId()`"lag-summary"`null)).build()).setMaxLagConsumer(Relationship.create(urlFactory.create("v3"`"clusters"`groupLagSummary.getClusterId()`"consumer-groups"`groupLagSummary.getConsumerGroupId()`"consumers"`groupLagSummary.getMaxLagConsumerId()))).setMaxLagPartition(Relationship.create(urlFactory.create("v3"`"clusters"`groupLagSummary.getClusterId()`"topics"`groupLagSummary.getMaxLagTopicName()`"partitions"`Integer.toString(groupLagSummary.getMaxLagPartitionId())))).build();" is 863.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigsResource,listBrokerConfigs,Long Statement,The length of the statement "CompletableFuture<ListBrokerConfigsResponse> response=brokerConfigManager.get().listBrokerConfigs(clusterId`brokerId).thenApply(configs -> ListBrokerConfigsResponse.create(BrokerConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"brokers"`String.valueOf(brokerId)`"configs")).build()).setData(configs.stream().sorted(Comparator.comparing(BrokerConfig::getName)).map(brokerConfig -> toBrokerConfigData(brokerConfig`crnFactory`urlFactory)).collect(Collectors.toList())).build()));" is 554.,73
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigsResource,getBrokerConfig,Long Statement,The length of the statement "CompletableFuture<GetBrokerConfigResponse> response=brokerConfigManager.get().getBrokerConfig(clusterId`brokerId`name).thenApply(broker -> broker.orElseThrow(NotFoundException::new)).thenApply(broker -> GetBrokerConfigResponse.create(toBrokerConfigData(broker`crnFactory`urlFactory)));" is 285.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigsResource,updateBrokerConfig,Long Parameter List,The method has 5 parameters. ,136
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigsResource,toBrokerConfigData,Long Statement,The length of the statement "return BrokerConfigData.fromBrokerConfig(brokerConfig).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`brokerConfig.getClusterId()`"brokers"`String.valueOf(brokerConfig.getBrokerId())`"configs"`brokerConfig.getName())).setResourceName(crnFactory.create("kafka"`brokerConfig.getClusterId()`"broker"`String.valueOf(brokerConfig.getBrokerId())`"config"`brokerConfig.getName())).build()).build();" is 426.,176
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterClusterConfigBatchAction,alterClusterConfigBatch,Long Statement,The length of the statement "CompletableFuture<Void> response=clusterConfigManager.get().alterClusterConfigs(clusterId`configType`request.getValue().toAlterConfigCommands());" is 145.,52
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,listTopics,Long Statement,The length of the statement "CompletableFuture<ListTopicsResponse> response=topicManager.get().listTopics(clusterId`includeAuthorizedOperations).thenApply(topics -> ListTopicsResponse.create(TopicDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics")).build()).setData(topics.stream().sorted(Comparator.comparing(Topic::getName)).map(this::toTopicData).collect(Collectors.toList())).build()));" is 440.,81
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,getTopic,Long Statement,The length of the statement "CompletableFuture<GetTopicResponse> response=topicManager.get().getTopic(clusterId`topicName`includeAuthorizedOperations).thenApply(topic -> topic.orElseThrow(NotFoundException::new)).thenApply(topic -> GetTopicResponse.create(toTopicData(topic)));" is 248.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,createTopic,Long Statement,The length of the statement "Map<String`Optional<String>> configs=request.getConfigs().stream().collect(Collectors.toMap(ConfigEntry::getName`ConfigEntry::getValue));" is 137.,134
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,createTopic,Long Statement,The length of the statement "short assumedReplicationFactor=replicationFactor.orElse(replicasAssignments.isEmpty() ? 0 : (short)replicasAssignments.values().iterator().next().size());" is 154.,134
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,createTopic,Long Statement,The length of the statement "TopicData topicData=toTopicData(Topic.create(clusterId`topicName`emptyList()`assumedReplicationFactor`false`emptySet()));" is 121.,134
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,createTopic,Long Statement,The length of the statement "CompletableFuture<CreateTopicResponse> response=topicManager.get().createTopic(clusterId`topicName`partitionsCount`replicationFactor`replicasAssignments`configs).thenApply(none -> CreateTopicResponse.create(topicData));" is 219.,134
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,createTopic,Long Statement,The length of the statement "AsyncResponseBuilder.from(Response.status(Status.CREATED).location(URI.create(topicData.getMetadata().getSelf()))).entity(response).asyncResume(asyncResponse);" is 159.,134
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResource,toTopicData,Long Statement,The length of the statement "return TopicData.fromTopic(topic).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`topic.getClusterId()`"topics"`topic.getName())).setResourceName(crnFactory.create("kafka"`topic.getClusterId()`"topic"`topic.getName())).build()).setPartitions(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`topic.getClusterId()`"topics"`topic.getName()`"partitions"))).setConfigs(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`topic.getClusterId()`"topics"`topic.getName()`"configs"))).setPartitionReassignments(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`topic.getClusterId()`"topics"`topic.getName()`"partitions"`"-"`"reassignment"))).build();" is 712.,204
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,GetReassignmentAction,getReassignment,Long Statement,The length of the statement "CompletableFuture<GetReassignmentResponse> response=reassignmentManager.get().getReassignment(clusterId`topicName`partitionId).thenApply(reassignment -> reassignment.orElseThrow(NotFoundException::new)).thenApply(reassignment -> GetReassignmentResponse.create(toReassignmentData(reassignment)));" is 295.,60
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,GetReassignmentAction,toReassignmentData,Long Statement,The length of the statement "return ReassignmentData.fromReassignment(reassignment).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`reassignment.getClusterId()`"topics"`reassignment.getTopicName()`"partitions"`Integer.toString(reassignment.getPartitionId())`"reassignment")).setResourceName(crnFactory.create("kafka"`reassignment.getClusterId()`"topic"`reassignment.getTopicName()`"partition"`Integer.toString(reassignment.getPartitionId())`"reassignment"`null)).build()).setReplicas(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`reassignment.getClusterId()`"topics"`reassignment.getTopicName()`"partitions"`Integer.toString(reassignment.getPartitionId())`"replicas"))).build();" is 700.,80
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResource,listConsumerAssignments,Long Statement,The length of the statement "CompletableFuture<ListConsumerAssignmentsResponse> response=consumerAssignmentManager.get().listConsumerAssignments(clusterId`consumerGroupId`consumerId).thenApply(assignments -> ListConsumerAssignmentsResponse.create(ConsumerAssignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups"`consumerGroupId`"consumers"`consumerId`"assignments")).build()).setData(assignments.stream().map(this::toConsumerAssignmentData).sorted(Comparator.comparing(ConsumerAssignmentData::getTopicName).thenComparing(ConsumerAssignmentData::getPartitionId)).collect(Collectors.toList())).build()));" is 665.,67
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResource,getConsumerAssignment,Long Parameter List,The method has 6 parameters. ,109
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResource,getConsumerAssignment,Long Statement,The length of the statement "CompletableFuture<GetConsumerAssignmentResponse> response=consumerAssignmentManager.get().getConsumerAssignment(clusterId`consumerGroupId`consumerId`topicName`partitionId).thenApply(assignment -> assignment.orElseThrow(NotFoundException::new)).thenApply(assignment -> GetConsumerAssignmentResponse.create(toConsumerAssignmentData(assignment)));" is 344.,109
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResource,toConsumerAssignmentData,Long Statement,The length of the statement "return ConsumerAssignmentData.fromConsumerAssignment(assignment).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`assignment.getClusterId()`"consumer-groups"`assignment.getConsumerGroupId()`"consumers"`assignment.getConsumerId()`"assignments"`assignment.getTopicName()`"partitions"`Integer.toString(assignment.getPartitionId()))).setResourceName(crnFactory.create("kafka"`assignment.getClusterId()`"consumer-group"`assignment.getConsumerGroupId()`"consumer"`assignment.getConsumerId()`"assignment"`assignment.getTopicName()`"partition"`Integer.toString(assignment.getPartitionId()))).build()).setPartition(Relationship.create(urlFactory.create("v3"`"clusters"`assignment.getClusterId()`"topics"`assignment.getTopicName()`"partitions"`Integer.toString(assignment.getPartitionId())))).setLag(Relationship.create(urlFactory.create("v3"`"clusters"`assignment.getClusterId()`"consumer-groups"`assignment.getConsumerGroupId()`"lags"`assignment.getTopicName()`"partitions"`Integer.toString(assignment.getPartitionId())))).build();" is 1056.,133
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsAction,listTopicConfigs,Long Statement,The length of the statement "CompletableFuture<ListTopicConfigsResponse> response=topicManager.get().listTopics(clusterId).thenCompose(topics -> resolvedTopicConfigManager.listTopicConfigs(clusterId`topics.stream().map(topic -> topic.getName()).collect(Collectors.toList())).thenApply(configs -> ListTopicConfigsResponse.create(TopicConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics"`"-"`"configs")).build()).setData(configs.values().stream().flatMap(topicConfigs -> topicConfigs.stream().sorted(Comparator.comparing(TopicConfig::getName))).map(topicConfig -> TopicConfigsResource.toTopicConfigData(topicConfig`crnFactory`urlFactory)).collect(Collectors.toList())).build())));" is 732.,65
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResource,listBrokers,Long Statement,The length of the statement "CompletableFuture<ListBrokersResponse> response=brokerManager.get().listBrokers(clusterId).thenApply(brokers -> ListBrokersResponse.create(BrokerDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"brokers")).build()).setData(brokers.stream().map(this::toBrokerData).collect(Collectors.toList())).build()));" is 376.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResource,getBroker,Long Statement,The length of the statement "CompletableFuture<GetBrokerResponse> response=brokerManager.get().getBroker(clusterId`brokerId).thenApply(broker -> broker.orElseThrow(NotFoundException::new)).thenApply(broker -> GetBrokerResponse.create(toBrokerData(broker)));" is 228.,90
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResource,toBrokerData,Long Statement,The length of the statement "return BrokerData.fromBroker(broker).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`broker.getClusterId()`"brokers"`Integer.toString(broker.getBrokerId()))).setResourceName(crnFactory.create("kafka"`broker.getClusterId()`"broker"`Integer.toString(broker.getBrokerId()))).build()).setConfigs(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`broker.getClusterId()`"brokers"`Integer.toString(broker.getBrokerId())`"configs"))).setPartitionReplicas(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`broker.getClusterId()`"brokers"`Integer.toString(broker.getBrokerId())`"partition-replicas"))).build();" is 660.,109
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResource,listConsumerLags,Long Statement,The length of the statement "CompletableFuture<ListConsumerLagsResponse> response=consumerLagManager.get().listConsumerLags(clusterId`consumerGroupId).thenApply(lags -> {" is 141.,65
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResource,listConsumerLags,Long Statement,The length of the statement ").thenApply(lags -> ListConsumerLagsResponse.create(ConsumerLagDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups"`consumerGroupId`"lags")).build()).setData(lags.stream().map(this::toConsumerLagData).sorted(Comparator.comparing(ConsumerLagData::getLag).reversed().thenComparing(ConsumerLagData::getTopicName).thenComparing(ConsumerLagData::getPartitionId)).collect(Collectors.toList())).build()));" is 484.,65
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResource,getConsumerLag,Long Parameter List,The method has 5 parameters. ,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResource,getConsumerLag,Long Statement,The length of the statement "CompletableFuture<GetConsumerLagResponse> response=consumerLagManager.get().getConsumerLag(clusterId`consumerGroupId`topicName`partitionId).thenApply(lag -> lag.orElseThrow(NotFoundException::new)).thenApply(lag -> GetConsumerLagResponse.create(toConsumerLagData(lag)));" is 270.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResource,toConsumerLagData,Long Statement,The length of the statement "return ConsumerLagData.fromConsumerLag(lag).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`lag.getClusterId()`"consumer-groups"`lag.getConsumerGroupId()`"lags"`lag.getTopicName()`"partitions"`Integer.toString(lag.getPartitionId()))).setResourceName(crnFactory.create("kafka"`lag.getClusterId()`"consumer-group"`lag.getConsumerGroupId()`"lag"`lag.getTopicName()`"partition"`Integer.toString(lag.getPartitionId()))).build()).build();" is 466.,134
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResource,listClusters,Long Statement,The length of the statement "CompletableFuture<ListClustersResponse> response=clusterManager.get().listClusters().thenApply(clusters -> ListClustersResponse.create(ClusterDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters")).build()).setData(clusters.stream().map(this::toClusterData).collect(Collectors.toList())).build()));" is 355.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResource,getCluster,Long Statement,The length of the statement "CompletableFuture<GetClusterResponse> response=clusterManager.get().getCluster(clusterId).thenApply(cluster -> cluster.orElseThrow(NotFoundException::new)).thenApply(cluster -> GetClusterResponse.create(toClusterData(cluster)));" is 228.,88
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResource,toClusterData,Long Statement,The length of the statement "ClusterData.Builder clusterData=ClusterData.fromCluster(cluster).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`cluster.getClusterId())).setResourceName(crnFactory.create("kafka"`cluster.getClusterId())).build()).setAcls(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"acls"))).setBrokers(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"brokers"))).setBrokerConfigs(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"broker-configs"))).setConsumerGroups(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"consumer-groups"))).setTopics(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"topics"))).setPartitionReassignments(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"topics"`"-"`"partitions"`"-"`"reassignment")));" is 978.,105
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResource,toClusterData,Long Statement,The length of the statement "clusterData.setController(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`cluster.getClusterId()`"brokers"`Integer.toString(cluster.getController().getBrokerId()))));" is 181.,105
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,ProducerMetrics,Long Identifier,The length of the field RECORD_RATE_LIMITED_SENSOR_NAME is 31.,118
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestSensor,Long Identifier,The length of the field REQUEST_COUNT_WINDOWED_METRIC_NAME is 34.,145
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestSensor,Long Identifier,The length of the field REQUEST_COUNT_WINDOWED_METRIC_DOC is 33.,145
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,createMeter,Long Statement,The length of the statement "MetricName rateMetricName=metrics.metricName(baseName + "-rate"`GROUP_NAME`String.format("The number of %s per second"`descriptiveName)`metricTags);" is 148.,160
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,createMeter,Long Statement,The length of the statement "MetricName totalMetricName=metrics.metricName(baseName + "-total"`GROUP_NAME`String.format("The total number of %s"`descriptiveName)`metricTags);" is 145.,160
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupResponseSensor,Long Identifier,The length of the field RESPONSE_COUNT_WINDOWED_METRIC_NAME is 35.,177
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupResponseSensor,Long Identifier,The length of the field RESPONSE_COUNT_WINDOWED_METRIC_DOC is 34.,177
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordErrorSensor,Long Identifier,The length of the field RECORD_ERROR_COUNT_WINDOWED_METRIC_NAME is 39.,187
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordErrorSensor,Long Identifier,The length of the field RECORD_ERROR_COUNT_WINDOWED_METRIC_DOC is 38.,187
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordErrorSensor,Long Statement,The length of the statement "addWindowedCount(recordErrorSensor`RECORD_ERROR_COUNT_WINDOWED_METRIC_NAME`RECORD_ERROR_COUNT_WINDOWED_METRIC_DOC`metricsTags);" is 127.,187
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordRateLimitedSensor,Long Identifier,The length of the field RECORD_RATE_LIMITED_SENSOR_NAME is 31.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordRateLimitedSensor,Long Identifier,The length of the field RECORD_RATE_LIMITED_RATE_METRIC_NAME is 36.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordRateLimitedSensor,Long Identifier,The length of the field RECORD_RATE_LIMITED_RATE_METRIC_DOC is 35.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordRateLimitedSensor,Long Identifier,The length of the field RECORD_RATE_LIMITED_COUNT_WINDOWED_METRIC_NAME is 46.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordRateLimitedSensor,Long Identifier,The length of the field RECORD_RATE_LIMITED_COUNT_WINDOWED_METRIC_DOC is 45.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRecordRateLimitedSensor,Long Statement,The length of the statement "addWindowedCount(recordRateLimitedSensor`RECORD_RATE_LIMITED_COUNT_WINDOWED_METRIC_NAME`RECORD_RATE_LIMITED_COUNT_WINDOWED_METRIC_DOC`metricsTags);" is 147.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Identifier,The length of the field REQUEST_LATENCY_MAX_METRIC_NAME is 31.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Identifier,The length of the field REQUEST_LATENCY_MAX_METRIC_DOC is 30.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Identifier,The length of the field REQUEST_LATENCY_AVG_METRIC_NAME is 31.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Identifier,The length of the field REQUEST_LATENCY_AVG_METRIC_DOC is 30.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Identifier,The length of the field REQUEST_LATENCY_PCT_METRIC_PREFIX is 33.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Identifier,The length of the field REQUEST_LATENCY_PCT_METRIC_DOC is 30.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Long Statement,The length of the statement "addPercentiles(requestLatencySensor`REQUEST_LATENCY_PCT_METRIC_PREFIX`ImmutableMap.of("p95"`0.95`"p99"`0.99`"p999"`0.999)`REQUEST_LATENCY_PCT_METRIC_DOC`metricsTags);" is 166.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Magic Number,The method contains a magic number: 0.95,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Magic Number,The method contains a magic number: 0.99,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,setupRequestLatencySensor,Magic Number,The method contains a magic number: 0.999,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Long Parameter List,The method has 5 parameters. ,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Long Statement,The length of the statement "sensor.add(new Percentiles(30 * 1000 * 4`30 * 1000`Percentiles.BucketSizing.CONSTANT`percentiles.entrySet().stream().map(entry -> new Percentile(getMetricName(prefix + entry.getKey()`doc`metricsTags)`entry.getValue())).toArray(Percentile[]::new)));" is 248.,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Magic Number,The method contains a magic number: 30,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Magic Number,The method contains a magic number: 1000,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Magic Number,The method contains a magic number: 4,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Magic Number,The method contains a magic number: 30,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetrics,addPercentiles,Magic Number,The method contains a magic number: 1000,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsAction,listBrokersConfigs,Long Statement,The length of the statement "CompletableFuture<ListBrokerConfigsResponse> response=brokerManager.get().listBrokers(clusterId).thenCompose(brokers -> resolvedBrokerConfigManager.listAllBrokerConfigs(clusterId`brokers.stream().map(Broker::getBrokerId).collect(Collectors.toList())).thenApply(configs -> ListBrokerConfigsResponse.create(BrokerConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"brokers"`"-"`"configs")).build()).setData(configs.values().stream().flatMap(brokerConfigs -> brokerConfigs.stream().sorted(Comparator.comparing(BrokerConfig::getBrokerId))).map(brokerConfig -> BrokerConfigsResource.toBrokerConfigData(brokerConfig`crnFactory`urlFactory)).collect(Collectors.toList())).build())));" is 751.,66
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterTopicConfigBatchAction,alterTopicConfigBatch,Long Statement,The length of the statement "CompletableFuture<Void> response=topicConfigManager.get().alterTopicConfigs(clusterId`topicName`request.getValue().toAlterConfigCommands());" is 140.,51
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResource,listTopicConfigs,Long Statement,The length of the statement "CompletableFuture<ListTopicConfigsResponse> response=topicConfigManager.get().listTopicConfigs(clusterId`topicName).thenApply(configs -> ListTopicConfigsResponse.create(TopicConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics"`topicName`"configs")).build()).setData(configs.stream().sorted(Comparator.comparing(TopicConfig::getName)).map(topicConfig -> toTopicConfigData(topicConfig`crnFactory`urlFactory)).collect(Collectors.toList())).build()));" is 530.,73
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResource,getTopicConfig,Long Statement,The length of the statement "CompletableFuture<GetTopicConfigResponse> response=topicConfigManager.get().getTopicConfig(clusterId`topicName`name).thenApply(topic -> topic.orElseThrow(NotFoundException::new)).thenApply(topic -> GetTopicConfigResponse.create(toTopicConfigData(topic`crnFactory`urlFactory)));" is 277.,112
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResource,updateTopicConfig,Long Parameter List,The method has 5 parameters. ,135
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResource,toTopicConfigData,Long Statement,The length of the statement "return TopicConfigData.fromTopicConfig(topicConfig).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`topicConfig.getClusterId()`"topics"`topicConfig.getTopicName()`"configs"`topicConfig.getName())).setResourceName(crnFactory.create("kafka"`topicConfig.getClusterId()`"topic"`topicConfig.getTopicName()`"config"`topicConfig.getName())).build()).build();" is 385.,175
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResource,listReplicas,Long Statement,The length of the statement "CompletableFuture<ListReplicasResponse> response=replicaManager.get().listReplicas(clusterId`topicName`partitionId).thenApply(replicas -> ListReplicasResponse.create(ReplicaDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics"`topicName`"partitions"`Integer.toString(partitionId)`"replicas")).build()).setData(replicas.stream().map(this::toReplicaData).collect(Collectors.toList())).build()));" is 469.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResource,getReplica,Long Parameter List,The method has 5 parameters. ,101
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResource,getReplica,Long Statement,The length of the statement "CompletableFuture<GetReplicaResponse> response=replicaManager.get().getReplica(clusterId`topicName`partitionId`brokerId).thenApply(replica -> replica.orElseThrow(NotFoundException::new)).thenApply(replica -> GetReplicaResponse.create(toReplicaData(replica)));" is 259.,101
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResource,toReplicaData,Long Statement,The length of the statement "return ReplicaData.fromPartitionReplica(replica).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`replica.getClusterId()`"topics"`replica.getTopicName()`"partitions"`Integer.toString(replica.getPartitionId())`"replicas"`Integer.toString(replica.getBrokerId()))).setResourceName(crnFactory.create("kafka"`replica.getClusterId()`"topic"`replica.getTopicName()`"partition"`Integer.toString(replica.getPartitionId())`"replica"`Integer.toString(replica.getBrokerId()))).build()).setBroker(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`replica.getClusterId()`"brokers"`Integer.toString(replica.getBrokerId())))).build();" is 664.,122
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,V3ResourcesModule,configure,Long Statement,The length of the statement "bindFactory(ProduceResponseExecutorServiceFactory.class).qualifiedBy(new ProduceResponseThreadPoolImpl()).to(ExecutorService.class).in(Singleton.class);" is 152.,45
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReplicasByBrokerAction,searchReplicasByBroker,Long Statement,The length of the statement "CompletableFuture<SearchReplicasByBrokerResponse> response=replicaManager.get().searchReplicasByBrokerId(clusterId`brokerId).thenApply(replicas -> SearchReplicasByBrokerResponse.create(ReplicaDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"brokers"`Integer.toString(brokerId)`"partition-replicas")).build()).setData(replicas.stream().sorted(comparing(PartitionReplica::getTopicName).thenComparing(PartitionReplica::getPartitionId)).map(this::toReplicaData).collect(Collectors.toList())).build()));" is 571.,61
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReplicasByBrokerAction,toReplicaData,Long Statement,The length of the statement "return ReplicaData.fromPartitionReplica(replica).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`replica.getClusterId()`"topics"`replica.getTopicName()`"partitions"`Integer.toString(replica.getPartitionId())`"replicas"`Integer.toString(replica.getBrokerId()))).setResourceName(crnFactory.create("kafka"`replica.getClusterId()`"topic"`replica.getTopicName()`"partition"`Integer.toString(replica.getPartitionId())`"replica"`Integer.toString(replica.getBrokerId()))).build()).setBroker(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`replica.getClusterId()`"brokers"`Integer.toString(replica.getBrokerId())))).build();" is 664.,100
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResource,listConsumerGroups,Long Statement,The length of the statement "CompletableFuture<ListConsumerGroupsResponse> response=consumerGroupManager.get().listConsumerGroups(clusterId).thenApply(consumerGroups -> ListConsumerGroupsResponse.create(ConsumerGroupDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups")).build()).setData(consumerGroups.stream().map(consumerGroup -> toConsumerGroupData(clusterId`consumerGroup)).collect(Collectors.toList())).build()));" is 476.,65
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResource,getConsumerGroup,Long Statement,The length of the statement "CompletableFuture<GetConsumerGroupResponse> response=consumerGroupManager.get().getConsumerGroup(clusterId`consumerGroupId).thenApply(consumerGroup -> consumerGroup.orElseThrow(NotFoundException::new)).thenApply(consumerGroup -> GetConsumerGroupResponse.create(toConsumerGroupData(clusterId`consumerGroup)));" is 308.,96
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResource,toConsumerGroupData,Long Statement,The length of the statement "return ConsumerGroupData.fromConsumerGroup(consumerGroup).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups"`consumerGroup.getConsumerGroupId())).setResourceName(crnFactory.create("kafka"`clusterId`"consumer-group"`consumerGroup.getConsumerGroupId())).build()).setCoordinator(Relationship.create(urlFactory.create("v3"`"clusters"`clusterId`"brokers"`Integer.toString(consumerGroup.getCoordinator().getBrokerId())))).setConsumers(Relationship.create(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups"`consumerGroup.getConsumerGroupId()`"consumers"))).setLagSummary(Relationship.create(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups"`consumerGroup.getConsumerGroupId()`"lag-summary"))).build();" is 776.,117
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResource,listConsumers,Long Statement,The length of the statement "CompletableFuture<ListConsumersResponse> response=consumerManager.get().listConsumers(clusterId`consumerGroupId).thenApply(consumers -> ListConsumersResponse.create(ConsumerDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"consumer-groups"`consumerGroupId`"consumers")).build()).setData(consumers.stream().map(this::toConsumerData).sorted(Comparator.comparing(ConsumerData::getConsumerId)).collect(Collectors.toList())).build()));" is 502.,64
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResource,getConsumer,Long Statement,The length of the statement "CompletableFuture<GetConsumerResponse> response=consumerManager.get().getConsumer(clusterId`consumerGroupId`consumerId).thenApply(consumer -> consumer.orElseThrow(NotFoundException::new)).thenApply(consumer -> GetConsumerResponse.create(toConsumerData(consumer)));" is 264.,101
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResource,toConsumerData,Long Statement,The length of the statement "return ConsumerData.fromConsumer(consumer).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`consumer.getClusterId()`"consumer-groups"`consumer.getConsumerGroupId()`"consumers"`consumer.getConsumerId())).setResourceName(crnFactory.create("kafka"`consumer.getClusterId()`"consumer-group"`consumer.getConsumerGroupId()`"consumer"`consumer.getConsumerId())).build()).setAssignments(Relationship.create(urlFactory.create("v3"`"clusters"`consumer.getClusterId()`"consumer-groups"`consumer.getConsumerGroupId()`"consumers"`consumer.getConsumerId()`"assignments"))).build();" is 599.,121
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterBrokerConfigBatchAction,alterBrokerConfigBatch,Long Statement,The length of the statement "CompletableFuture<Void> response=brokerConfigManager.get().alterBrokerConfigs(clusterId`brokerId`request.getValue().toAlterConfigCommands());" is 141.,51
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,ProduceAction,Long Parameter List,The method has 7 parameters. ,88
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,produce,Long Statement,The length of the statement "streamingResponseFactory.from(requests).compose(request -> produce(clusterId`topicName`request`controller`producerMetricsProvider.get())).resume(asyncResponse);" is 160.,106
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,produce,Long Identifier,The length of the field PRODUCE_REQUEST_HEADER_COLLECTOR is 32.,131
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,produce,Long Parameter List,The method has 5 parameters. ,131
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,produce,Long Statement,The length of the statement "Optional<EmbeddedFormat> keyFormat=keySchema.map(schema -> Optional.of(schema.getFormat())).orElse(request.getKey().flatMap(ProduceRequestData::getFormat));" is 156.,131
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,produce,Long Statement,The length of the statement "Optional<EmbeddedFormat> valueFormat=valueSchema.map(schema -> Optional.of(schema.getFormat())).orElse(request.getValue().flatMap(ProduceRequestData::getFormat));" is 162.,131
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,produce,Long Statement,The length of the statement "CompletableFuture<ProduceResult> produceResult=controller.produce(clusterId`topicName`request.getPartitionId()`request.getHeaders().stream().collect(PRODUCE_REQUEST_HEADER_COLLECTOR)`serializedKey`serializedValue`request.getTimestamp().orElse(Instant.now()));" is 259.,131
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,getSchema,Long Statement,The length of the statement "return Optional.of(schemaManagerProvider.get().getSchema(topicName`data.getFormat()`data.getSubject()`data.getSubjectNameStrategy().map(Function.identity())`data.getSchemaId()`data.getSchemaVersion()`data.getRawSchema()`isKey));" is 228.,202
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,serialize,Long Parameter List,The method has 5 parameters. ,228
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,serialize,Long Statement,The length of the statement "return recordSerializerProvider.get().serialize(format.orElse(EmbeddedFormat.BINARY)`topicName`schema`data.map(ProduceRequestData::getData).orElse(NullNode.getInstance())`isKey);" is 178.,228
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,toProduceResponse,Long Parameter List,The method has 7 parameters. ,244
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceAction,toProduceResponse,Long Statement,The length of the statement "return ProduceResponse.builder().setClusterId(clusterId).setTopicName(topicName).setPartitionId(result.getPartitionId()).setOffset(result.getOffset()).setTimestamp(result.getTimestamp()).setKey(keyFormat.map(format -> ProduceResponseData.builder().setType(keyFormat).setSubject(keySchema.map(RegisteredSchema::getSubject)).setSchemaId(keySchema.map(RegisteredSchema::getSchemaId)).setSchemaVersion(keySchema.map(RegisteredSchema::getSchemaVersion)).setSize(result.getSerializedKeySize()).build())).setValue(valueFormat.map(format -> ProduceResponseData.builder().setType(valueFormat).setSubject(valueSchema.map(RegisteredSchema::getSubject)).setSchemaId(valueSchema.map(RegisteredSchema::getSchemaId)).setSchemaVersion(valueSchema.map(RegisteredSchema::getSchemaVersion)).setSize(result.getSerializedValueSize()).build())).setErrorCode(HttpStatus.OK_200).build();" is 863.,244
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResource,listPartitions,Long Statement,The length of the statement "CompletableFuture<ListPartitionsResponse> response=partitionManager.get().listPartitions(clusterId`topicName).thenApply(partitions -> ListPartitionsResponse.create(PartitionDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics"`topicName`"partitions")).build()).setData(partitions.stream().map(this::toPartitionData).collect(Collectors.toList())).build()));" is 432.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResource,getPartition,Long Statement,The length of the statement "CompletableFuture<GetPartitionResponse> response=partitionManager.get().getPartition(clusterId`topicName`partitionId).thenApply(partition -> partition.orElseThrow(NotFoundException::new)).thenApply(partition -> GetPartitionResponse.create(toPartitionData(partition)));" is 268.,98
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResource,toPartitionData,Long Statement,The length of the statement "PartitionData.Builder partitionData=PartitionData.fromPartition(partition).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`partition.getClusterId()`"topics"`partition.getTopicName()`"partitions"`Integer.toString(partition.getPartitionId()))).setResourceName(crnFactory.create("kafka"`partition.getClusterId()`"topic"`partition.getTopicName()`"partition"`Integer.toString(partition.getPartitionId()))).build()).setReplicas(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`partition.getClusterId()`"topics"`partition.getTopicName()`"partitions"`Integer.toString(partition.getPartitionId())`"replicas"))).setReassignment(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`partition.getClusterId()`"topics"`partition.getTopicName()`"partitions"`Integer.toString(partition.getPartitionId())`"reassignment")));" is 864.,122
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResource,toPartitionData,Long Statement,The length of the statement "partition.getLeader().map(replica -> Resource.Relationship.create(urlFactory.create("v3"`"clusters"`partition.getClusterId()`"topics"`partition.getTopicName()`"partitions"`Integer.toString(partition.getPartitionId())`"replicas"`Integer.toString(replica.getBrokerId())))).ifPresent(partitionData::setLeader);" is 307.,122
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllReassignmentsAction,listReassignments,Long Statement,The length of the statement "CompletableFuture<ListAllReassignmentsResponse> response=reassignmentManager.get().listReassignments(clusterId).thenApply(reassignments -> ListAllReassignmentsResponse.create(ReassignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics"`"-"`"partitions"`"-"`"reassignments")).build()).setData(reassignments.stream().map(this::toReassignmentData).collect(Collectors.toList())).build()));" is 466.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllReassignmentsAction,toReassignmentData,Long Statement,The length of the statement "return ReassignmentData.fromReassignment(reassignment).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`reassignment.getClusterId()`"topics"`reassignment.getTopicName()`"partitions"`Integer.toString(reassignment.getPartitionId())`"reassignments")).setResourceName(crnFactory.create("kafka"`reassignment.getClusterId()`"topic"`reassignment.getTopicName()`"partition"`Integer.toString(reassignment.getPartitionId())`"reassignments"`null)).build()).setReplicas(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`reassignment.getClusterId()`"topics"`reassignment.getTopicName()`"partitions"`Integer.toString(reassignment.getPartitionId())`"replicas"))).build();" is 702.,98
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicAction,listReassignmentsByTopic,Long Statement,The length of the statement "CompletableFuture<SearchReassignmentsByTopicResponse> response=reassignmentManager.get().searchReassignmentsByTopicName(clusterId`topicName).thenApply(reassignments -> SearchReassignmentsByTopicResponse.create(ReassignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`clusterId`"topics"`topicName`"partitions"`"-"`"reassignments")).build()).setData(reassignments.stream().map(this::toReassignmentData).collect(Collectors.toList())).build()));" is 507.,62
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicAction,toReassignmentData,Long Statement,The length of the statement "return ReassignmentData.fromReassignment(reassignment).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.create("v3"`"clusters"`reassignment.getClusterId()`"topics"`reassignment.getTopicName()`"partitions"`Integer.toString(reassignment.getPartitionId())`"reassignments")).setResourceName(crnFactory.create("kafka"`reassignment.getClusterId()`"topic"`reassignment.getTopicName()`"partition"`Integer.toString(reassignment.getPartitionId())`"reassignments"`null)).build()).setReplicas(Resource.Relationship.create(urlFactory.create("v3"`"clusters"`reassignment.getClusterId()`"topics"`reassignment.getTopicName()`"partitions"`Integer.toString(reassignment.getPartitionId())`"replicas"))).build();" is 702.,100
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,searchAcls,Long Parameter List,The method has 9 parameters. ,74
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,searchAcls,Long Statement,The length of the statement "CompletableFuture<SearchAclsResponse> response=aclManager.get().searchAcls(clusterId`resourceType`resourceName.isEmpty() ? null : resourceName`patternType`principal.isEmpty() ? null : principal`host.isEmpty() ? null : host`operation`permission).thenApply(acls -> SearchAclsResponse.create(AclDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(urlFactory.newUrlBuilder().appendPathSegment("v3").appendPathSegment("clusters").appendPathSegment(clusterId).appendPathSegment("acls").putQueryParameter("resource_type"`resourceType.name()).putQueryParameter("resource_name"`resourceName).putQueryParameter("pattern_type"`patternType.name()).putQueryParameter("principal"`principal).putQueryParameter("host"`host).putQueryParameter("operation"`operation.name()).putQueryParameter("permission"`permission.name()).build()).build()).setData(acls.stream().map(this::toAclData).sorted(Comparator.comparing(AclData::getResourceType).thenComparing(AclData::getResourceName).thenComparing(AclData::getPatternType).thenComparing(AclData::getPrincipal).thenComparing(AclData::getHost).thenComparing(AclData::getOperation).thenComparing(AclData::getPermission)).collect(Collectors.toList())).build()));" is 1210.,74
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,createAcl,Complex Conditional,The conditional expression request.getPatternType() == Acl.PatternType.ANY || request.getPatternType() == Acl.PatternType.MATCH || request.getPatternType() == Acl.PatternType.UNKNOWN is complex.,152
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,createAcl,Long Statement,The length of the statement "if (request.getPatternType() == Acl.PatternType.ANY || request.getPatternType() == Acl.PatternType.MATCH || request.getPatternType() == Acl.PatternType.UNKNOWN) {" is 162.,152
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,createAcl,Long Statement,The length of the statement "CompletableFuture<Void> response=aclManager.get().createAcl(clusterId`request.getResourceType()`request.getResourceName()`request.getPatternType()`request.getPrincipal()`request.getHost()`request.getOperation()`request.getPermission());" is 236.,152
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,createAcl,Long Statement,The length of the statement "AsyncResponseBuilder.from(Response.status(Status.CREATED).location(URI.create(urlFactory.newUrlBuilder().appendPathSegment("v3").appendPathSegment("clusters").appendPathSegment(clusterId).appendPathSegment("acls").putQueryParameter("resource_type"`request.getResourceType().name()).putQueryParameter("resource_name"`request.getResourceName()).putQueryParameter("pattern_type"`request.getPatternType().name()).putQueryParameter("principal"`request.getPrincipal()).putQueryParameter("host"`request.getHost()).putQueryParameter("operation"`request.getOperation().name()).putQueryParameter("permission"`request.getPermission().name()).build()))).entity(response).asyncResume(asyncResponse);" is 686.,152
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,deleteAcls,Long Parameter List,The method has 9 parameters. ,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,deleteAcls,Long Statement,The length of the statement "CompletableFuture<DeleteAclsResponse> response=aclManager.get().deleteAcls(clusterId`resourceType`resourceName.isEmpty() ? null : resourceName`patternType`principal.isEmpty() ? null : principal`host.isEmpty() ? null : host`operation`permission).thenApply(acls -> DeleteAclsResponse.create(acls.stream().map(this::toAclData).sorted(Comparator.comparing(AclData::getResourceType).thenComparing(AclData::getResourceName).thenComparing(AclData::getPatternType).thenComparing(AclData::getPrincipal).thenComparing(AclData::getHost).thenComparing(AclData::getOperation).thenComparing(AclData::getPermission)).collect(Collectors.toList())));" is 633.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResource,toAclData,Long Statement,The length of the statement "return AclData.fromAcl(acl).setMetadata(Resource.Metadata.builder().setSelf(urlFactory.newUrlBuilder().appendPathSegment("v3").appendPathSegment("clusters").appendPathSegment(acl.getClusterId()).appendPathSegment("acls").putQueryParameter("resource_type"`acl.getResourceType().name()).putQueryParameter("resource_name"`acl.getResourceName()).putQueryParameter("pattern_type"`acl.getPatternType().name()).putQueryParameter("principal"`acl.getPrincipal()).putQueryParameter("host"`acl.getHost()).putQueryParameter("operation"`acl.getOperation().name()).putQueryParameter("permission"`acl.getPermission().name()).build()).build()).build();" is 636.,272
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,newTopicData,Long Statement,The length of the statement "return TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(String.format("/v3/clusters/cluster-1/topics/%s"`topicName)).setResourceName(String.format("crn:///kafka=cluster-1/topic=%s"`topicName)).build()).setClusterId("cluster-1").setTopicName(topicName).setInternal(isInternal).setReplicationFactor(replicationFactor).setPartitions(Resource.Relationship.create(String.format("/v3/clusters/cluster-1/topics/%s/partitions"`topicName))).setConfigs(Resource.Relationship.create(String.format("/v3/clusters/cluster-1/topics/%s/configs"`topicName))).setPartitionReassignments(Resource.Relationship.create(String.format("/v3/clusters/cluster-1/topics/%s/partitions/-/reassignment"`topicName))).setPartitionsCount(partitionsCount).setAuthorizedOperations(emptySet()).build();" is 784.,332
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Long Statement,The length of the statement "ListTopicsResponse expected=ListTopicsResponse.create(TopicDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics").build()).setData(Arrays.asList(newTopicData("topic-1"`true`3`3)`newTopicData("topic-2"`true`3`3)`newTopicData("topic-3"`false`3`3))).build());" is 311.,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Magic Number,The method contains a magic number: 3,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Magic Number,The method contains a magic number: 3,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Magic Number,The method contains a magic number: 3,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Magic Number,The method contains a magic number: 3,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Magic Number,The method contains a magic number: 3,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,listTopics_existingCluster_returnsTopics,Magic Number,The method contains a magic number: 3,368
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,getTopics_existingCluster_returnsTopic,Long Statement,The length of the statement "expect(topicManager.getTopic(TOPIC_1.getClusterId()`TOPIC_1.getName()`false)).andReturn(completedFuture(Optional.of(TOPIC_1)));" is 127.,418
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,getTopics_existingCluster_returnsTopic,Magic Number,The method contains a magic number: 3,418
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,getTopics_existingCluster_returnsTopic,Magic Number,The method contains a magic number: 3,418
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,getTopics_existingCluster_nonExistingTopic_throwsNotFound,Long Statement,The length of the statement "expect(topicManager.getTopic(TOPIC_1.getClusterId()`TOPIC_1.getName()`false)).andReturn(completedFuture(Optional.empty()));" is 123.,444
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_createsTopic,Long Statement,The length of the statement "expect(topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.of(TOPIC_1.getReplicationFactor())`Collections.emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact")))).andReturn(completedFuture(null));" is 261.,456
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_createsTopic,Long Statement,The length of the statement "topicsResource.createTopic(response`TOPIC_1.getClusterId()`CreateTopicRequest.builder().setTopicName(TOPIC_1.getName()).setPartitionsCount(TOPIC_1.getPartitions().size()).setReplicationFactor(TOPIC_1.getReplicationFactor()).setConfigs(singletonList(CreateTopicRequest.ConfigEntry.create("cleanup.policy"`"compact"))).build());" is 326.,456
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_createsTopic,Magic Number,The method contains a magic number: 3,456
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_defaultPartitionsCount_createsTopic,Long Statement,The length of the statement "expect(topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.empty()`Optional.of(TOPIC_1.getReplicationFactor())`Collections.emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact")))).andReturn(completedFuture(null));" is 234.,486
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_defaultPartitionsCount_createsTopic,Long Statement,The length of the statement "topicsResource.createTopic(response`TOPIC_1.getClusterId()`CreateTopicRequest.builder().setTopicName(TOPIC_1.getName()).setReplicationFactor(TOPIC_1.getReplicationFactor()).setConfigs(singletonList(CreateTopicRequest.ConfigEntry.create("cleanup.policy"`"compact"))).build());" is 275.,486
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_defaultPartitionsCount_createsTopic,Magic Number,The method contains a magic number: 3,486
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_defaultReplicationFactor_createsTopic,Long Statement,The length of the statement "expect(topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.empty()`Collections.emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact")))).andReturn(completedFuture(null));" is 234.,515
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_defaultReplicationFactor_createsTopic,Long Statement,The length of the statement "topicsResource.createTopic(response`TOPIC_1.getClusterId()`CreateTopicRequest.builder().setTopicName(TOPIC_1.getName()).setPartitionsCount(TOPIC_1.getPartitions().size()).setConfigs(singletonList(CreateTopicRequest.ConfigEntry.create("cleanup.policy"`"compact"))).build());" is 273.,515
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_customReplicasAssignments_createsTopic,Long Statement,The length of the statement "expect(topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.empty()`Optional.empty()`replicasAssignments`singletonMap("cleanup.policy"`Optional.of("compact")))).andReturn(completedFuture(null));" is 204.,544
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingTopic_customReplicasAssignments_createsTopic,Long Statement,The length of the statement "topicsResource.createTopic(response`TOPIC_1.getClusterId()`CreateTopicRequest.builder().setTopicName(TOPIC_1.getName()).setReplicasAssignments(replicasAssignments).setConfigs(singletonList(CreateTopicRequest.ConfigEntry.create("cleanup.policy"`"compact"))).build());" is 266.,544
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_existingTopic_throwsTopicExists,Long Statement,The length of the statement "expect(topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.of(TOPIC_1.getReplicationFactor())`Collections.emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact")))).andReturn(failedFuture(new TopicExistsException("")));" is 282.,587
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_existingTopic_throwsTopicExists,Long Statement,The length of the statement "topicsResource.createTopic(response`TOPIC_1.getClusterId()`CreateTopicRequest.builder().setTopicName(TOPIC_1.getName()).setPartitionsCount(TOPIC_1.getPartitions().size()).setReplicationFactor(TOPIC_1.getReplicationFactor()).setConfigs(singletonList(CreateTopicRequest.ConfigEntry.create("cleanup.policy"`"compact"))).build());" is 326.,587
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.of(TOPIC_1.getReplicationFactor())`Collections.emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact")))).andReturn(failedFuture(new NotFoundException()));" is 277.,615
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,createTopic_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "topicsResource.createTopic(response`TOPIC_1.getClusterId()`CreateTopicRequest.builder().setTopicName(TOPIC_1.getName()).setPartitionsCount(TOPIC_1.getPartitions().size()).setReplicationFactor(TOPIC_1.getReplicationFactor()).setConfigs(singletonList(CreateTopicRequest.ConfigEntry.create("cleanup.policy"`"compact"))).build());" is 326.,615
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicsResourceTest,deleteTopic_nonExistingTopic_throwsUnknownTopicOfPartitionException,Long Statement,The length of the statement "expect(topicManager.deleteTopic(CLUSTER_ID`TOPIC_1.getName())).andReturn(failedFuture(new UnknownTopicOrPartitionException("")));" is 129.,657
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,setUp,Long Statement,The length of the statement "clusterConfigsResource=new ClusterConfigsResource(() -> clusterConfigManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 122.,94
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,listClusterConfigs_existingCluster_returnsConfigs,Long Statement,The length of the statement "expect(clusterConfigManager.listClusterConfigs(CLUSTER_ID`ClusterConfig.Type.BROKER)).andReturn(completedFuture(Arrays.asList(CONFIG_1`CONFIG_2`CONFIG_3)));" is 156.,103
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,listClusterConfigs_existingCluster_returnsConfigs,Long Statement,The length of the statement "ListClusterConfigsResponse expected=ListClusterConfigsResponse.create(ClusterConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/broker-configs").build()).setData(Arrays.asList(ClusterConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/broker-configs/config-1").setResourceName("crn:///kafka=cluster-1/broker-config=config-1").build()).setClusterId(CLUSTER_ID).setConfigType(ClusterConfig.Type.BROKER).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`ClusterConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/broker-configs/config-2").setResourceName("crn:///kafka=cluster-1/broker-config=config-2").build()).setClusterId(CLUSTER_ID).setConfigType(ClusterConfig.Type.BROKER).setName(CONFIG_2.getName()).setValue(CONFIG_2.getValue()).setDefault(CONFIG_2.isDefault()).setReadOnly(CONFIG_2.isReadOnly()).setSensitive(CONFIG_2.isSensitive()).setSource(CONFIG_2.getSource()).setSynonyms(CONFIG_2.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`ClusterConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/broker-configs/config-3").setResourceName("crn:///kafka=cluster-1/broker-config=config-3").build()).setClusterId(CLUSTER_ID).setConfigType(ClusterConfig.Type.BROKER).setName(CONFIG_3.getName()).setValue(CONFIG_3.getValue()).setDefault(CONFIG_3.isDefault()).setReadOnly(CONFIG_3.isReadOnly()).setSensitive(CONFIG_3.isSensitive()).setSource(CONFIG_3.getSource()).setSynonyms(CONFIG_3.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build())).build());" is 1998.,103
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,listClusterConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(clusterConfigManager.listClusterConfigs(CLUSTER_ID`ClusterConfig.Type.BROKER)).andReturn(failedFuture(new NotFoundException()));" is 135.,186
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,getClusterConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(clusterConfigManager.getClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName())).andReturn(completedFuture(Optional.of(CONFIG_1)));" is 153.,198
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,getClusterConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "GetClusterConfigResponse expected=GetClusterConfigResponse.create(ClusterConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/broker-configs/config-1").setResourceName("crn:///kafka=cluster-1/broker-config=config-1").build()).setClusterId(CLUSTER_ID).setConfigType(ClusterConfig.Type.BROKER).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build());" is 652.,198
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,getClusterConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(clusterConfigManager.getClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 152.,234
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,getClusterConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(clusterConfigManager.getClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 152.,249
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,updateClusterConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(clusterConfigManager.upsertClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName()`"new-value")).andReturn(completedFuture(null));" is 151.,264
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,updateClusterConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "clusterConfigsResource.upsertClusterConfig(response`CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName()`UpdateClusterConfigRequest.create("new-value"));" is 156.,264
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,updateConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(clusterConfigManager.upsertClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName()`"new-value")).andReturn(failedFuture(new NotFoundException()));" is 167.,284
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,updateConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "clusterConfigsResource.upsertClusterConfig(response`CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName()`UpdateClusterConfigRequest.create("new-value"));" is 156.,284
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,resetClusterConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(clusterConfigManager.deleteClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName())).andReturn(completedFuture(null));" is 139.,303
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClusterConfigResourceTest,resetClusterConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(clusterConfigManager.deleteClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 155.,320
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoSchemaRegistryDefined,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,94
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoSchemaRegistryDefined,Long Statement,The length of the statement "ProduceAction produceAction=getProduceAction(properties`chunkedOutputFactory`1`countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider`true);" is 177.,94
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoSchemaRegistryDefined,Long Statement,The length of the statement "ErrorResponse err=ErrorResponse.create(422`"Error: 42206 : Payload error. Schema Registry must be configured when using" + " schemas.");" is 136.,94
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoSchemaRegistryDefined,Magic Number,The method contains a magic number: 999999999,94
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoSchemaRegistryDefined,Magic Number,The method contains a magic number: 422,94
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Long Identifier,The length of the identifier totalNumberOfProduceCallsProd1 is 30.,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Long Statement,The length of the statement "ProduceAction produceAction1=getProduceAction(properties`chunkedOutputFactory`totalNumberOfStreamingCalls`countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 199.,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 4,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 10000,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 999999999,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 3600000,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 4,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 2,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,streamingRequests,Magic Number,The method contains a magic number: 3,174
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Long Statement,The length of the statement "ProduceAction produceAction=getProduceAction(properties`chunkedOutputFactory`1`countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 172.,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Long Statement,The length of the statement "ErrorResponse err=ErrorResponse.create(429`"Request rate limit exceeded: " + "The rate limit of requests per second has been exceeded.");" is 137.,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Long Statement,The length of the statement "verify(requests`mockedChunkedOutput`countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 153.,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Magic Number,The method contains a magic number: 2,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Magic Number,The method contains a magic number: 30,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithByteLimit,Magic Number,The method contains a magic number: 429,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Long Statement,The length of the statement "ProduceAction produceAction=getProduceAction(properties`chunkedOutputFactory`1`countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 172.,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Long Statement,The length of the statement "ErrorResponse err=ErrorResponse.create(429`"Request rate limit exceeded: " + "The rate limit of requests per second has been exceeded.");" is 137.,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Long Statement,The length of the statement "verify(requests`mockedChunkedOutput`countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 153.,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Magic Number,The method contains a magic number: 2,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Magic Number,The method contains a magic number: 30,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceWithCountLimit,Magic Number,The method contains a magic number: 429,385
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoLimit,Long Statement,The length of the statement "replay(countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 178.,487
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoLimit,Long Statement,The length of the statement "ProduceAction produceAction=getProduceAction(properties`chunkedOutputFactory`2`countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 172.,487
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoLimit,Long Statement,The length of the statement "verify(requests`mockedChunkedOutput`countLimitProvider`bytesLimitProvider`rateLimiterForCount`rateLimiterForBytes`countLimiterGlobal`bytesLimiterGlobal);" is 153.,487
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoLimit,Magic Number,The method contains a magic number: 2,487
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoLimit,Magic Number,The method contains a magic number: 30,487
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,produceNoLimit,Magic Number,The method contains a magic number: 2,487
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,testHasNextOnNullData,Long Statement,The length of the statement "ProduceAction produceAction=getProduceAction(properties`chunkedOutputFactory`1`countLimitProvider`bytesLimitProvider`countLimiterGlobalProvider`bytesLimiterGlobalProvider);" is 172.,570
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,testHasNextOnNullData,Long Statement,The length of the statement "RestConstraintViolationException e=assertThrows(RestConstraintViolationException.class`() -> produceAction.produce(fakeAsyncResponse`"clusterId"`"topicName"`null));" is 164.,570
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,testHasNextOnNullData,Magic Number,The method contains a magic number: 30,570
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,testHasNextOnNullData,Magic Number,The method contains a magic number: 42206,570
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getRecordSerializerProvider,Long Statement,The length of the statement "expect(recordSerializer.serialize(anyObject()`anyObject()`anyObject()`anyObject()`anyBoolean())).andReturn(Optional.empty()).anyTimes();" is 136.,620
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getRecordSerializerProvider,Long Statement,The length of the statement "expect(recordSerializer.serialize(anyObject()`anyObject()`anyObject()`anyObject()`anyBoolean())).andThrow(Errors.messageSerializationException("Schema Registry not defined` " + "no Schema Registry client available to deserialize message.")).anyTimes();" is 252.,620
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceRequestsMappingIterator,Magic Number,The method contains a magic number: 25L,653
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceRequestsMappingIteratorWithSchemaNeeded,Long Statement,The length of the statement "ProduceRequestData key=ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setData(TextNode.valueOf("bob")).setRawSchema("bob").build();" is 144.,667
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceRequestsMappingIteratorWithSchemaNeeded,Magic Number,The method contains a magic number: 25L,667
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getStreamingProduceRequestsMappingIterator,Magic Number,The method contains a magic number: 25L,688
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceResponse,Long Statement,The length of the statement "return ProduceResponse.builder().setClusterId("clusterId").setTopicName("topicName").setPartitionId(partitionId).setOffset(offset).setTimestamp(Instant.ofEpochMilli(0)).setErrorCode(HttpStatus.OK_200).build();" is 209.,719
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,setupExpectsMockCallsForProduce,Long Statement,The length of the statement "expect((produceController.produce(anyObject()`anyObject()`anyObject()`anyObject()`anyObject()`anyObject()`anyObject()))).andReturn(response);" is 141.,750
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Parameter List,The method has 7 parameters. ,767
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Statement,The length of the statement "return getProduceAction(properties`chunkedOutputFactory`times`countLimiter`bytesLimiter`countLimiterGlobal`bytesLimiterGlobal`false);" is 133.,767
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Parameter List,The method has 8 parameters. ,786
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Statement,The length of the statement "return getProduceAction(new ProduceRateLimiters(countLimiter`bytesLimiter`countLimiterGlobal`bytesLimiterGlobal`Boolean.parseBoolean(properties.getProperty(PRODUCE_RATE_LIMIT_ENABLED))`Duration.ofMillis(Integer.parseInt(properties.getProperty(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))))`chunkedOutputFactory`times`0`errorSchemaRegistry);" is 332.,786
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Parameter List,The method has 5 parameters. ,810
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Statement,The length of the statement "expect(schemaManagerMock.getSchema("topicName"`Optional.of(EmbeddedFormat.AVRO)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("bob")`true)).andThrow(Errors.invalidPayloadException("Schema Registry must be configured when using schemas."));" is 273.,810
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Statement,The length of the statement "StreamingResponseFactory streamingResponseFactory=new StreamingResponseFactory(chunkedOutputFactory`FIVE_SECONDS_MS`FIVE_SECONDS_MS);" is 133.,810
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProduceActionTest,getProduceAction,Long Statement,The length of the statement "ProduceAction produceAction=new ProduceAction(schemaManagerProvider`recordSerializerProvider`produceControllerProvider`() -> new ProducerMetrics(kafkaRestConfig`emptyMap())`streamingResponseFactory`produceRateLimiters`executorService);" is 235.,810
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterTopicConfigBatchActionTest,alterTopicConfigs_existingConfig_alterConfigs,Long Statement,The length of the statement "expect(topicConfigManager.alterTopicConfigs(CLUSTER_ID`TOPIC_NAME`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"newValue")`AlterConfigCommand.delete(CONFIG_2.getName())))).andReturn(completedFuture(null));" is 216.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterTopicConfigBatchActionTest,alterTopicConfigs_existingConfig_alterConfigs,Long Statement,The length of the statement "alterTopicConfigBatchAction.alterTopicConfigBatch(response`CLUSTER_ID`TOPIC_NAME`AlterTopicConfigBatchRequest.create(AlterConfigBatchRequestData.create(Arrays.asList(AlterEntry.builder().setName(CONFIG_1.getName()).setValue("newValue").build()`AlterEntry.builder().setName(CONFIG_2.getName()).setOperation(AlterOperation.DELETE).build()))));" is 341.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterTopicConfigBatchActionTest,alterTopicConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(topicConfigManager.alterTopicConfigs(CLUSTER_ID`TOPIC_NAME`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"newValue")`AlterConfigCommand.delete(CONFIG_2.getName())))).andReturn(failedFuture(new NotFoundException()));" is 232.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterTopicConfigBatchActionTest,alterTopicConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "alterTopicConfigBatchAction.alterTopicConfigBatch(response`CLUSTER_ID`TOPIC_NAME`AlterTopicConfigBatchRequest.create(AlterConfigBatchRequestData.create(Arrays.asList(AlterEntry.builder().setName(CONFIG_1.getName()).setValue("newValue").build()`AlterEntry.builder().setName(CONFIG_2.getName()).setOperation(AlterOperation.DELETE).build()))));" is 341.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,setUp,Long Statement,The length of the statement "Metrics metrics=new Metrics(new MetricConfig().samples(config.getInt(RestConfig.METRICS_NUM_SAMPLES_CONFIG)).timeWindow(config.getLong(RestConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG)`TimeUnit.MILLISECONDS).recordLevel(Sensor.RecordingLevel.INFO)`singletonList(reporter)`Time.SYSTEM`config.getMetricsContext());" is 306.,53
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testAvgMetrics,Magic Number,The method contains a magic number: 10L,81
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testAvgMetrics,Magic Number,The method contains a magic number: 4.5,81
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testRateMetrics,Long Statement,The length of the statement "String[] rateMetrics=new String[]{ProducerMetrics.RECORD_ERROR_RATE_METRIC_NAME`ProducerMetrics.REQUEST_RATE_METRIC_NAME`ProducerMetrics.RESPONSE_RATE_METRIC_NAME};" is 164.,96
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testRateMetrics,Magic Number,The method contains a magic number: 30,96
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testRateMetrics,Magic Number,The method contains a magic number: 0.01,96
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testMaxMetrics,Magic Number,The method contains a magic number: 10L,127
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testMaxMetrics,Magic Number,The method contains a magic number: 9.0,127
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testPercentileMetrics,Long Statement,The length of the statement "String[] percentileMetrics=new String[]{ProducerMetrics.REQUEST_LATENCY_PCT_METRIC_PREFIX + "p95"`ProducerMetrics.REQUEST_LATENCY_PCT_METRIC_PREFIX + "p99"`ProducerMetrics.REQUEST_LATENCY_PCT_METRIC_PREFIX + "p999"};" is 216.,142
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testPercentileMetrics,Magic Number,The method contains a magic number: 1000L,142
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testPercentileMetrics,Magic Number,The method contains a magic number: 9.0,142
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testWindowedCountMetrics,Long Statement,The length of the statement "String[] maxMetrics=new String[]{ProducerMetrics.REQUEST_COUNT_WINDOWED_METRIC_NAME`ProducerMetrics.RECORD_ERROR_COUNT_WINDOWED_METRIC_NAME`ProducerMetrics.RESPONSE_COUNT_WINDOWED_METRIC_NAME};" is 193.,162
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testWindowedCountMetrics,Magic Number,The method contains a magic number: 10,162
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testWindowedCountMetrics,Magic Number,The method contains a magic number: 10.0,162
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testMeterBasedMetrics,Magic Number,The method contains a magic number: 30,189
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testMeterBasedMetrics,Magic Number,The method contains a magic number: 30.0,189
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ProducerMetricsTest,testMeterBasedMetrics,Magic Number,The method contains a magic number: 0.01,189
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResourceTest,listClusters_returnsArrayWithOwnClusters,Long Statement,The length of the statement "ListClustersResponse expected=ListClustersResponse.create(ClusterDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters").build()).setData(singletonList(ClusterData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1").setResourceName("crn:///kafka=cluster-1").build()).setClusterId("cluster-1").setController(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1")).setAcls(Resource.Relationship.create("/v3/clusters/cluster-1/acls")).setBrokers(Resource.Relationship.create("/v3/clusters/cluster-1/brokers")).setBrokerConfigs(Resource.Relationship.create("/v3/clusters/cluster-1/broker-configs")).setConsumerGroups(Resource.Relationship.create("/v3/clusters/cluster-1/consumer-groups")).setTopics(Resource.Relationship.create("/v3/clusters/cluster-1/topics")).setPartitionReassignments(Resource.Relationship.create("/v3/clusters/cluster-1/topics/-/partitions/-/reassignment")).build())).build());" is 973.,69
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResourceTest,getCluster_ownCluster_returnsCluster,Long Statement,The length of the statement "expect(clusterManager.getCluster(CLUSTER_1.getClusterId())).andReturn(CompletableFuture.completedFuture(Optional.of(CLUSTER_1)));" is 129.,124
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ClustersResourceTest,getCluster_ownCluster_returnsCluster,Long Statement,The length of the statement "GetClusterResponse expected=GetClusterResponse.create(ClusterData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1").setResourceName("crn:///kafka=cluster-1").build()).setClusterId("cluster-1").setController(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1")).setAcls(Resource.Relationship.create("/v3/clusters/cluster-1/acls")).setBrokers(Resource.Relationship.create("/v3/clusters/cluster-1/brokers")).setBrokerConfigs(Resource.Relationship.create("/v3/clusters/cluster-1/broker-configs")).setConsumerGroups(Resource.Relationship.create("/v3/clusters/cluster-1/consumer-groups")).setTopics(Resource.Relationship.create("/v3/clusters/cluster-1/topics")).setPartitionReassignments(Resource.Relationship.create("/v3/clusters/cluster-1/topics/-/partitions" + "/-/reassignment")).build());" is 833.,124
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "expect(brokerConfigManager.listBrokerConfigs(CLUSTER_ID`BROKER_ID)).andReturn(completedFuture(Arrays.asList(CONFIG_1`CONFIG_2`CONFIG_3)));" is 138.,104
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "ListBrokerConfigsResponse expected=ListBrokerConfigsResponse.create(BrokerConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs").build()).setData(Arrays.asList(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-1").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-1").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-2").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-2").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_2.getName()).setValue(CONFIG_2.getValue()).setDefault(CONFIG_2.isDefault()).setReadOnly(CONFIG_2.isReadOnly()).setSensitive(CONFIG_2.isSensitive()).setSource(CONFIG_2.getSource()).setSynonyms(CONFIG_2.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-3").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-3").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_3.getName()).setValue(CONFIG_3.getValue()).setDefault(CONFIG_3.isDefault()).setReadOnly(CONFIG_3.isReadOnly()).setSensitive(CONFIG_3.isSensitive()).setSource(CONFIG_3.getSource()).setSynonyms(CONFIG_3.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build())).build());" is 1956.,104
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,getBrokerConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(brokerConfigManager.getBrokerConfig(CLUSTER_ID`BROKER_ID`CONFIG_1.getName())).andReturn(completedFuture(Optional.of(CONFIG_1)));" is 135.,199
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,getBrokerConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "GetBrokerConfigResponse expected=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-1").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-1").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build());" is 636.,199
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,getBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(brokerConfigManager.getBrokerConfig(CLUSTER_ID`BROKER_ID`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 134.,232
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,getBrokerConfig_nonExistingBrokerorCluster_throwsNotFound,Long Statement,The length of the statement "expect(brokerConfigManager.getBrokerConfig(CLUSTER_ID`BROKER_ID`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 134.,244
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,updateBrokerConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(brokerConfigManager.updateBrokerConfig(CLUSTER_ID`BROKER_ID`CONFIG_1.getName()`"new-value")).andReturn(completedFuture(null));" is 133.,256
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,updateBrokerConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "brokerConfigsResource.updateBrokerConfig(response`CLUSTER_ID`BROKER_ID`CONFIG_1.getName()`UpdateBrokerConfigRequest.create("new-value"));" is 137.,256
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,updateConfig_nonExistingConfigOrBrokerOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(brokerConfigManager.updateBrokerConfig(CLUSTER_ID`BROKER_ID`CONFIG_1.getName()`"new-value")).andReturn(failedFuture(new NotFoundException()));" is 149.,276
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,updateConfig_nonExistingConfigOrBrokerOrCluster_throwsNotFound,Long Statement,The length of the statement "brokerConfigsResource.updateBrokerConfig(response`CLUSTER_ID`BROKER_ID`CONFIG_1.getName()`UpdateBrokerConfigRequest.create("new-value"));" is 137.,276
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokerConfigResourceTest,resetBrokerConfig_nonExistingConfigOrBrokerOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(brokerConfigManager.resetBrokerConfig(CLUSTER_ID`BROKER_ID`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 136.,309
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResourceTest,setUp,Long Statement,The length of the statement "consumerAssignmentsResource=new ConsumerAssignmentsResource(() -> consumerAssignmentManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 137.,80
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResourceTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "expect(consumerAssignmentManager.listConsumerAssignments(CLUSTER_ID`CONSUMER_GROUP_ID`CONSUMER_ID)).andReturn(completedFuture(Arrays.asList(CONSUMER_ASSIGNMENT_1`CONSUMER_ASSIGNMENT_2`CONSUMER_ASSIGNMENT_3)));" is 209.,87
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResourceTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "ListConsumerAssignmentsResponse expected=ListConsumerAssignmentsResponse.create(ConsumerAssignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1/assignments").build()).setData(Arrays.asList(ConsumerAssignmentData.fromConsumerAssignment(CONSUMER_ASSIGNMENT_1).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1" + "/assignments/topic-1/partitions/1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-1" + "/assignment=topic-1/partition=1").build()).setPartition(Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1")).setLag(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lags" + "/topic-1/partitions/1")).build()`ConsumerAssignmentData.fromConsumerAssignment(CONSUMER_ASSIGNMENT_2).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1" + "/assignments/topic-2/partitions/2").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-1" + "/assignment=topic-2/partition=2").build()).setPartition(Relationship.create("/v3/clusters/cluster-1/topics/topic-2/partitions/2")).setLag(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lags" + "/topic-2/partitions/2")).build()`ConsumerAssignmentData.fromConsumerAssignment(CONSUMER_ASSIGNMENT_3).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1" + "/assignments/topic-3/partitions/3").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-1" + "/assignment=topic-3/partition=3").build()).setPartition(Relationship.create("/v3/clusters/cluster-1/topics/topic-3/partitions/3")).setLag(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lags" + "/topic-3/partitions/3")).build())).build());" is 2108.,87
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResourceTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "expect(consumerAssignmentManager.getConsumerAssignment(CLUSTER_ID`CONSUMER_GROUP_ID`CONSUMER_ID`"topic-1"`1)).andReturn(completedFuture(Optional.of(CONSUMER_ASSIGNMENT_1)));" is 173.,178
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResourceTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "GetConsumerAssignmentResponse expected=GetConsumerAssignmentResponse.create(ConsumerAssignmentData.fromConsumerAssignment(CONSUMER_ASSIGNMENT_1).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1" + "/assignments/topic-1/partitions/1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-1" + "/assignment=topic-1/partition=1").build()).setPartition(Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1")).setLag(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lags" + "/topic-1/partitions/1")).build());" is 675.,178
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerAssignmentsResourceTest,getConsumer_nonExistingConsumer_throwsNotFound,Long Statement,The length of the statement "expect(consumerAssignmentManager.getConsumerAssignment(CLUSTER_ID`CONSUMER_GROUP_ID`CONSUMER_ID`"topic-1"`1)).andReturn(completedFuture(Optional.empty()));" is 155.,215
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,setUp,Long Identifier,The length of the field consumerGroupLagSummariesResource is 33.,64
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,setUp,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,64
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,setUp,Long Statement,The length of the statement "consumerGroupLagSummariesResource=new ConsumerGroupLagSummariesResource(() -> consumerGroupLagSummaryManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 154.,64
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,71
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Identifier,The length of the field consumerGroupLagSummariesResource is 33.,71
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "expect(consumerGroupLagSummaryManager.getConsumerGroupLagSummary(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.of(CONSUMER_GROUP_LAG_1)));" is 158.,71
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "GetConsumerGroupLagSummaryResponse expected=GetConsumerGroupLagSummaryResponse.create(ConsumerGroupLagSummaryData.fromConsumerGroupLagSummary(CONSUMER_GROUP_LAG_1).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lag-summary").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1/lag-summary").build()).setMaxLagConsumer(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/" + "consumers/consumer-1")).setMaxLagPartition(Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1")).build());" is 605.,71
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_nonExistingConsumerGroupLagSummary_throwsNotFound,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,102
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_nonExistingConsumerGroupLagSummary_throwsNotFound,Long Identifier,The length of the field consumerGroupLagSummariesResource is 33.,102
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupLagSummariesResourceTest,getConsumerGroupLagSummary_nonExistingConsumerGroupLagSummary_throwsNotFound,Long Statement,The length of the statement "expect(consumerGroupLagSummaryManager.getConsumerGroupLagSummary(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.empty()));" is 141.,102
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResourceTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(partitionManager.listPartitions(CLUSTER_ID`TOPIC_NAME)).andReturn(CompletableFuture.completedFuture(Arrays.asList(PARTITION_1`PARTITION_2`PARTITION_3)));" is 160.,146
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResourceTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "ListPartitionsResponse expected=ListPartitionsResponse.create(PartitionDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions").build()).setData(Arrays.asList(PartitionData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=0").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_1.getPartitionId()).setLeader(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/0" + "/replicas/1")).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/0/replicas")).setReassignment(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/0" + "/reassignment")).build()`PartitionData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_2.getPartitionId()).setLeader(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1" + "/replicas/2")).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1/replicas")).setReassignment(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1" + "/reassignment")).build()`PartitionData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/2").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=2").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_3.getPartitionId()).setLeader(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/2" + "/replicas/3")).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/2/replicas")).setReassignment(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/2/reassignment")).build())).build());" is 2154.,146
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResourceTest,getPartition_existingPartition_returnsPartition,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_1.getPartitionId())).andReturn(CompletableFuture.completedFuture(Optional.of(PARTITION_1)));" is 161.,248
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResourceTest,getPartition_existingPartition_returnsPartition,Long Statement,The length of the statement "GetPartitionResponse expected=GetPartitionResponse.create(PartitionData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=0").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_1.getPartitionId()).setLeader(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/0/replicas/1")).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/0/replicas")).setReassignment(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/0/reassignment")).build());" is 688.,248
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResourceTest,getPartition_nonExistingPartition_throwsNotFound,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_1.getPartitionId())).andReturn(CompletableFuture.completedFuture(Optional.empty()));" is 153.,282
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,PartitionsResourceTest,getPartition_nonExistingTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_1.getPartitionId())).andReturn(failedFuture(new NotFoundException()));" is 139.,294
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResourceTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "ListConsumerLagsResponse expected=ListConsumerLagsResponse.create(ConsumerLagDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lags").build()).setData(Arrays.asList(ConsumerLagData.fromConsumerLag(CONSUMER_LAG_2).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/" + "lags/topic-1/partitions/2").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1/" + "lag=topic-1/partition=2").build()).build()`ConsumerLagData.fromConsumerLag(CONSUMER_LAG_1).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/" + "lags/topic-1/partitions/1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1/" + "lag=topic-1/partition=1").build()).build())).build());" is 872.,91
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResourceTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "expect(consumerLagManager.getConsumerLag(CLUSTER_ID`CONSUMER_GROUP_ID`TOPIC`1)).andReturn(completedFuture(Optional.of(CONSUMER_LAG_1)));" is 136.,136
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResourceTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "GetConsumerLagResponse expected=GetConsumerLagResponse.create(ConsumerLagData.fromConsumerLag(CONSUMER_LAG_1).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/" + "lags/topic-1/partitions/1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1/" + "lag=topic-1/partition=1").build()).build());" is 369.,136
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerLagsResourceTest,getConsumerLag_nonExistingConsumerLag_throwsNotFound,Long Statement,The length of the statement "expect(consumerLagManager.getConsumerLag(CLUSTER_ID`CONSUMER_GROUP_ID`TOPIC`1)).andReturn(completedFuture(Optional.empty()));" is 125.,162
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResourceTest,listBrokers_existingCluster_returnsBrokers,Long Statement,The length of the statement "expect(brokerManager.listBrokers(CLUSTER_ID)).andReturn(CompletableFuture.completedFuture(Arrays.asList(BROKER_1`BROKER_2`BROKER_3)));" is 134.,66
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResourceTest,listBrokers_existingCluster_returnsBrokers,Long Statement,The length of the statement "ListBrokersResponse expected=ListBrokersResponse.create(BrokerDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers").build()).setData(Arrays.asList(BrokerData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1").setResourceName("crn:///kafka=cluster-1/broker=1").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_1.getBrokerId()).setHost(BROKER_1.getHost()).setPort(BROKER_1.getPort()).setRack(BROKER_1.getRack()).setConfigs(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1/configs")).setPartitionReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1/partition-replicas")).build()`BrokerData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/2").setResourceName("crn:///kafka=cluster-1/broker=2").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_2.getBrokerId()).setHost(BROKER_2.getHost()).setPort(BROKER_2.getPort()).setRack(BROKER_2.getRack()).setConfigs(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/2/configs")).setPartitionReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/2/partition-replicas")).build()`BrokerData.builder().setMetadata(Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/3").setResourceName("crn:///kafka=cluster-1/broker=3").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_3.getBrokerId()).setHost(BROKER_3.getHost()).setPort(BROKER_3.getPort()).setRack(BROKER_3.getRack()).setConfigs(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/3/configs")).setPartitionReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/3/partition-replicas")).build())).build());" is 1733.,66
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResourceTest,getBroker_existingClusterExistingBroker_returnsBroker,Long Statement,The length of the statement "expect(brokerManager.getBroker(CLUSTER_ID`BROKER_1.getBrokerId())).andReturn(CompletableFuture.completedFuture(Optional.of(BROKER_1)));" is 135.,154
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResourceTest,getBroker_existingClusterExistingBroker_returnsBroker,Long Statement,The length of the statement "GetBrokerResponse expected=GetBrokerResponse.create(BrokerData.builder().setMetadata(Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1").setResourceName("crn:///kafka=cluster-1/broker=1").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_1.getBrokerId()).setHost(BROKER_1.getHost()).setPort(BROKER_1.getPort()).setRack(BROKER_1.getRack()).setConfigs(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1/configs")).setPartitionReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1/partition-replicas")).build());" is 553.,154
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResourceTest,getBroker_existingClusterNonExistingBroker_throwsNotFound,Magic Number,The method contains a magic number: 4,197
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,BrokersResourceTest,getBroker_existingClusterNonExistingBroker_throwsNotFound,Magic Number,The method contains a magic number: 4,197
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResourceTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "expect(consumerManager.listConsumers(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId())).andReturn(completedFuture(Arrays.asList(CONSUMERS)));" is 139.,157
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResourceTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "ListConsumersResponse expected=ListConsumersResponse.create(ConsumerDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/consumers").build()).setData(Arrays.asList(ConsumerData.fromConsumer(CONSUMERS[0]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-1").build()).setAssignments(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1/assignments")).build()`ConsumerData.fromConsumer(CONSUMERS[1]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-2").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-2").build()).setAssignments(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-2/assignments")).build()`ConsumerData.fromConsumer(CONSUMERS[2]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-3").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-3").build()).setAssignments(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-3/assignments")).build())).build());" is 1522.,157
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResourceTest,listConsumers_returnsConsumers,Magic Number,The method contains a magic number: 2,157
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResourceTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId()`CONSUMERS[0].getConsumerId())).andReturn(completedFuture(Optional.of(CONSUMERS[0])));" is 167.,226
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResourceTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "GetConsumerResponse expected=GetConsumerResponse.create(ConsumerData.fromConsumer(CONSUMERS[0]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1" + "/consumer=consumer-1").build()).setAssignments(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers/consumer-1/assignments")).build());" is 479.,226
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumersResourceTest,getConsumer_nonExistingConsumer_throwsNotFound,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId()`CONSUMERS[0].getConsumerId())).andReturn(completedFuture(Optional.empty()));" is 158.,259
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterBrokerConfigBatchActionTest,alterBrokerConfigs_existingConfig_alterConfigs,Long Statement,The length of the statement "expect(brokerConfigManager.alterBrokerConfigs(CLUSTER_ID`BROKER_ID`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"newValue")`AlterConfigCommand.delete(CONFIG_2.getName())))).andReturn(completedFuture(null));" is 217.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterBrokerConfigBatchActionTest,alterBrokerConfigs_existingConfig_alterConfigs,Long Statement,The length of the statement "alterBrokerConfigBatchAction.alterBrokerConfigBatch(response`CLUSTER_ID`BROKER_ID`AlterBrokerConfigBatchRequest.create(AlterConfigBatchRequestData.create(Arrays.asList(AlterEntry.builder().setName(CONFIG_1.getName()).setValue("newValue").build()`AlterEntry.builder().setName(CONFIG_2.getName()).setOperation(AlterOperation.DELETE).build()))));" is 343.,82
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterBrokerConfigBatchActionTest,alterBrokerConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(brokerConfigManager.alterBrokerConfigs(CLUSTER_ID`BROKER_ID`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"newValue")`AlterConfigCommand.delete(CONFIG_2.getName())))).andReturn(failedFuture(new NotFoundException()));" is 233.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterBrokerConfigBatchActionTest,alterBrokerConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "alterBrokerConfigBatchAction.alterBrokerConfigBatch(response`CLUSTER_ID`BROKER_ID`AlterBrokerConfigBatchRequest.create(AlterConfigBatchRequestData.create(Arrays.asList(AlterEntry.builder().setName(CONFIG_1.getName()).setValue("newValue").build()`AlterEntry.builder().setName(CONFIG_2.getName()).setOperation(AlterOperation.DELETE).build()))));" is 343.,113
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,searchAcls_returnsMatchedAcls,Long Statement,The length of the statement "expect(aclManager.searchAcls(CLUSTER_ID`Acl.ResourceType.TOPIC`"topic-1"`Acl.PatternType.MATCH`null`null`Acl.Operation.ANY`Acl.Permission.ALLOW)).andReturn(completedFuture(Arrays.asList(ACL_1`ACL_2)));" is 201.,78
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,searchAcls_returnsMatchedAcls,Long Statement,The length of the statement "aclsResource.searchAcls(response`CLUSTER_ID`Acl.ResourceType.TOPIC`"topic-1"`Acl.PatternType.MATCH`""`""`Acl.Operation.ANY`Acl.Permission.ALLOW);" is 145.,78
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,searchAcls_returnsMatchedAcls,Long Statement,The length of the statement "SearchAclsResponse expected=SearchAclsResponse.create(AclDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/acls" + "?resource_type=TOPIC" + "&resource_name=topic-1"+ "&pattern_type=MATCH"+ "&principal="+ "&host="+ "&operation=ANY"+ "&permission=ALLOW").build()).setData(Arrays.asList(AclData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/acls" + "?resource_type=TOPIC" + "&resource_name=*"+ "&pattern_type=LITERAL"+ "&principal=User%3Aalice"+ "&host=*"+ "&operation=READ"+ "&permission=ALLOW").build()).setClusterId(CLUSTER_ID).setResourceType(Acl.ResourceType.TOPIC).setResourceName("*").setPatternType(Acl.PatternType.LITERAL).setPrincipal("User:alice").setHost("*").setOperation(Acl.Operation.READ).setPermission(Acl.Permission.ALLOW).build()`AclData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/acls" + "?resource_type=TOPIC" + "&resource_name=topic-"+ "&pattern_type=PREFIXED"+ "&principal=User%3Abob"+ "&host=1.2.3.4"+ "&operation=WRITE"+ "&permission=ALLOW").build()).setClusterId(CLUSTER_ID).setResourceType(Acl.ResourceType.TOPIC).setResourceName("topic-").setPatternType(Acl.PatternType.PREFIXED).setPrincipal("User:bob").setHost("1.2.3.4").setOperation(Acl.Operation.WRITE).setPermission(Acl.Permission.ALLOW).build())).build());" is 1364.,78
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,createAcl_createsAcl,Long Statement,The length of the statement "expect(aclManager.createAcl(CLUSTER_ID`Acl.ResourceType.TOPIC`"*"`Acl.PatternType.LITERAL`"User:alice"`"*"`Acl.Operation.READ`Acl.Permission.ALLOW)).andReturn(completedFuture(null));" is 182.,171
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,createAcl_createsAcl,Long Statement,The length of the statement "aclsResource.createAcl(response`CLUSTER_ID`CreateAclRequest.builder().setResourceType(Acl.ResourceType.TOPIC).setResourceName("*").setPatternType(Acl.PatternType.LITERAL).setPrincipal("User:alice").setHost("*").setOperation(Acl.Operation.READ).setPermission(Acl.Permission.ALLOW).build());" is 289.,171
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,deleteAcl_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "expect(aclManager.deleteAcls(CLUSTER_ID`Acl.ResourceType.TOPIC`"topic-1"`Acl.PatternType.MATCH`null`null`Acl.Operation.ANY`Acl.Permission.ALLOW)).andReturn(completedFuture(Arrays.asList(ACL_1`ACL_2)));" is 201.,204
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,deleteAcl_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "aclsResource.deleteAcls(response`CLUSTER_ID`Acl.ResourceType.TOPIC`"topic-1"`Acl.PatternType.MATCH`""`""`Acl.Operation.ANY`Acl.Permission.ALLOW);" is 145.,204
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AclsResourceTest,deleteAcl_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "DeleteAclsResponse expected=DeleteAclsResponse.create(Arrays.asList(AclData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/acls" + "?resource_type=TOPIC" + "&resource_name=*"+ "&pattern_type=LITERAL"+ "&principal=User%3Aalice"+ "&host=*"+ "&operation=READ"+ "&permission=ALLOW").build()).setClusterId(CLUSTER_ID).setResourceType(Acl.ResourceType.TOPIC).setResourceName("*").setPatternType(Acl.PatternType.LITERAL).setPrincipal("User:alice").setHost("*").setOperation(Acl.Operation.READ).setPermission(Acl.Permission.ALLOW).build()`AclData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/acls" + "?resource_type=TOPIC" + "&resource_name=topic-"+ "&pattern_type=PREFIXED"+ "&principal=User%3Abob"+ "&host=1.2.3.4"+ "&operation=WRITE"+ "&permission=ALLOW").build()).setClusterId(CLUSTER_ID).setResourceType(Acl.ResourceType.TOPIC).setResourceName("topic-").setPatternType(Acl.PatternType.PREFIXED).setPrincipal("User:bob").setHost("1.2.3.4").setOperation(Acl.Operation.WRITE).setPermission(Acl.Permission.ALLOW).build()));" is 1088.,204
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReplicasByBrokerActionTest,setUp,Long Statement,The length of the statement "searchReplicasByBrokerAction=new SearchReplicasByBrokerAction(() -> replicaManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 128.,70
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReplicasByBrokerActionTest,searchReplicasByBroker_existingBroker_returnsReplicas,Long Statement,The length of the statement "expect(replicaManager.searchReplicasByBrokerId(CLUSTER_ID`BROKER_ID)).andReturn(completedFuture(Arrays.asList(REPLICA_1`REPLICA_2)));" is 133.,79
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReplicasByBrokerActionTest,searchReplicasByBroker_existingBroker_returnsReplicas,Long Statement,The length of the statement "SearchReplicasByBrokerResponse expected=SearchReplicasByBrokerResponse.create(ReplicaDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/partition-replicas").build()).setData(Arrays.asList(ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/1" + "/replicas/1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=1" + "/replica=1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(REPLICA_1.getPartitionId()).setBrokerId(BROKER_ID).setLeader(true).setInSync(true).setBroker(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1")).build()`ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/2" + "/replicas/1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=2" + "/replica=1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(REPLICA_2.getPartitionId()).setBrokerId(BROKER_ID).setLeader(false).setInSync(false).setBroker(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1")).build())).build());" is 1189.,79
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllReassignmentsActionTest,setUp,Long Statement,The length of the statement "listAllReassignmentsAction=new ListAllReassignmentsAction(() -> reassignmentManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 129.,76
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllReassignmentsActionTest,listAllReassignments_existingCluster_returnsReassignments,Long Statement,The length of the statement "expect(reassignmentManager.listReassignments(CLUSTER_ID)).andReturn(CompletableFuture.completedFuture(asList(REASSIGNMENT_1`REASSIGNMENT_2`REASSIGNMENT_3)));" is 157.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllReassignmentsActionTest,listAllReassignments_existingCluster_returnsReassignments,Long Statement,The length of the statement "ListAllReassignmentsResponse expected=ListAllReassignmentsResponse.create(ReassignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/-/partitions/-/reassignments").build()).setData(Arrays.asList(ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/1" + "/reassignments").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=1" + "/reassignments").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_1).setAddingReplicas(ADDING_REPLICAS_1).setRemovingReplicas(REMOVING_REPLICAS_1).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1/replicas")).build()`ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/2" + "/reassignments").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=2" + "/reassignments").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_2).setAddingReplicas(ADDING_REPLICAS_2).setRemovingReplicas(REMOVING_REPLICAS_2).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/2/replicas")).build()`ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/3" + "/reassignments").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=3" + "/reassignments").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_3).setAddingReplicas(ADDING_REPLICAS_3).setRemovingReplicas(REMOVING_REPLICAS_3).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/3/replicas")).build())).build());" is 1806.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,listReplicas_existingPartition_returnsReplicas,Long Statement,The length of the statement "expect(replicaManager.listReplicas(CLUSTER_ID`TOPIC_NAME`PARTITION_ID)).andReturn(completedFuture(Arrays.asList(REPLICA_1`REPLICA_2`REPLICA_3)));" is 145.,89
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,listReplicas_existingPartition_returnsReplicas,Long Statement,The length of the statement "ListReplicasResponse expected=ListReplicasResponse.create(ReplicaDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0/replicas").build()).setData(Arrays.asList(ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0" + "/replicas/1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=0" + "/replica=1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_ID).setBrokerId(REPLICA_1.getBrokerId()).setLeader(true).setInSync(true).setBroker(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1")).build()`ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0" + "/replicas/2").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=0" + "/replica=2").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_ID).setBrokerId(REPLICA_2.getBrokerId()).setLeader(false).setInSync(true).setBroker(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/2")).build()`ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0" + "/replicas/3").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=0" + "/replica=3").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_ID).setBrokerId(REPLICA_3.getBrokerId()).setLeader(false).setInSync(false).setBroker(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/3")).build())).build());" is 1642.,89
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,listReplicas_nonExistingPartitionOrTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(replicaManager.listReplicas(CLUSTER_ID`TOPIC_NAME`PARTITION_ID)).andReturn(failedFuture(new NotFoundException()));" is 121.,169
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,getReplica_existingReplica_returnsReplica,Long Statement,The length of the statement "expect(replicaManager.getReplica(CLUSTER_ID`TOPIC_NAME`PARTITION_ID`REPLICA_1.getBrokerId())).andReturn(completedFuture(Optional.of(REPLICA_1)));" is 145.,181
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,getReplica_existingReplica_returnsReplica,Long Statement,The length of the statement "GetReplicaResponse expected=GetReplicaResponse.create(ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/0/replicas/1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=0/replica=1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setPartitionId(PARTITION_ID).setBrokerId(REPLICA_1.getBrokerId()).setLeader(true).setInSync(true).setBroker(Resource.Relationship.create("/v3/clusters/cluster-1/brokers/1")).build());" is 509.,181
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,getReplica_nonExistingReplica_throwNotFound,Long Statement,The length of the statement "expect(replicaManager.getReplica(CLUSTER_ID`TOPIC_NAME`PARTITION_ID`REPLICA_1.getBrokerId())).andReturn(completedFuture(Optional.empty()));" is 139.,212
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ReplicasResourceTest,getReplica_nonExistingPartitionOrTopicOrCluster_throwNotFound,Long Statement,The length of the statement "expect(replicaManager.getReplica(CLUSTER_ID`TOPIC_NAME`PARTITION_ID`REPLICA_1.getBrokerId())).andReturn(failedFuture(new NotFoundException()));" is 143.,225
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,setUp,Long Statement,The length of the statement "allBrokersConfigsAction=new ListAllBrokersConfigsAction(() -> brokerManager`() -> brokerConfigManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 147.,97
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,listAllBrokerConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "expect(brokerManager.listBrokers(CLUSTER_ID)).andReturn(completedFuture(Arrays.asList(Broker.create(CLUSTER_ID`BROKER_ID`"localhost"`9092`"us-east"))));" is 152.,107
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,listAllBrokerConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "expect(brokerConfigManager.listAllBrokerConfigs(CLUSTER_ID`Arrays.asList(BROKER_ID))).andReturn(completedFuture(new HashMap<Integer`List<BrokerConfig>>(){" is 154.,107
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,listAllBrokerConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "ListBrokerConfigsResponse expected=ListBrokerConfigsResponse.create(BrokerConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/-/configs").build()).setData(Arrays.asList(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-1").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-1").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-2").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-2").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_2.getName()).setValue(CONFIG_2.getValue()).setDefault(CONFIG_2.isDefault()).setReadOnly(CONFIG_2.isReadOnly()).setSensitive(CONFIG_2.isSensitive()).setSource(CONFIG_2.getSource()).setSynonyms(CONFIG_2.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/1/configs/config-3").setResourceName("crn:///kafka=cluster-1/broker=1/config=config-3").build()).setClusterId(CLUSTER_ID).setBrokerId(BROKER_ID).setName(CONFIG_3.getName()).setValue(CONFIG_3.getValue()).setDefault(CONFIG_3.isDefault()).setReadOnly(CONFIG_3.isReadOnly()).setSensitive(CONFIG_3.isSensitive()).setSource(CONFIG_3.getSource()).setSynonyms(CONFIG_3.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build())).build());" is 1956.,107
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,listAllBrokerConfigs_existingBrokers_returnsConfigs,Magic Number,The method contains a magic number: 9092,107
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,listAllBrokerConfigs_noBrokers_returnsEmptyConfigs,Long Statement,The length of the statement "expect(brokerConfigManager.listAllBrokerConfigs(CLUSTER_ID`new ArrayList<>())).andReturn(completedFuture(new HashMap<Integer`List<BrokerConfig>>()));" is 149.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllBrokersConfigsActionTest,listAllBrokerConfigs_noBrokers_returnsEmptyConfigs,Long Statement,The length of the statement "ListBrokerConfigsResponse expected=ListBrokerConfigsResponse.create(BrokerConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/brokers/-/configs").build()).setData(new ArrayList<>()).build());" is 246.,201
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "expect(topicConfigManager.listTopicConfigs(CLUSTER_ID`TOPIC_NAME)).andReturn(completedFuture(Arrays.asList(CONFIG_1`CONFIG_2`CONFIG_3)));" is 137.,104
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "ListTopicConfigsResponse expected=ListTopicConfigsResponse.create(TopicConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs").build()).setData(Arrays.asList(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-2").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-2").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_2.getName()).setValue(CONFIG_2.getValue()).setDefault(CONFIG_2.isDefault()).setReadOnly(CONFIG_2.isReadOnly()).setSensitive(CONFIG_2.isSensitive()).setSource(CONFIG_2.getSource()).setSynonyms(CONFIG_2.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-3").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-3").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_3.getName()).setValue(CONFIG_3.getValue()).setDefault(CONFIG_3.isDefault()).setReadOnly(CONFIG_3.isReadOnly()).setSensitive(CONFIG_3.isSensitive()).setSource(CONFIG_3.getSource()).setSynonyms(CONFIG_3.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build())).build());" is 1991.,104
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,getTopicConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(topicConfigManager.getTopicConfig(CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName())).andReturn(completedFuture(Optional.of(CONFIG_1)));" is 134.,202
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,getTopicConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "GetTopicConfigResponse expected=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build());" is 645.,202
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,getTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(topicConfigManager.getTopicConfig(CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName())).andReturn(completedFuture(Optional.empty()));" is 129.,236
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,getTopicConfig_nonExistingTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(topicConfigManager.getTopicConfig(CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 133.,248
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,updateTopicConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(topicConfigManager.updateTopicConfig(CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName()`"new-value")).andReturn(completedFuture(null));" is 132.,260
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,updateTopicConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "topicConfigsResource.updateTopicConfig(response`CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName()`UpdateTopicConfigRequest.create("new-value"));" is 135.,260
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,updateTopicConfig_nonExistingConfigOrTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(topicConfigManager.updateTopicConfig(CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName()`"new-value")).andReturn(failedFuture(new NotFoundException()));" is 148.,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,updateTopicConfig_nonExistingConfigOrTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "topicConfigsResource.updateTopicConfig(response`CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName()`UpdateTopicConfigRequest.create("new-value"));" is 135.,281
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,TopicConfigsResourceTest,resetTopicConfig_nonExistingConfigOrTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(topicConfigManager.resetTopicConfig(CLUSTER_ID`TOPIC_NAME`CONFIG_1.getName())).andReturn(failedFuture(new NotFoundException()));" is 135.,314
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterClusterConfigBatchActionTest,alterClusterConfigs_existingConfig_alterConfigs,Long Statement,The length of the statement "expect(clusterConfigManager.alterClusterConfigs(CLUSTER_ID`ClusterConfig.Type.BROKER`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"newValue")`AlterConfigCommand.delete(CONFIG_2.getName())))).andReturn(completedFuture(null));" is 235.,81
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterClusterConfigBatchActionTest,alterClusterConfigs_existingConfig_alterConfigs,Long Statement,The length of the statement "alterClusterConfigBatchAction.alterClusterConfigBatch(response`CLUSTER_ID`ClusterConfig.Type.BROKER`AlterClusterConfigBatchRequest.create(AlterConfigBatchRequestData.create(Arrays.asList(AlterEntry.builder().setName(CONFIG_1.getName()).setValue("newValue").build()`AlterEntry.builder().setName(CONFIG_2.getName()).setOperation(AlterOperation.DELETE).build()))));" is 362.,81
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterClusterConfigBatchActionTest,alterClusterConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(clusterConfigManager.alterClusterConfigs(CLUSTER_ID`ClusterConfig.Type.BROKER`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"newValue")`AlterConfigCommand.delete(CONFIG_2.getName())))).andReturn(failedFuture(new NotFoundException()));" is 251.,112
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,AlterClusterConfigBatchActionTest,alterClusterConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "alterClusterConfigBatchAction.alterClusterConfigBatch(response`CLUSTER_ID`ClusterConfig.Type.BROKER`AlterClusterConfigBatchRequest.create(AlterConfigBatchRequestData.create(Arrays.asList(AlterEntry.builder().setName(CONFIG_1.getName()).setValue("newValue").build()`AlterEntry.builder().setName(CONFIG_2.getName()).setOperation(AlterOperation.DELETE).build()))));" is 362.,112
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,setUp,Long Identifier,The length of the field listReassignmentsByTopicAction is 30.,76
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,setUp,Long Statement,The length of the statement "listReassignmentsByTopicAction=new SearchReassignmentsByTopicAction(() -> reassignmentManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 139.,76
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,searchReassignments_existingCluster_returnsReassignments,Long Identifier,The length of the field listReassignmentsByTopicAction is 30.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,searchReassignments_existingCluster_returnsReassignments,Long Statement,The length of the statement "expect(reassignmentManager.searchReassignmentsByTopicName(CLUSTER_ID`TOPIC_1)).andReturn(CompletableFuture.completedFuture(asList(REASSIGNMENT_1`REASSIGNMENT_2`REASSIGNMENT_3)));" is 178.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,searchReassignments_existingCluster_returnsReassignments,Long Statement,The length of the statement "SearchReassignmentsByTopicResponse expected=SearchReassignmentsByTopicResponse.create(ReassignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/-/reassignments").build()).setData(Arrays.asList(ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/1" + "/reassignments").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=1" + "/reassignments").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_1).setAddingReplicas(ADDING_REPLICAS_1).setRemovingReplicas(REMOVING_REPLICAS_1).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1/replicas")).build()`ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/2" + "/reassignments").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=2" + "/reassignments").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_2).setAddingReplicas(ADDING_REPLICAS_2).setRemovingReplicas(REMOVING_REPLICAS_2).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/2/replicas")).build()`ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/3" + "/reassignments").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=3" + "/reassignments").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_3).setAddingReplicas(ADDING_REPLICAS_3).setRemovingReplicas(REMOVING_REPLICAS_3).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/3/replicas")).build())).build());" is 1824.,85
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,searchReassignments_nonExistingCluster_throwsNotFound,Long Identifier,The length of the field listReassignmentsByTopicAction is 30.,167
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,SearchReassignmentsByTopicActionTest,searchReassignments_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(reassignmentManager.searchReassignmentsByTopicName(CLUSTER_ID`TOPIC_1)).andReturn(failedFuture(new NotFoundException()));" is 128.,167
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsActionTest,setUp,Long Statement,The length of the statement "allTopicConfigsResource=new ListAllTopicsConfigsAction(() -> topicManager`() -> topicConfigManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 144.,98
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsActionTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "expect(topicManager.listTopics(CLUSTER_ID)).andReturn(completedFuture(Arrays.asList(Topic.create(CLUSTER_ID`TOPIC_NAME`new ArrayList<>()`(short)1`false`emptySet()))));" is 167.,108
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsActionTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "expect(topicConfigManager.listTopicConfigs(CLUSTER_ID`Arrays.asList(TOPIC_NAME))).andReturn(completedFuture(new HashMap<String`List<TopicConfig>>(){" is 148.,108
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsActionTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "ListTopicConfigsResponse expected=ListTopicConfigsResponse.create(TopicConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/-/configs").build()).setData(Arrays.asList(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-1").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-1").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_1.getName()).setValue(CONFIG_1.getValue()).setDefault(CONFIG_1.isDefault()).setReadOnly(CONFIG_1.isReadOnly()).setSensitive(CONFIG_1.isSensitive()).setSource(CONFIG_1.getSource()).setSynonyms(CONFIG_1.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-2").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-2").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_2.getName()).setValue(CONFIG_2.getValue()).setDefault(CONFIG_2.isDefault()).setReadOnly(CONFIG_2.isReadOnly()).setSensitive(CONFIG_2.isSensitive()).setSource(CONFIG_2.getSource()).setSynonyms(CONFIG_2.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build()`TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/configs/config-3").setResourceName("crn:///kafka=cluster-1/topic=topic-1/config=config-3").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_NAME).setName(CONFIG_3.getName()).setValue(CONFIG_3.getValue()).setDefault(CONFIG_3.isDefault()).setReadOnly(CONFIG_3.isReadOnly()).setSensitive(CONFIG_3.isSensitive()).setSource(CONFIG_3.getSource()).setSynonyms(CONFIG_3.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList())).build())).build());" is 1985.,108
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsActionTest,listTopicConfigs_noTopics_returnsEmptyConfigs,Long Statement,The length of the statement "expect(topicConfigManager.listTopicConfigs(CLUSTER_ID`new ArrayList<>())).andReturn(completedFuture(new HashMap<String`List<TopicConfig>>()));" is 142.,207
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ListAllTopicsConfigsActionTest,listTopicConfigs_noTopics_returnsEmptyConfigs,Long Statement,The length of the statement "ListTopicConfigsResponse expected=ListTopicConfigsResponse.create(TopicConfigDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/-/configs").build()).setData(new ArrayList<>()).build());" is 242.,207
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResourceTest,setUp,Long Statement,The length of the statement "consumerGroupsResource=new ConsumerGroupsResource(() -> consumerGroupManager`new CrnFactoryImpl("")`new FakeUrlFactory());" is 122.,243
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResourceTest,listConsumerGroups_returnsConsumerGroups,Long Statement,The length of the statement "ListConsumerGroupsResponse expected=ListConsumerGroupsResponse.create(ConsumerGroupDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups").build()).setData(Arrays.asList(ConsumerGroupData.fromConsumerGroup(CONSUMER_GROUPS[0]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1").build()).setCoordinator(Relationship.create("/v3/clusters/cluster-1/brokers/1")).setConsumers(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1" + "/consumers")).setLagSummary(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lag-summary")).build()`ConsumerGroupData.fromConsumerGroup(CONSUMER_GROUPS[1]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-2").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-2").build()).setCoordinator(Relationship.create("/v3/clusters/cluster-1/brokers/2")).setConsumers(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-2" + "/consumers")).setLagSummary(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-2" + "/lag-summary")).build())).build());" is 1329.,250
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResourceTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUPS[0].getConsumerGroupId())).andReturn(completedFuture(Optional.of(CONSUMER_GROUPS[0])));" is 158.,308
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResourceTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "GetConsumerGroupResponse expected=GetConsumerGroupResponse.create(ConsumerGroupData.fromConsumerGroup(CONSUMER_GROUPS[0]).setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/consumer-groups/consumer-group-1").setResourceName("crn:///kafka=cluster-1/consumer-group=consumer-group-1").build()).setCoordinator(Relationship.create("/v3/clusters/cluster-1/brokers/1")).setConsumers(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/consumers")).setLagSummary(Relationship.create("/v3/clusters/cluster-1/consumer-groups/consumer-group-1/lag-summary")).build());" is 602.,308
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,ConsumerGroupsResourceTest,getConsumerGroup_nonExistingConsumerGroup_throwsNotFound,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUPS[0].getConsumerGroupId())).andReturn(completedFuture(Optional.empty()));" is 143.,340
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,GetReassignmentActionTest,getReassignment_existingClusterTopicPartition_returnsReassignment,Long Statement,The length of the statement "expect(reassignmentManager.getReassignment(CLUSTER_ID`TOPIC_1`PARTITION_ID_1)).andReturn(CompletableFuture.completedFuture(Optional.of(REASSIGNMENT_1)));" is 153.,71
confluentinc_kafka-rest,io.confluent.kafkarest.resources.v3,GetReassignmentActionTest,getReassignment_existingClusterTopicPartition_returnsReassignment,Long Statement,The length of the statement "GetReassignmentResponse expected=GetReassignmentResponse.create(ReassignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf("/v3/clusters/cluster-1/topics/topic-1/partitions/1" + "/reassignment").setResourceName("crn:///kafka=cluster-1/topic=topic-1/partition=1/reassignment").build()).setClusterId(CLUSTER_ID).setTopicName(TOPIC_1).setPartitionId(PARTITION_ID_1).setAddingReplicas(ADDING_REPLICAS_1).setRemovingReplicas(REMOVING_REPLICAS_1).setReplicas(Resource.Relationship.create("/v3/clusters/cluster-1/topics/topic-1/partitions/1/replicas")).build());" is 571.,71
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ClusterConfig,create,Long Parameter List,The method has 9 parameters. ,35
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ClusterConfig,create,Long Statement,The length of the statement "return builder().setClusterId(clusterId).setName(name).setValue(value).setDefault(isDefault).setReadOnly(isReadOnly).setSensitive(isSensitive).setSource(source).setSynonyms(synonyms).setType(type).build();" is 205.,35
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Acl,fromAclBinding,Long Statement,The length of the statement "return builder().setResourceType(ResourceType.fromAdminResourceType(acl.pattern().resourceType())).setResourceName(acl.pattern().name()).setPatternType(PatternType.fromAdminPatternType(acl.pattern().patternType())).setPrincipal(acl.entry().principal()).setHost(acl.entry().host()).setOperation(Operation.fromAclOperation(acl.entry().operation())).setPermission(Permission.fromAclPermissionType(acl.entry().permissionType()));" is 425.,48
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Reassignment,create,Long Parameter List,The method has 5 parameters. ,37
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Reassignment,create,Long Statement,The length of the statement "return new AutoValue_Reassignment(clusterId`topicName`partitionId`ImmutableList.copyOf(addingReplicas)`ImmutableList.copyOf(removingReplicas));" is 143.,37
confluentinc_kafka-rest,io.confluent.kafkarest.entities,BrokerConfig,create,Long Parameter List,The method has 9 parameters. ,34
confluentinc_kafka-rest,io.confluent.kafkarest.entities,BrokerConfig,create,Long Statement,The length of the statement "return builder().setClusterId(clusterId).setName(name).setValue(value).setDefault(isDefault).setReadOnly(isReadOnly).setSensitive(isSensitive).setSource(source).setSynonyms(synonyms).setBrokerId(brokerId).build();" is 213.,34
confluentinc_kafka-rest,io.confluent.kafkarest.entities,PartitionReplica,create,Long Parameter List,The method has 6 parameters. ,37
confluentinc_kafka-rest,io.confluent.kafkarest.entities,TopicConfig,create,Long Parameter List,The method has 9 parameters. ,34
confluentinc_kafka-rest,io.confluent.kafkarest.entities,TopicConfig,create,Long Statement,The length of the statement "return builder().setClusterId(clusterId).setName(name).setValue(value).setDefault(isDefault).setReadOnly(isReadOnly).setSensitive(isSensitive).setSource(source).setSynonyms(synonyms).setTopicName(topicName).build();" is 215.,34
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ConsumerRecord,create,Long Parameter List,The method has 5 parameters. ,38
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Broker,create,Long Parameter List,The method has 5 parameters. ,41
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Broker,fromNode,Long Statement,The length of the statement "return create(clusterId`node.id()`!node.host().equals("") ? node.host() : null`node.port() != -1 ? node.port() : null`node.rack());" is 131.,50
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Partition,create,Long Parameter List,The method has 6 parameters. ,59
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Partition,create,Long Statement,The length of the statement "return new AutoValue_Partition(clusterId`topicName`partitionId`ImmutableList.copyOf(replicas)`earliestOffset`latestOffset);" is 123.,59
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Consumer,fromMemberDescription,Long Statement,The length of the statement "return builder().setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setConsumerId(description.consumerId()).setInstanceId(description.groupInstanceId().orElse(null)).setClientId(description.clientId()).setHost(description.host()).setAssignedPartitions(description.assignment().topicPartitions().stream().map(partition -> Partition.create(clusterId`partition.topic()`partition.partition()`emptyList())).collect(Collectors.toList())).build();" is 449.,51
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ProduceRequest,create,Long Parameter List,The method has 5 parameters. ,41
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ConsumerInstanceConfig,create,Long Parameter List,The method has 7 parameters. ,57
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ConsumerInstanceConfig,create,Long Statement,The length of the statement "return new AutoValue_ConsumerInstanceConfig(id`name`format`autoOffsetReset`autoCommitEnable`responseMinBytes`requestWaitMs);" is 124.,57
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ProduceResult,create,Long Parameter List,The method has 6 parameters. ,41
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ProduceResult,create,Long Statement,The length of the statement "return new AutoValue_ProduceResult(partitionId`offset`Optional.ofNullable(timestamp)`serializedKeySize`serializedValueSize`completionTimestamp);" is 144.,41
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ProduceResult,fromRecordMetadata,Long Statement,The length of the statement "return create(metadata.partition()`metadata.offset()`metadata.hasTimestamp() ? Instant.ofEpochMilli(metadata.timestamp()) : null`metadata.serializedKeySize()`metadata.serializedValueSize()`completionTimestamp);" is 210.,57
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ProduceResult,fromRecordMetadata,Long Statement,The length of the statement "return create(metadata.partition()`metadata.offset()`metadata.hasTimestamp() ? Instant.ofEpochMilli(metadata.timestamp()) : null`metadata.serializedKeySize()`metadata.serializedValueSize()`Instant.now());" is 204.,68
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Topic,create,Long Parameter List,The method has 5 parameters. ,43
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Topic,create,Long Parameter List,The method has 6 parameters. ,52
confluentinc_kafka-rest,io.confluent.kafkarest.entities,Topic,create,Long Statement,The length of the statement "return new AutoValue_Topic(clusterId`name`ImmutableList.copyOf(partitions)`replicationFactor`isInternal`authorizedOperations == null ? emptySet() : authorizedOperations);" is 170.,52
confluentinc_kafka-rest,io.confluent.kafkarest.entities,ConsumerGroup,fromConsumerGroupDescription,Long Statement,The length of the statement "return builder().setClusterId(clusterId).setConsumerGroupId(description.groupId()).setSimple(description.isSimpleConsumerGroup()).setPartitionAssignor(description.partitionAssignor()).setState(State.fromConsumerGroupState(description.state())).setCoordinator(Broker.fromNode(clusterId`description.coordinator())).setConsumers(description.members().stream().map(consumer -> Consumer.fromMemberDescription(clusterId`description.groupId()`consumer)).collect(Collectors.toList())).build();" is 485.,59
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerAssignmentRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerAssignmentRequest.class.getSimpleName() + "["`"]").add("partitions=" + partitions).toString();" is 131.,58
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerCommittedResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerCommittedResponse.class.getSimpleName() + "["`"]").add("offsets=" + offsets).toString();" is 125.,58
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,GetPartitionResponse,fromPartition,Long Statement,The length of the statement "return new GetPartitionResponse(partition.getPartitionId()`partition.getLeader().map(PartitionReplica::getBrokerId).orElse(-1)`replicas.stream().map(Replica::fromPartitionReplica).collect(Collectors.toList()));" is 210.,66
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,GetPartitionResponse,equals,Long Statement,The length of the statement "return Objects.equals(partition`that.partition) && Objects.equals(leader`that.leader) && Objects.equals(replicas`that.replicas);" is 128.,75
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,GetPartitionResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`GetPartitionResponse.class.getSimpleName() + "["`"]").add("partition=" + partition).add("leader=" + leader).add("replicas=" + replicas).toString();" is 176.,94
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerSeekRequest,fromJson,Long Statement,The length of the statement "return new AutoValue_ConsumerSeekRequest(offsets != null ? ImmutableList.copyOf(offsets) : ImmutableList.of()`timestamps != null ? ImmutableList.copyOf(timestamps) : ImmutableList.of());" is 186.,38
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,TopicPartitionOffsetMetadata,equals,Long Statement,The length of the statement "return Objects.equals(topic`that.topic) && Objects.equals(partition`that.partition) && Objects.equals(offset`that.offset)&& Objects.equals(metadata`that.metadata);" is 163.,70
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,TopicPartitionOffsetMetadata,toString,Long Statement,The length of the statement "return new StringJoiner("` "`TopicPartitionOffsetMetadata.class.getSimpleName() + "["`"]").add("topic='" + topic + "'").add("partition=" + partition).add("offset=" + offset).add("metadata='" + metadata + "'").toString();" is 220.,90
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,CommitOffsetsResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`CommitOffsetsResponse.class.getSimpleName() + "["`"]").add("offsets=" + offsets).toString();" is 121.,67
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryPartitionProduceRequest,BinaryPartitionProduceRequest,Long Parameter List,The method has 5 parameters. ,36
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryPartitionProduceRequest,toProduceRequest,Long Statement,The length of the statement "return ProduceRequest.create(records.stream().map(record -> ProduceRecord.create(record.key`record.value`null)).collect(Collectors.toList())`null`null`null`null);" is 162.,64
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryPartitionProduceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`BinaryPartitionProduceRequest.class.getSimpleName() + "["`"]").add("records=" + records).toString();" is 129.,95
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,BinaryConsumerRecord,Long Parameter List,The method has 5 parameters. ,42
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,fromConsumerRecord,Long Statement,The length of the statement "return new BinaryConsumerRecord(Objects.requireNonNull(record.getTopic())`record.getKey() != null ? record.getKey().toByteArray() : null`record.getValue() != null ? record.getValue().toByteArray() : null`record.getPartition()`record.getOffset());" is 246.,86
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,toConsumerRecord,Long Statement,The length of the statement "return ConsumerRecord.create(topic`key != null ? ByteString.copyFrom(key) : null`value != null ? ByteString.copyFrom(value) : null`partition`offset);" is 149.,102
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,equals,Long Statement,The length of the statement "return Objects.equals(topic`that.topic) && Arrays.equals(key`that.key) && Arrays.equals(value`that.value)&& Objects.equals(partition`that.partition)&& Objects.equals(offset`that.offset);" is 186.,120
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,hashCode,Magic Number,The method contains a magic number: 31,136
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,hashCode,Magic Number,The method contains a magic number: 31,136
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryConsumerRecord,toString,Long Statement,The length of the statement "return new StringJoiner("` "`BinaryConsumerRecord.class.getSimpleName() + "["`"]").add("topic='" + topic + "'").add("key=" + Arrays.toString(key)).add("value=" + Arrays.toString(value)).add("partition=" + partition).add("offset=" + offset).toString();" is 251.,144
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,TopicPartitionOffsetResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`TopicPartitionOffsetResponse.class.getSimpleName() + "["`"]").add("beginningOffset=" + beginningOffset).add("endOffset=" + endOffset).toString();" is 174.,76
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonConsumerRecord,JsonConsumerRecord,Long Parameter List,The method has 5 parameters. ,39
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonConsumerRecord,fromConsumerRecord,Long Statement,The length of the statement "return new JsonConsumerRecord(Objects.requireNonNull(record.getTopic())`record.getKey()`record.getValue()`record.getPartition()`record.getOffset());" is 148.,83
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonConsumerRecord,equals,Long Statement,The length of the statement "return Objects.equals(topic`that.topic) && Objects.equals(key`that.key) && Objects.equals(value`that.value)&& Objects.equals(partition`that.partition)&& Objects.equals(offset`that.offset);" is 188.,111
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonConsumerRecord,toString,Long Statement,The length of the statement "return new StringJoiner("` "`JsonConsumerRecord.class.getSimpleName() + "["`"]").add("topic='" + topic + "'").add("key=" + key).add("value=" + value).add("partition=" + partition).add("offset=" + offset).toString();" is 215.,132
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerSubscriptionRecord,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerSubscriptionRecord.class.getSimpleName() + "["`"]").add("topics=" + topics).add("topicPattern='" + topicPattern + "'").toString();" is 167.,68
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerSeekToRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerSeekToRequest.class.getSimpleName() + "["`"]").add("partitions=" + partitions).toString();" is 127.,58
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaConsumerRecord,SchemaConsumerRecord,Long Parameter List,The method has 5 parameters. ,40
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaConsumerRecord,fromConsumerRecord,Long Statement,The length of the statement "return new SchemaConsumerRecord(Objects.requireNonNull(record.getTopic())`record.getKey()`record.getValue()`record.getPartition()`record.getOffset());" is 150.,84
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaConsumerRecord,equals,Long Statement,The length of the statement "return Objects.equals(topic`that.topic) && Objects.equals(key`that.key) && Objects.equals(value`that.value)&& Objects.equals(partition`that.partition)&& Objects.equals(offset`that.offset);" is 188.,112
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaConsumerRecord,toString,Long Statement,The length of the statement "return new StringJoiner("` "`SchemaConsumerRecord.class.getSimpleName() + "["`"]").add("topic='" + topic + "'").add("key=" + key).add("value=" + value).add("partition=" + partition).add("offset=" + offset).toString();" is 217.,133
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonTopicProduceRequest,JsonTopicProduceRequest,Long Parameter List,The method has 5 parameters. ,34
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonTopicProduceRequest,toProduceRequest,Long Statement,The length of the statement "return ProduceRequest.create(records.stream().map(record -> ProduceRecord.create(record.key`record.value`record.partition)).collect(Collectors.toList())`null`null`null`null);" is 174.,62
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonTopicProduceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`JsonTopicProduceRequest.class.getSimpleName() + "["`"]").add("records=" + records).toString();" is 123.,93
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerAssignmentResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerAssignmentResponse.class.getSimpleName() + "["`"]").add("partitions=" + partitions).toString();" is 132.,58
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ProduceResponse,equals,Long Statement,The length of the statement "return Objects.equals(offsets`that.offsets) && Objects.equals(keySchemaId`that.keySchemaId) && Objects.equals(valueSchemaId`that.valueSchemaId);" is 144.,81
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ProduceResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ProduceResponse.class.getSimpleName() + "["`"]").add("offsets=" + offsets).add("keySchemaId=" + keySchemaId).add("valueSchemaId=" + valueSchemaId).toString();" is 187.,100
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaPartitionProduceRequest,SchemaPartitionProduceRequest,Long Parameter List,The method has 5 parameters. ,42
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaPartitionProduceRequest,create,Long Parameter List,The method has 5 parameters. ,86
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaPartitionProduceRequest,toProduceRequest,Long Statement,The length of the statement "return ProduceRequest.create(records.stream().map(record -> ProduceRecord.create(record.key`record.value`null)).collect(Collectors.toList())`keySchema`keySchemaId`valueSchema`valueSchemaId);" is 190.,99
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaPartitionProduceRequest,equals,Long Statement,The length of the statement "return Objects.equals(records`that.records) && Objects.equals(keySchema`that.keySchema) && Objects.equals(keySchemaId`that.keySchemaId)&& Objects.equals(valueSchema`that.valueSchema)&& Objects.equals(valueSchemaId`that.valueSchemaId);" is 234.,113
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaPartitionProduceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`SchemaPartitionProduceRequest.class.getSimpleName() + "["`"]").add("records=" + records).add("keySchema='" + keySchema + "'").add("keySchemaId=" + keySchemaId).add("valueSchema='" + valueSchema + "'").add("valueSchemaId=" + valueSchemaId).toString();" is 279.,134
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryTopicProduceRequest,BinaryTopicProduceRequest,Long Parameter List,The method has 5 parameters. ,37
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryTopicProduceRequest,toProduceRequest,Long Statement,The length of the statement "return ProduceRequest.create(records.stream().map(record -> ProduceRecord.create(record.key`record.value`record.partition)).collect(Collectors.toList())`null`null`null`null);" is 174.,65
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,BinaryTopicProduceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`BinaryTopicProduceRequest.class.getSimpleName() + "["`"]").add("records=" + records).toString();" is 125.,96
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaTopicProduceRequest,SchemaTopicProduceRequest,Long Parameter List,The method has 5 parameters. ,43
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaTopicProduceRequest,create,Long Parameter List,The method has 5 parameters. ,87
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaTopicProduceRequest,toProduceRequest,Long Statement,The length of the statement "return ProduceRequest.create(records.stream().map(record -> ProduceRecord.create(record.key`record.value`record.partition)).collect(Collectors.toList())`keySchema`keySchemaId`valueSchema`valueSchemaId);" is 202.,100
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaTopicProduceRequest,equals,Long Statement,The length of the statement "return Objects.equals(records`that.records) && Objects.equals(keySchema`that.keySchema) && Objects.equals(keySchemaId`that.keySchemaId)&& Objects.equals(valueSchema`that.valueSchema)&& Objects.equals(valueSchemaId`that.valueSchemaId);" is 234.,114
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,SchemaTopicProduceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`SchemaTopicProduceRequest.class.getSimpleName() + "["`"]").add("records=" + records).add("keySchema='" + keySchema + "'").add("keySchemaId=" + keySchemaId).add("valueSchema='" + valueSchema + "'").add("valueSchemaId=" + valueSchemaId).toString();" is 275.,135
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerOffsetCommitRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerOffsetCommitRequest.class.getSimpleName() + "["`"]").add("offsets=" + offsets).toString();" is 127.,58
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ProduceRequest,create,Long Parameter List,The method has 5 parameters. ,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ProduceRequest,create,Long Statement,The length of the statement "return new AutoValue_ProduceRequest(ImmutableList.copyOf(records)`Optional.ofNullable(keySchemaId)`Optional.ofNullable(keySchema)`Optional.ofNullable(valueSchemaId)`Optional.ofNullable(valueSchema));" is 199.,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ProduceRequest,fromJson,Long Parameter List,The method has 5 parameters. ,70
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,CreateConsumerInstanceResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`CreateConsumerInstanceResponse.class.getSimpleName() + "["`"]").add("instanceId='" + instanceId + "'").add("baseUri='" + baseUri + "'").toString();" is 176.,67
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerSubscriptionResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerSubscriptionResponse.class.getSimpleName() + "["`"]").add("topics=" + topics).toString();" is 126.,57
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,ConsumerCommittedRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`ConsumerCommittedRequest.class.getSimpleName() + "["`"]").add("partitions=" + partitions).toString();" is 130.,58
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,PartitionOffset,equals,Long Statement,The length of the statement "return Objects.equals(partition`that.partition) && Objects.equals(offset`that.offset) && Objects.equals(errorCode`that.errorCode)&& Objects.equals(error`that.error);" is 165.,71
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,PartitionOffset,toString,Long Statement,The length of the statement "return new StringJoiner("` "`PartitionOffset.class.getSimpleName() + "["`"]").add("partition=" + partition).add("offset=" + offset).add("errorCode=" + errorCode).add("error='" + error + "'").toString();" is 202.,91
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,CreateConsumerInstanceRequest,CreateConsumerInstanceRequest,Long Parameter List,The method has 7 parameters. ,60
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,CreateConsumerInstanceRequest,computeResponseMinBytes,Long Statement,The length of the statement "KafkaRestConfig.PROXY_FETCH_MIN_BYTES_VALIDATOR.ensureValid(KafkaRestConfig.PROXY_FETCH_MIN_BYTES_CONFIG`responseMinBytes);" is 123.,94
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,CreateConsumerInstanceRequest,equals,Long Statement,The length of the statement "return Objects.equals(id`that.id) && Objects.equals(name`that.name) && format == that.format && Objects.equals(autoOffsetReset`that.autoOffsetReset) && Objects.equals(autoCommitEnable`that.autoCommitEnable) && Objects.equals(responseMinBytes`that.responseMinBytes) && Objects.equals(requestWaitMs`that.requestWaitMs);" is 317.,154
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,CreateConsumerInstanceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`CreateConsumerInstanceRequest.class.getSimpleName() + "["`"]").add("id='" + id + "'").add("name='" + name + "'").add("format=" + format).add("autoOffsetReset='" + autoOffsetReset + "'").add("autoCommitEnable='" + autoCommitEnable + "'").add("responseMinBytes=" + responseMinBytes).add("requestWaitMs=" + requestWaitMs).toString();" is 359.,178
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,TopicPartition,toString,Long Statement,The length of the statement "return new StringJoiner("` "`TopicPartition.class.getSimpleName() + "["`"]").add("topic='" + topic + "'").add("partition=" + partition).toString();" is 147.,67
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonPartitionProduceRequest,JsonPartitionProduceRequest,Long Parameter List,The method has 5 parameters. ,33
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonPartitionProduceRequest,toProduceRequest,Long Statement,The length of the statement "return ProduceRequest.create(records.stream().map(record -> ProduceRecord.create(record.key`record.value`null)).collect(Collectors.toList())`null`null`null`null);" is 162.,61
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,JsonPartitionProduceRequest,toString,Long Statement,The length of the statement "return new StringJoiner("` "`JsonPartitionProduceRequest.class.getSimpleName() + "["`"]").add("records=" + records).toString();" is 127.,92
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,GetTopicResponse,fromTopic,Long Statement,The length of the statement "return new GetTopicResponse(topic.getName()`configsMap`topic.getPartitions().stream().map(GetPartitionResponse::fromPartition).collect(Collectors.toList()));" is 157.,68
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,GetTopicResponse,equals,Long Statement,The length of the statement "return Objects.equals(name`that.name) && Objects.equals(configs`that.configs) && Objects.equals(partitions`that.partitions);" is 124.,81
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v2,GetTopicResponse,toString,Long Statement,The length of the statement "return new StringJoiner("` "`GetTopicResponse.class.getSimpleName() + "["`"]").add("name='" + name + "'").add("configs=" + configs).add("partitions=" + partitions).toString();" is 175.,100
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,BrokerConfigData,fromBrokerConfig,Long Statement,The length of the statement "return builder().setClusterId(config.getClusterId()).setBrokerId(config.getBrokerId()).setName(config.getName()).setValue(config.getValue()).setDefault(config.isDefault()).setReadOnly(config.isReadOnly()).setSensitive(config.isSensitive()).setSource(config.getSource()).setSynonyms(config.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList()));" is 384.,39
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,BrokerConfigData,fromJson,Long Parameter List,The method has 11 parameters. ,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,BrokerConfigData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setBrokerId(brokerId).setName(name).setValue(value).setDefault(isDefault).setReadOnly(isReadOnly).setSensitive(isSensitive).setSource(source).setSynonyms(synonyms).build();" is 249.,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,TopicConfigData,fromTopicConfig,Long Statement,The length of the statement "return builder().setClusterId(config.getClusterId()).setTopicName(config.getTopicName()).setName(config.getName()).setValue(config.getValue()).setDefault(config.isDefault()).setReadOnly(config.isReadOnly()).setSensitive(config.isSensitive()).setSource(config.getSource()).setSynonyms(config.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList()));" is 386.,39
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,TopicConfigData,fromJson,Long Parameter List,The method has 11 parameters. ,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,TopicConfigData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setTopicName(topicName).setName(name).setValue(value).setDefault(isDefault).setReadOnly(isReadOnly).setSensitive(isSensitive).setSource(source).setSynonyms(synonyms).build();" is 251.,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ReassignmentData,fromReassignment,Long Statement,The length of the statement "return builder().setClusterId(reassignment.getClusterId()).setTopicName(reassignment.getTopicName()).setPartitionId(reassignment.getPartitionId()).setAddingReplicas(reassignment.getAddingReplicas()).setRemovingReplicas(reassignment.getRemovingReplicas());" is 255.,52
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ReassignmentData,fromJson,Long Parameter List,The method has 8 parameters. ,61
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ReassignmentData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setTopicName(topicName).setPartitionId(partitionId).setAddingReplicas(addingReplicas).setRemovingReplicas(removingReplicas).setReplicas(replicas).build();" is 231.,61
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,CreateTopicRequest,fromJson,Long Parameter List,The method has 5 parameters. ,53
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,CreateTopicRequest,fromJson,Long Statement,The length of the statement "return builder().setTopicName(topicName).setPartitionsCount(partitionsCount).setReplicationFactor(replicationFactor).setReplicasAssignments(replicasAssignments != null ? replicasAssignments : Collections.emptyMap()).setConfigs(configs != null ? configs : ImmutableList.of()).build();" is 283.,53
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerAssignmentData,fromConsumerAssignment,Long Statement,The length of the statement "return builder().setClusterId(assignment.getClusterId()).setConsumerGroupId(assignment.getConsumerGroupId()).setConsumerId(assignment.getConsumerId()).setTopicName(assignment.getTopicName()).setPartitionId(assignment.getPartitionId());" is 235.,53
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerAssignmentData,fromJson,Long Parameter List,The method has 9 parameters. ,62
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerAssignmentData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setConsumerId(consumerId).setTopicName(topicName).setPartitionId(partitionId).setPartition(partition).setLag(lag).build();" is 235.,62
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,TopicData,fromTopic,Long Statement,The length of the statement "return builder().setClusterId(topic.getClusterId()).setTopicName(topic.getName()).setInternal(topic.isInternal()).setReplicationFactor(topic.getReplicationFactor()).setPartitionsCount(topic.getPartitions().size()).setAuthorizedOperations(topic.getAuthorizedOperations());" is 271.,63
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,TopicData,fromJson,Long Parameter List,The method has 11 parameters. ,73
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,TopicData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setTopicName(topicName).setInternal(isInternal).setReplicationFactor(replicationFactor).setPartitionsCount(partitionsCount).setPartitions(partitions).setConfigs(configs).setPartitionReassignments(partitionReassignments).setAuthorizedOperations(authorizedOperations).build();" is 351.,73
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,BrokerData,fromBroker,Long Statement,The length of the statement "return builder().setClusterId(broker.getClusterId()).setBrokerId(broker.getBrokerId()).setHost(broker.getHost()).setPort(broker.getPort()).setRack(broker.getRack());" is 165.,55
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,BrokerData,fromJson,Long Parameter List,The method has 9 parameters. ,64
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,BrokerData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setBrokerId(brokerId).setHost(host).setPort(port).setRack(rack).setConfigs(configs).setPartitionReplicas(partitionReplicas).build();" is 209.,64
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,AclData,fromAcl,Long Statement,The length of the statement "return builder().setClusterId(acl.getClusterId()).setResourceType(acl.getResourceType()).setResourceName(acl.getResourceName()).setPatternType(acl.getPatternType()).setPrincipal(acl.getPrincipal()).setHost(acl.getHost()).setOperation(acl.getOperation()).setPermission(acl.getPermission());" is 289.,60
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,AclData,fromJson,Long Parameter List,The method has 10 parameters. ,72
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,AclData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setResourceType(resourceType).setResourceName(resourceName).setPatternType(patternType).setPrincipal(principal).setHost(host).setOperation(operation).setPermission(permission).build();" is 261.,72
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,PartitionData,fromPartition,Long Statement,The length of the statement "return builder().setClusterId(partition.getClusterId()).setTopicName(partition.getTopicName()).setPartitionId(partition.getPartitionId());" is 138.,52
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,PartitionData,fromJson,Long Parameter List,The method has 8 parameters. ,59
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,PartitionData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setTopicName(topicName).setPartitionId(partitionId).setLeader(leader).setReplicas(replicas).setReassignment(reassignment).build();" is 207.,59
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ProduceResponse,fromJson,Long Parameter List,The method has 8 parameters. ,60
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ProduceResponse,fromJson,Long Statement,The length of the statement "return builder().setErrorCode(errorCode).setClusterId(clusterId).setTopicName(topicName).setPartitionId(partitionId).setOffset(offset).setTimestamp(timestamp).setKey(key).setValue(value).build();" is 195.,60
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerLagData,fromConsumerLag,Long Statement,The length of the statement "return builder().setClusterId(consumerLag.getClusterId()).setConsumerGroupId(consumerLag.getConsumerGroupId()).setTopicName(consumerLag.getTopicName()).setPartitionId(consumerLag.getPartitionId()).setConsumerId(consumerLag.getConsumerId()).setInstanceId(consumerLag.getInstanceId().orElse(null)).setClientId(consumerLag.getClientId()).setCurrentOffset(consumerLag.getCurrentOffset()).setLogEndOffset(consumerLag.getLogEndOffset()).setLag(consumerLag.getLag());" is 460.,64
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerLagData,fromJson,Long Parameter List,The method has 12 parameters. ,79
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerLagData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setTopicName(topicName).setPartitionId(partitionId).setConsumerId(consumerId).setInstanceId(instanceId).setClientId(clientId).setCurrentOffset(currentOffset).setLogEndOffset(logEndOffset).setLag(lag).build();" is 321.,79
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ClusterData,fromJson,Long Parameter List,The method has 10 parameters. ,64
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ClusterData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setController(controller).setAcls(acls).setBrokers(brokers).setBrokerConfigs(brokerConfigs).setConsumerGroups(consumerGroups).setTopics(topics).setPartitionReassignments(partitionReassignments).build();" is 279.,64
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ClusterConfigData,fromClusterConfig,Long Statement,The length of the statement "return builder().setClusterId(config.getClusterId()).setConfigType(config.getType()).setName(config.getName()).setValue(config.getValue()).setDefault(config.isDefault()).setReadOnly(config.isReadOnly()).setSensitive(config.isSensitive()).setSource(config.getSource()).setSynonyms(config.getSynonyms().stream().map(ConfigSynonymData::fromConfigSynonym).collect(Collectors.toList()));" is 382.,39
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ClusterConfigData,fromJson,Long Parameter List,The method has 11 parameters. ,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ClusterConfigData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setConfigType(configType).setName(name).setValue(value).setDefault(isDefault).setReadOnly(isReadOnly).setSensitive(isSensitive).setSource(source).setSynonyms(synonyms).build();" is 253.,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerGroupLagSummaryData,fromConsumerGroupLagSummary,Long Statement,The length of the statement "return builder().setClusterId(consumerGroupLagSummary.getClusterId()).setConsumerGroupId(consumerGroupLagSummary.getConsumerGroupId()).setMaxLag(consumerGroupLagSummary.getMaxLag()).setTotalLag(consumerGroupLagSummary.getTotalLag()).setMaxLagConsumerId(consumerGroupLagSummary.getMaxLagConsumerId()).setMaxLagClientId(consumerGroupLagSummary.getMaxLagClientId()).setMaxLagInstanceId(consumerGroupLagSummary.getMaxLagInstanceId().orElse(null)).setMaxLagTopicName(consumerGroupLagSummary.getMaxLagTopicName()).setMaxLagPartitionId(consumerGroupLagSummary.getMaxLagPartitionId());" is 577.,68
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerGroupLagSummaryData,fromJson,Long Parameter List,The method has 13 parameters. ,83
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerGroupLagSummaryData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setMaxLag(maxLag).setTotalLag(totalLag).setMaxLagConsumerId(maxLagConsumerId).setMaxLagConsumer(maxLagConsumer).setMaxLagClientId(maxLagClientId).setMaxLagInstanceId(maxLagInstanceId).setMaxLagTopicName(maxLagTopicName).setMaxLagPartitionId(maxLagPartitionId).setMaxLagPartition(maxLagPartition).build();" is 417.,83
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerData,fromConsumer,Long Statement,The length of the statement "return builder().setClusterId(consumer.getClusterId()).setConsumerGroupId(consumer.getConsumerGroupId()).setConsumerId(consumer.getConsumerId()).setInstanceId(consumer.getInstanceId().orElse(null)).setClientId(consumer.getClientId());" is 234.,52
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerData,fromJson,Long Parameter List,The method has 8 parameters. ,61
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setConsumerId(consumerId).setInstanceId(instanceId).setClientId(clientId).setAssignments(assignments).build();" is 223.,61
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,CreateAclRequest,fromJson,Long Parameter List,The method has 7 parameters. ,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,CreateAclRequest,fromJson,Long Statement,The length of the statement "return builder().setResourceType(resourceType).setResourceName(resourceName).setPatternType(patternType).setPrincipal(principal).setHost(host).setOperation(operation).setPermission(permission).build();" is 201.,56
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerGroupData,fromConsumerGroup,Long Statement,The length of the statement "return builder().setClusterId(consumerGroup.getClusterId()).setConsumerGroupId(consumerGroup.getConsumerGroupId()).setSimple(consumerGroup.isSimple()).setPartitionAssignor(consumerGroup.getPartitionAssignor()).setState(consumerGroup.getState());" is 245.,57
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerGroupData,fromJson,Long Parameter List,The method has 10 parameters. ,66
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ConsumerGroupData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setSimple(isSimple).setPartitionAssignor(partitionAssignor).setState(state).setCoordinator(coordinator).setConsumers(consumers).setLagSummary(lagSummary).build();" is 275.,66
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,AlterConfigBatchRequestData,toAlterConfigCommands,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@1303db2b,47
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ReplicaData,fromPartitionReplica,Long Statement,The length of the statement "return builder().setClusterId(replica.getClusterId()).setTopicName(replica.getTopicName()).setPartitionId(replica.getPartitionId()).setBrokerId(replica.getBrokerId()).setLeader(replica.isLeader()).setInSync(replica.isInSync());" is 227.,53
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ReplicaData,fromJson,Long Parameter List,The method has 9 parameters. ,63
confluentinc_kafka-rest,io.confluent.kafkarest.entities.v3,ReplicaData,fromJson,Long Statement,The length of the statement "return builder().setKind(kind).setMetadata(metadata).setClusterId(clusterId).setTopicName(topicName).setPartitionId(partitionId).setBrokerId(brokerId).setLeader(isLeader).setInSync(isInSync).setBroker(broker).build();" is 217.,63
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field METRICS_JMX_PREFIX_DEFAULT_OVERRIDE is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PROXY_FETCH_MIN_BYTES_VALIDATOR is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RATE_LIMIT_ENABLED_DEFAULT is 34.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RATE_LIMIT_ENABLED_DOC is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_PER_SECOND is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_PER_SECOND_DEFAULT is 39.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_PER_SECOND_VALIDATOR is 41.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_PER_SECOND_DOC is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND is 38.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND_DEFAULT is 46.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND_VALIDATOR is 48.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND_DOC is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_PER_SECOND_DEFAULT is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_PER_SECOND_VALIDATOR is 38.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_PER_SECOND_DOC is 32.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND_DEFAULT is 43.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND_VALIDATOR is 45.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND_DOC is 39.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS is 34.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS_DEFAULT is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS_DOC is 38.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RESPONSE_THREAD_POOL_SIZE is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RESPONSE_THREAD_POOL_SIZE_DEFAULT is 41.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RESPONSE_THREAD_POOL_SIZE_VALIDATOR is 43.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field PRODUCE_RESPONSE_THREAD_POOL_SIZE_DOC is 37.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_ITERATOR_TIMEOUT_MS_CONFIG is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_ITERATOR_TIMEOUT_MS_DEFAULT is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_ITERATOR_TIMEOUT_MS_DOC is 32.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_ITERATOR_BACKOFF_MS_CONFIG is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_ITERATOR_BACKOFF_MS_DEFAULT is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_ITERATOR_BACKOFF_MS_DOC is 32.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_REQUEST_TIMEOUT_MS_CONFIG is 34.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_REQUEST_TIMEOUT_MS_DEFAULT is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_REQUEST_TIMEOUT_MS_DOC is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_REQUEST_MAX_BYTES_CONFIG is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_REQUEST_MAX_BYTES_DEFAULT is 34.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_REQUEST_MAX_BYTES_DOC is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_INSTANCE_TIMEOUT_MS_CONFIG is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_INSTANCE_TIMEOUT_MS_DEFAULT is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONSUMER_INSTANCE_TIMEOUT_MS_DOC is 32.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field SIMPLE_CONSUMER_MAX_POOL_SIZE_CONFIG is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field SIMPLE_CONSUMER_MAX_POOL_SIZE_DEFAULT is 37.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field SIMPLE_CONSUMER_MAX_POOL_SIZE_DOC is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field SIMPLE_CONSUMER_POOL_TIMEOUT_MS_CONFIG is 38.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field SIMPLE_CONSUMER_POOL_TIMEOUT_MS_DEFAULT is 39.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field SIMPLE_CONSUMER_POOL_TIMEOUT_MS_DOC is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_ZK_SESSION_TIMEOUT_MS_CONFIG is 40.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_ZK_SESSION_TIMEOUT_MS_DOC is 37.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_INIT_TIMEOUT_CONFIG is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SECURITY_PROTOCOL_CONFIG is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SECURITY_PROTOCOL_DOC is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTSTORE_LOCATION_CONFIG is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTSTORE_LOCATION_DOC is 39.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTSTORE_PASSWORD_CONFIG is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTSTORE_PASSWORD_DOC is 39.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTSTORE_TYPE_CONFIG is 38.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKASTORE_SSL_TRUSTSTORE_TYPE_DOC is 34.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTMANAGER_ALGORITHM_CONFIG is 45.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_TRUSTMANAGER_ALGORITHM_DOC is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYSTORE_LOCATION_CONFIG is 40.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYSTORE_LOCATION_DOC is 37.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYSTORE_PASSWORD_CONFIG is 40.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYSTORE_PASSWORD_DOC is 37.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYSTORE_TYPE_CONFIG is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKASTORE_SSL_KEYSTORE_TYPE_DOC is 32.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYMANAGER_ALGORITHM_CONFIG is 43.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEYMANAGER_ALGORITHM_DOC is 40.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEY_PASSWORD_CONFIG is 35.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_KEY_PASSWORD_DOC is 32.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_ENABLED_PROTOCOLS_CONFIG is 40.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKASTORE_SSL_ENABLED_PROTOCOLS_DOC is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_PROTOCOL_CONFIG is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_PROVIDER_CONFIG is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_CIPHER_SUITES_CONFIG is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_CIPHER_SUITES_DOC is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG is 56.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_DOC is 53.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_SERVICE_NAME_CONFIG is 45.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_SERVICE_NAME_DOC is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_MECHANISM_CONFIG is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_MECHANISM_DOC is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_KINIT_CMD_CONFIG is 42.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_KINIT_CMD_DOC is 39.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN_CONFIG is 56.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN_DOC is 53.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_JITTER_CONFIG is 52.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_JITTER_DOC is 49.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_CONFIG is 59.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_DOC is 56.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKA_REST_RESOURCE_EXTENSION_CONFIG is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field KAFKA_REST_RESOURCE_EXTENSION_DOC is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONFLUENT_RESOURCE_NAME_AUTHORITY_DEFAULT is 41.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field CONFLUENT_RESOURCE_NAME_AUTHORITY_DOC is 37.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field API_ENDPOINTS_ALLOWLIST_CONFIG is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field API_ENDPOINTS_ALLOWLIST_DEFAULT is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field API_ENDPOINTS_BLOCKLIST_CONFIG is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field API_ENDPOINTS_BLOCKLIST_DEFAULT is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field RATE_LIMIT_PERMITS_PER_SEC_CONFIG is 33.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field RATE_LIMIT_PERMITS_PER_SEC_DEFAULT is 34.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field RATE_LIMIT_PERMITS_PER_SEC_DOC is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field RATE_LIMIT_DEFAULT_COST_CONFIG is 30.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field RATE_LIMIT_DEFAULT_COST_DEFAULT is 31.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_MS is 36.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_MS_DEFAULT is 44.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_MS_DOC is 40.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS is 49.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS_DEFAULT is 57.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS_DOC is 53.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Long Statement,The length of the statement "return baseConfigDef(KAFKAREST_PORT_DEFAULT`KAFKAREST_LISTENERS_DEFAULT`String.join("`"`Versions.PREFERRED_RESPONSE_TYPES)`MediaType.APPLICATION_JSON`METRICS_JMX_PREFIX_DEFAULT_OVERRIDE).define(ID_CONFIG`Type.STRING`ID_DEFAULT`Importance.HIGH`ID_CONFIG_DOC).define(HOST_NAME_CONFIG`Type.STRING`HOST_NAME_DEFAULT`Importance.MEDIUM`HOST_NAME_DOC).define(ADVERTISED_LISTENERS_CONFIG`Type.LIST`ADVERTISED_LISTENERS_DEFAULT`Importance.MEDIUM`ADVERTISED_LISTENERS_DOC).define(CONSUMER_MAX_THREADS_CONFIG`Type.INT`CONSUMER_MAX_THREADS_DEFAULT`Importance.MEDIUM`CONSUMER_MAX_THREADS_DOC).define(ZOOKEEPER_CONNECT_CONFIG`Type.STRING`ZOOKEEPER_CONNECT_DEFAULT`Importance.HIGH`ZOOKEEPER_CONNECT_DOC).define(BOOTSTRAP_SERVERS_CONFIG`Type.STRING`BOOTSTRAP_SERVERS_DEFAULT`Importance.HIGH`BOOTSTRAP_SERVERS_DOC).define(SCHEMA_REGISTRY_URL_CONFIG`Type.STRING`SCHEMA_REGISTRY_URL_DEFAULT`Importance.HIGH`SCHEMA_REGISTRY_URL_DOC).define(PROXY_FETCH_MIN_BYTES_CONFIG`Type.INT`PROXY_FETCH_MIN_BYTES_DEFAULT`PROXY_FETCH_MIN_BYTES_VALIDATOR`Importance.LOW`PROXY_FETCH_MIN_BYTES_DOC).define(PRODUCER_THREADS_CONFIG`Type.INT`PRODUCER_THREADS_DEFAULT`Importance.LOW`PRODUCER_THREADS_DOC).define(PRODUCE_RATE_LIMIT_ENABLED`Type.BOOLEAN`PRODUCE_RATE_LIMIT_ENABLED_DEFAULT`Importance.LOW`PRODUCE_RATE_LIMIT_ENABLED_DOC).define(PRODUCE_MAX_REQUESTS_PER_SECOND`Type.INT`PRODUCE_MAX_REQUESTS_PER_SECOND_DEFAULT`PRODUCE_MAX_REQUESTS_PER_SECOND_VALIDATOR`Importance.LOW`PRODUCE_MAX_REQUESTS_PER_SECOND_DOC).define(PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND`Type.INT`PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND_DEFAULT`PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND_VALIDATOR`Importance.LOW`PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND_DOC).define(PRODUCE_MAX_BYTES_PER_SECOND`Type.INT`PRODUCE_MAX_BYTES_PER_SECOND_DEFAULT`PRODUCE_MAX_BYTES_PER_SECOND_VALIDATOR`Importance.LOW`PRODUCE_MAX_BYTES_PER_SECOND_DOC).define(PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND`Type.INT`PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND_DEFAULT`PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND_VALIDATOR`Importance.LOW`PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND_DOC).define(PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS`Type.INT`PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS_DEFAULT`Importance.LOW`PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS_DOC).define(PRODUCE_RESPONSE_THREAD_POOL_SIZE`Type.INT`PRODUCE_RESPONSE_THREAD_POOL_SIZE_DEFAULT`PRODUCE_RESPONSE_THREAD_POOL_SIZE_VALIDATOR`Importance.LOW`PRODUCE_RESPONSE_THREAD_POOL_SIZE_DOC).define(CONSUMER_ITERATOR_TIMEOUT_MS_CONFIG`Type.INT`CONSUMER_ITERATOR_TIMEOUT_MS_DEFAULT`Importance.LOW`CONSUMER_ITERATOR_TIMEOUT_MS_DOC).define(CONSUMER_ITERATOR_BACKOFF_MS_CONFIG`Type.INT`CONSUMER_ITERATOR_BACKOFF_MS_DEFAULT`Importance.LOW`CONSUMER_ITERATOR_BACKOFF_MS_DOC).define(CONSUMER_REQUEST_TIMEOUT_MS_CONFIG`Type.INT`CONSUMER_REQUEST_TIMEOUT_MS_DEFAULT`Importance.MEDIUM`CONSUMER_REQUEST_TIMEOUT_MS_DOC).define(CONSUMER_REQUEST_MAX_BYTES_CONFIG`Type.LONG`CONSUMER_REQUEST_MAX_BYTES_DEFAULT`Importance.MEDIUM`CONSUMER_REQUEST_MAX_BYTES_DOC).define(CONSUMER_INSTANCE_TIMEOUT_MS_CONFIG`Type.INT`CONSUMER_INSTANCE_TIMEOUT_MS_DEFAULT`Importance.LOW`CONSUMER_INSTANCE_TIMEOUT_MS_DOC).define(SIMPLE_CONSUMER_MAX_POOL_SIZE_CONFIG`Type.INT`SIMPLE_CONSUMER_MAX_POOL_SIZE_DEFAULT`Importance.MEDIUM`SIMPLE_CONSUMER_MAX_POOL_SIZE_DOC).define(SIMPLE_CONSUMER_POOL_TIMEOUT_MS_CONFIG`Type.INT`SIMPLE_CONSUMER_POOL_TIMEOUT_MS_DEFAULT`Importance.LOW`SIMPLE_CONSUMER_POOL_TIMEOUT_MS_DOC).define(KAFKACLIENT_ZK_SESSION_TIMEOUT_MS_CONFIG`Type.INT`30000`Range.atLeast(0)`Importance.LOW`KAFKACLIENT_ZK_SESSION_TIMEOUT_MS_DOC).define(KAFKACLIENT_INIT_TIMEOUT_CONFIG`Type.INT`60000`Range.atLeast(0)`Importance.MEDIUM`KAFKACLIENT_INIT_TIMEOUT_DOC).define(KAFKACLIENT_TIMEOUT_CONFIG`Type.INT`500`Range.atLeast(0)`Importance.MEDIUM`KAFKACLIENT_TIMEOUT_DOC).define(KAFKACLIENT_SECURITY_PROTOCOL_CONFIG`Type.STRING`"PLAINTEXT"`Importance.MEDIUM`KAFKACLIENT_SECURITY_PROTOCOL_DOC).define(KAFKACLIENT_SSL_TRUSTSTORE_LOCATION_CONFIG`Type.STRING`""`Importance.HIGH`KAFKACLIENT_SSL_TRUSTSTORE_LOCATION_DOC).define(KAFKACLIENT_SSL_TRUSTSTORE_PASSWORD_CONFIG`Type.PASSWORD`""`Importance.HIGH`KAFKACLIENT_SSL_TRUSTSTORE_PASSWORD_DOC).define(KAFKACLIENT_SSL_TRUSTSTORE_TYPE_CONFIG`Type.STRING`"JKS"`Importance.MEDIUM`KAFKASTORE_SSL_TRUSTSTORE_TYPE_DOC).define(KAFKACLIENT_SSL_TRUSTMANAGER_ALGORITHM_CONFIG`Type.STRING`"PKIX"`Importance.LOW`KAFKACLIENT_SSL_TRUSTMANAGER_ALGORITHM_DOC).define(KAFKACLIENT_SSL_KEYSTORE_LOCATION_CONFIG`Type.STRING`""`Importance.HIGH`KAFKACLIENT_SSL_KEYSTORE_LOCATION_DOC).define(KAFKACLIENT_SSL_KEYSTORE_PASSWORD_CONFIG`Type.PASSWORD`""`Importance.HIGH`KAFKACLIENT_SSL_KEYSTORE_PASSWORD_DOC).define(KAFKACLIENT_SSL_KEYSTORE_TYPE_CONFIG`Type.STRING`"JKS"`Importance.MEDIUM`KAFKASTORE_SSL_KEYSTORE_TYPE_DOC).define(KAFKACLIENT_SSL_KEYMANAGER_ALGORITHM_CONFIG`Type.STRING`"SunX509"`Importance.LOW`KAFKACLIENT_SSL_KEYMANAGER_ALGORITHM_DOC).define(KAFKACLIENT_SSL_KEY_PASSWORD_CONFIG`Type.PASSWORD`""`Importance.HIGH`KAFKACLIENT_SSL_KEY_PASSWORD_DOC).define(KAFKACLIENT_SSL_ENABLED_PROTOCOLS_CONFIG`Type.STRING`"TLSv1.2`TLSv1.1`TLSv1"`Importance.MEDIUM`KAFKASTORE_SSL_ENABLED_PROTOCOLS_DOC).define(KAFKACLIENT_SSL_PROTOCOL_CONFIG`Type.STRING`"TLS"`Importance.MEDIUM`KAFKASTORE_SSL_PROTOCOL_DOC).define(KAFKACLIENT_SSL_PROVIDER_CONFIG`Type.STRING`""`Importance.MEDIUM`KAFKASTORE_SSL_PROVIDER_DOC).define(KAFKACLIENT_SSL_CIPHER_SUITES_CONFIG`Type.STRING`""`Importance.LOW`KAFKACLIENT_SSL_CIPHER_SUITES_DOC).define(KAFKACLIENT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG`Type.STRING`""`Importance.LOW`KAFKACLIENT_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_DOC).define(KAFKACLIENT_SASL_KERBEROS_SERVICE_NAME_CONFIG`Type.STRING`""`Importance.MEDIUM`KAFKACLIENT_SASL_KERBEROS_SERVICE_NAME_DOC).define(KAFKACLIENT_SASL_MECHANISM_CONFIG`Type.STRING`"GSSAPI"`Importance.MEDIUM`KAFKACLIENT_SASL_MECHANISM_DOC).define(KAFKACLIENT_SASL_KERBEROS_KINIT_CMD_CONFIG`Type.STRING`"/usr/bin/kinit"`Importance.LOW`KAFKACLIENT_SASL_KERBEROS_KINIT_CMD_DOC).define(KAFKACLIENT_SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN_CONFIG`Type.LONG`60000`Importance.LOW`KAFKACLIENT_SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN_DOC).define(KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_JITTER_CONFIG`Type.DOUBLE`0.05`Importance.LOW`KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_JITTER_DOC).define(KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_CONFIG`Type.DOUBLE`0.8`Importance.LOW`KAFKACLIENT_SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_DOC).define(KAFKA_REST_RESOURCE_EXTENSION_CONFIG`Type.LIST`""`Importance.LOW`KAFKA_REST_RESOURCE_EXTENSION_DOC).define(CRN_AUTHORITY_CONFIG`Type.STRING`CONFLUENT_RESOURCE_NAME_AUTHORITY_DEFAULT`Importance.LOW`CONFLUENT_RESOURCE_NAME_AUTHORITY_DOC).define(API_ENDPOINTS_ALLOWLIST_CONFIG`Type.LIST`API_ENDPOINTS_ALLOWLIST_DEFAULT`Importance.LOW`API_ENDPOINTS_ALLOWLIST_DOC).define(API_ENDPOINTS_BLOCKLIST_CONFIG`Type.LIST`API_ENDPOINTS_BLOCKLIST_DEFAULT`Importance.LOW`API_ENDPOINTS_BLOCKLIST_DOC).define(API_V2_ENABLE_CONFIG`Type.BOOLEAN`API_V2_ENABLE_DEFAULT`Importance.LOW`API_V2_ENABLE_DOC).define(API_V3_ENABLE_CONFIG`Type.BOOLEAN`API_V3_ENABLE_DEFAULT`Importance.LOW`API_V3_ENABLE_DOC).define(RATE_LIMIT_ENABLE_CONFIG`Type.BOOLEAN`RATE_LIMIT_ENABLE_DEFAULT`Importance.LOW`RATE_LIMIT_ENABLE_DOC).define(RATE_LIMIT_BACKEND_CONFIG`Type.STRING`RATE_LIMIT_BACKEND_DEFAULT`Importance.LOW`RATE_LIMIT_BACKEND_DOC).define(RATE_LIMIT_PERMITS_PER_SEC_CONFIG`Type.INT`RATE_LIMIT_PERMITS_PER_SEC_DEFAULT`Importance.LOW`RATE_LIMIT_PERMITS_PER_SEC_DOC).define(RATE_LIMIT_TIMEOUT_MS_CONFIG`Type.LONG`RATE_LIMIT_TIMEOUT_MS_DEFAULT`Importance.LOW`RATE_LIMIT_TIMEOUT_MS_DOC).define(RATE_LIMIT_DEFAULT_COST_CONFIG`Type.INT`RATE_LIMIT_DEFAULT_COST_DEFAULT`Importance.LOW`RATE_LIMIT_DEFAULT_COST_DOC).define(RATE_LIMIT_COSTS_CONFIG`Type.STRING`RATE_LIMIT_COSTS_DEFAULT`Importance.LOW`RATE_LIMIT_COSTS_DOC).define(STREAMING_CONNECTION_MAX_DURATION_MS`Type.LONG`STREAMING_CONNECTION_MAX_DURATION_MS_DEFAULT`Importance.LOW`STREAMING_CONNECTION_MAX_DURATION_MS_DOC).define(STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS`Type.LONG`STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS_DEFAULT`Importance.LOW`STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS_DOC);" is 8102.,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Magic Number,The method contains a magic number: 30000,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Magic Number,The method contains a magic number: 60000,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Magic Number,The method contains a magic number: 500,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Magic Number,The method contains a magic number: 60000,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Magic Number,The method contains a magic number: 0.05,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,baseKafkaRestConfigDef,Magic Number,The method contains a magic number: 0.8,479
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,KafkaRestConfig,Long Statement,The length of the statement "metricsContext=new KafkaRestMetricsContext(getString(METRICS_JMX_PREFIX_CONFIG)`originalsWithPrefix(METRICS_CONTEXT_PREFIX));" is 125.,880
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getSchemaRegistryConfigs,Long Statement,The length of the statement "ImmutableSet<String> mask=ImmutableSet.<String>builder().addAll(AbstractKafkaSchemaSerDeConfig.baseConfigDef().names()).add(SaslConfigs.SASL_JAAS_CONFIG).build();" is 162.,897
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getSchemaRegistryConfigs,Long Statement,The length of the statement "Map<String`Object> configs=new HashMap<>(new ConfigsBuilder(mask).addConfig("schema.registry.url").addConfigs("schema.registry.").addConfigs("schema.registry.ssl."`false).addConfigs("client.").addConfigs("producer.").addConfigs("consumer.").build());" is 250.,897
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getSchemaRegistryConfigs,Long Statement,The length of the statement "log.warn("Using default value {} for config {}. In a future release this config won't have a " + "default value anymore. If you are using Schema Registry` please` specify {} " + "explicitly. Requests will fail in a future release if you try to use Schema "+ "Registry but have not specified a value for {}. An empty value for this property "+ "means that the Schema Registry is disabled."`SCHEMA_REGISTRY_URL_DEFAULT`SCHEMA_REGISTRY_URL_CONFIG`SCHEMA_REGISTRY_URL_CONFIG`SCHEMA_REGISTRY_URL_CONFIG);" is 499.,897
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getSchemaRegistryConfigs,Long Statement,The length of the statement "log.warn("Config {} is not supported in Kafka REST and will be ignored. Please remove this " + "config. Configuration will fail in a future release for such cases."`AUTO_REGISTER_SCHEMAS);" is 188.,897
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getSchemaRegistryConfigs,Long Statement,The length of the statement "log.warn("Config {} is not supported in Kafka REST and will be ignored. Please remove this " + "config. Configuration will fail in a future release for such cases."`USE_LATEST_VERSION);" is 185.,897
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getAvroSerializerConfigs,Long Statement,The length of the statement "HashMap<String`Object> configs=new HashMap<>(new ConfigsBuilder(mask).addConfigs("client.").addConfigs("producer.").build());" is 125.,958
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getJsonschemaSerializerConfigs,Long Statement,The length of the statement "Set<String> mask=ImmutableSet.of(KafkaJsonSchemaSerializerConfig.JSON_INDENT_OUTPUT`KafkaJsonSchemaSerializerConfig.FAIL_INVALID_SCHEMA`KafkaJsonSchemaSerializerConfig.ONEOF_FOR_NULLABLES`KafkaJsonSchemaSerializerConfig.SCHEMA_SPEC_VERSION);" is 241.,967
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getJsonschemaSerializerConfigs,Long Statement,The length of the statement "HashMap<String`Object> configs=new HashMap<>(new ConfigsBuilder(mask).addConfigs("client.").addConfigs("producer.").build());" is 125.,967
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getProtobufSerializerConfigs,Long Statement,The length of the statement "HashMap<String`Object> configs=new HashMap<>(new ConfigsBuilder(mask).addConfigs("client.").addConfigs("producer.").build());" is 125.,981
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getProducerProperties,Long Statement,The length of the statement "Map<String`Object> producerConfigs=new ConfigsBuilder().addConfig(BOOTSTRAP_SERVERS_CONFIG).addConfigs("client.").addConfigs("producer.").addConfigs("schema.registry."`false).build();" is 183.,991
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getProducerConfigs,Long Statement,The length of the statement "return getProducerProperties().entrySet().stream().collect(Collectors.toMap(entry -> entry.getKey().toString()`Entry::getValue));" is 129.,1016
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getRateLimitPermitsPerSec,Long Identifier,The length of the field RATE_LIMIT_PERMITS_PER_SEC_CONFIG is 33.,1075
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getStreamingConnectionMaxDuration,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_MS is 36.,1083
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getStreamingConnectionMaxDurationGracePeriod,Long Identifier,The length of the field STREAMING_CONNECTION_MAX_DURATION_GRACE_PERIOD_MS is 49.,1087
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getRateLimitDefaultCost,Long Identifier,The length of the field RATE_LIMIT_DEFAULT_COST_CONFIG is 30.,1091
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfig,getRateLimitCosts,Long Statement,The length of the statement "return Arrays.stream(value.split("`")).map(String::trim).filter(entry -> !entry.isEmpty()).peek(entry -> checkArgument(entry.contains("=")`String.format("Invalid value for config %s: %s. Example valid value: " + "\"api.v3.clusters.*=1`api.v3.brokers.list=2\". A cost of zero means " + "no rate-limit."`RATE_LIMIT_COSTS_CONFIG`value))).collect(toImmutableMap(entry -> entry.substring(0`entry.indexOf('=')).trim()`entry -> Integer.valueOf(entry.substring(entry.indexOf('=') + 1).trim())));" is 487.,1095
confluentinc_kafka-rest,io.confluent.kafkarest,DefaultKafkaRestContext,getSchemaRegistryClient,Long Statement,The length of the statement "List<String> schemaRegistryUrls=schemaRegistryConfig.getSchemaRegistryUrls().stream().map(URI::create).map(Object::toString).collect(Collectors.toList());" is 154.,78
confluentinc_kafka-rest,io.confluent.kafkarest,DefaultKafkaRestContext,getSchemaRegistryClient,Long Statement,The length of the statement "schemaRegistryClient=new CachedSchemaRegistryClient(schemaRegistryUrls`schemaRegistryConfig.getMaxSchemasPerSubject()`SCHEMA_PROVIDERS`config.getSchemaRegistryConfigs()`schemaRegistryConfig.requestHeaders());" is 208.,78
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestApplication,KafkaRestApplication,Long Statement,The length of the statement "restResourceExtensions=config.getConfiguredInstances(KafkaRestConfig.KAFKA_REST_RESOURCE_EXTENSION_CONFIG`RestResourceExtension.class);" is 135.,71
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestApplication,setupResources,Long Statement,The length of the statement "if (StringUtil.isBlank(appConfig.getString(KafkaRestConfig.BOOTSTRAP_SERVERS_CONFIG)) && StringUtil.isBlank(appConfig.getString(KafkaRestConfig.ZOOKEEPER_CONNECT_CONFIG))) {" is 173.,86
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestApplication,setupResources,Long Statement,The length of the statement "throw new RuntimeException("Atleast one of " + KafkaRestConfig.BOOTSTRAP_SERVERS_CONFIG + " "+ "or "+ KafkaRestConfig.ZOOKEEPER_CONNECT_CONFIG+ " needs to be configured");" is 171.,86
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestApplication,getJsonMapper,Long Statement,The length of the statement "return super.getJsonMapper().registerModule(new GuavaModule()).registerModule(new Jdk8Module()).registerModule(new JavaTimeModule()).configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS`false).setDateFormat(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'")).setTimeZone(TimeZone.getTimeZone("UTC"));" is 302.,119
confluentinc_kafka-rest,io.confluent.kafkarest,UriUtils,absoluteUri,Long Statement,The length of the statement "advertisedListeners=config.getList(KafkaRestConfig.ADVERTISED_LISTENERS_CONFIG).stream().map(URI::create).collect(Collectors.toList());" is 135.,27
confluentinc_kafka-rest,io.confluent.kafkarest,UriUtils,absoluteUri,Long Statement,The length of the statement "return new UrlFactoryImpl(config.getString(KafkaRestConfig.HOST_NAME_CONFIG)`config.getInt(KafkaRestConfig.PORT_CONFIG)`advertisedListeners`listeners`uriInfo).create(components);" is 178.,27
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,partitionNotFoundException,Long Identifier,The length of the field PARTITION_NOT_FOUND_ERROR_CODE is 30.,47
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerInstanceNotFoundException,Long Identifier,The length of the field CONSUMER_INSTANCE_NOT_FOUND_MESSAGE is 35.,54
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerInstanceNotFoundException,Long Identifier,The length of the field CONSUMER_INSTANCE_NOT_FOUND_ERROR_CODE is 38.,54
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,leaderNotAvailableException,Long Identifier,The length of the field LEADER_NOT_AVAILABLE_ERROR_CODE is 31.,62
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerFormatMismatch,Long Identifier,The length of the field CONSUMER_FORMAT_MISMATCH_MESSAGE is 32.,71
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerFormatMismatch,Long Identifier,The length of the field CONSUMER_FORMAT_MISMATCH_ERROR_CODE is 35.,71
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerFormatMismatch,Long Statement,The length of the statement "return new RestException(CONSUMER_FORMAT_MISMATCH_MESSAGE`Response.Status.NOT_ACCEPTABLE.getStatusCode()`CONSUMER_FORMAT_MISMATCH_ERROR_CODE);" is 142.,71
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerAlreadySubscribedException,Long Identifier,The length of the field CONSUMER_ALREADY_SUBSCRIBED_MESSAGE is 35.,83
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerAlreadySubscribedException,Long Identifier,The length of the field CONSUMER_ALREADY_SUBSCRIBED_ERROR_CODE is 38.,83
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerAlreadySubscribedException,Long Statement,The length of the statement "return new RestException(CONSUMER_ALREADY_SUBSCRIBED_MESSAGE`Response.Status.CONFLICT.getStatusCode()`CONSUMER_ALREADY_SUBSCRIBED_ERROR_CODE);" is 142.,83
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerAlreadyExistsException,Long Identifier,The length of the field CONSUMER_ALREADY_EXISTS_MESSAGE is 31.,94
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerAlreadyExistsException,Long Identifier,The length of the field CONSUMER_ALREADY_EXISTS_ERROR_CODE is 34.,94
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,consumerAlreadyExistsException,Long Statement,The length of the statement "return new RestException(CONSUMER_ALREADY_EXISTS_MESSAGE`Response.Status.CONFLICT.getStatusCode()`CONSUMER_ALREADY_EXISTS_ERROR_CODE);" is 134.,94
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,illegalStateException,Long Statement,The length of the statement "return new RestException(ILLEGAL_STATE_MESSAGE + t.getMessage()`Response.Status.CONFLICT.getStatusCode()`ILLEGAL_STATE_ERROR_CODE);" is 131.,104
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,valueSchemaMissingException,Long Identifier,The length of the field VALUE_SCHEMA_MISSING_ERROR_CODE is 31.,124
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,invalidConsumerConfigException,Long Identifier,The length of the field INVALID_CONSUMER_CONFIG_MESSAGE is 31.,140
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,invalidConsumerConfigException,Long Identifier,The length of the field INVALID_CONSUMER_CONFIG_ERROR_CODE is 34.,140
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,invalidConsumerConfigException,Long Statement,The length of the statement "return new RestConstraintViolationException(INVALID_CONSUMER_CONFIG_MESSAGE + exceptionMessage`INVALID_CONSUMER_CONFIG_ERROR_CODE);" is 131.,140
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,invalidConsumerConfigConstraintException,Long Identifier,The length of the field INVALID_CONSUMER_CONFIG_CONSTRAINT_MESSAGE is 42.,150
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,invalidConsumerConfigConstraintException,Long Identifier,The length of the field INVALID_CONSUMER_CONFIG_CONSTAINT_ERROR_CODE is 44.,150
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,invalidConsumerConfigConstraintException,Long Statement,The length of the statement "return new RestConstraintViolationException(INVALID_CONSUMER_CONFIG_CONSTRAINT_MESSAGE + e.getMessage()`INVALID_CONSUMER_CONFIG_CONSTAINT_ERROR_CODE);" is 150.,150
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,messageSerializationException,Long Identifier,The length of the field SERIALIZATION_EXCEPTION_MESSAGE is 31.,176
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,messageSerializationException,Long Identifier,The length of the field SERIALIZATION_EXCEPTION_ERROR_CODE is 34.,176
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,messageSerializationException,Long Identifier,The length of the field SERIALIZATION_EXCEPTION_MESSAGE is 31.,181
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,messageSerializationException,Long Identifier,The length of the field SERIALIZATION_EXCEPTION_ERROR_CODE is 34.,181
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,messageSerializationException,Long Statement,The length of the statement "return new RestConstraintViolationException(SERIALIZATION_EXCEPTION_MESSAGE + cause + "\n"+ e.getMessage()`SERIALIZATION_EXCEPTION_ERROR_CODE);" is 143.,181
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,simpleConsumerPoolTimeoutException,Long Identifier,The length of the field NO_SIMPLE_CONSUMER_AVAILABLE_ERROR_MESSAGE is 42.,215
confluentinc_kafka-rest,io.confluent.kafkarest,Errors,simpleConsumerPoolTimeoutException,Long Identifier,The length of the field NO_SIMPLE_CONSUMER_AVAILABLE_ERROR_CODE is 39.,215
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestMetricsContext,KafkaRestMetricsContext,Long Identifier,The length of the field KAFKA_REST_RESOURCE_CLUSTER_ID_DEFAULT is 38.,35
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestMetricsContext,KafkaRestMetricsContext,Long Statement,The length of the statement "setResourceLabel(RESOURCE_LABEL_CLUSTER_ID`(String)config.getOrDefault(RESOURCE_LABEL_CLUSTER_ID`KAFKA_REST_RESOURCE_CLUSTER_ID_DEFAULT));" is 138.,35
confluentinc_kafka-rest,io.confluent.kafkarest,ConsumerInstanceId,hashCode,Magic Number,The method contains a magic number: 31,57
confluentinc_kafka-rest,io.confluent.kafkarest,OpenConfigEntry,OpenConfigEntry,Long Parameter List,The method has 5 parameters. ,35
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfigTest,getProducerProperties_propagateMetricsProperties,Long Statement,The length of the statement "assertEquals(Arrays.asList("metrics.reporter.1"`"metrics.reporter.2"`"metrics.reporter.3")`producerProperties.get(METRICS_REPORTER_CLASSES_CONFIG));" is 148.,62
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfigTest,getConsumerProperties_propagateMetricsProperties,Long Statement,The length of the statement "assertEquals(Arrays.asList("metrics.reporter.1"`"metrics.reporter.2"`"metrics.reporter.3")`consumerProperties.get(METRICS_REPORTER_CLASSES_CONFIG));" is 148.,110
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfigTest,getAdminProperties_propagateMetricsProperties,Long Statement,The length of the statement "assertEquals(Arrays.asList("metrics.reporter.1"`"metrics.reporter.2"`"metrics.reporter.3")`adminProperties.get(METRICS_REPORTER_CLASSES_CONFIG));" is 145.,148
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfigTest,getAvroSerializerConfigs,Long Statement,The length of the statement "assertEquals(ImmutableMap.of("schema.registry.url"`"foobar"`"auto.register.schemas"`false`"use.latest.version"`false)`config.getAvroSerializerConfigs());" is 153.,254
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfigTest,getJsonschemaSerializerConfigs,Long Statement,The length of the statement "assertEquals(ImmutableMap.of("schema.registry.url"`"foobar"`"auto.register.schemas"`false`"use.latest.version"`false`"json.fail.invalid.schema"`true)`config.getJsonschemaSerializerConfigs());" is 191.,269
confluentinc_kafka-rest,io.confluent.kafkarest,KafkaRestConfigTest,getProtobufSerializerConfigs,Long Statement,The length of the statement "assertEquals(ImmutableMap.of("schema.registry.url"`"foobar"`"auto.register.schemas"`false`"use.latest.version"`false`"reference.subject.name.strategy"`DefaultReferenceSubjectNameStrategy.class)`config.getProtobufSerializerConfigs());" is 233.,287
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,assertErrorResponse,Long Parameter List,The method has 5 parameters. ,94
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,encodeComparable,Complex Conditional,The conditional expression k instanceof Number || k instanceof Boolean || k instanceof Character|| k instanceof String is complex.,162
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,encodeComparable,Complex Method,Cyclomatic complexity of the method is 8,162
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,assertTopicContains,Long Parameter List,The method has 8 parameters. ,191
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,assertTopicContains,Long Statement,The length of the statement "KafkaConsumer<K`V> consumer=createConsumer(bootstrapServers`"testgroup"`"consumer0"`20000L`keyDeserializerClassName`valueDeserializerClassName`deserializerProps);" is 162.,191
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,assertTopicContains,Magic Number,The method contains a magic number: 20000L,191
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,assertTopicContains,Long Parameter List,The method has 7 parameters. ,245
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,assertTopicContains,Long Statement,The length of the statement "assertTopicContains(bootstrapServers`topicName`records`partition`keyDeserializerClassName`valueDeserializerClassName`new Properties()`validateContents);" is 152.,245
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,testWithRetry,Long Parameter List,The method has 5 parameters. ,274
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,testWithRetry,Long Statement,The length of the statement "throw new AssertionError(String.format("Failed after %d ms elapsed and %d%s retries with %d ms initial retry interval."`TimeUnit.NANOSECONDS.toMillis(elapsed)`numRetries`isExponentialBackoff ? " exponential backoff" : ""`initialRetryInterval.toMillis())`t);" is 257.,274
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,testWithRetry,Magic Number,The method contains a magic number: 2,274
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,waitForCondition,Long Statement,The length of the statement "throw new AssertionError(String.format("Condition '%s' not met after waiting for %d ms"`conditionDetailsSupplier.get()`timeout.toMillis())`ae);" is 143.,334
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,waitForCondition,Long Statement,The length of the statement "throw new AssertionError(String.format("Unexpected error while waiting for condition '%s'"`conditionDetailsSupplier.get())`t);" is 126.,334
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,topicCounts,Magic Number,The method contains a magic number: 100,382
confluentinc_kafka-rest,io.confluent.kafkarest,TestUtils,createConsumer,Long Parameter List,The method has 7 parameters. ,413
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,main,Long Statement,The length of the statement "System.out.println("Usage: java " + ProducerPerformance.class.getName() + " rest_url topic_name "+ "num_records record_size batch_size target_records_sec");" is 156.,44
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,main,Magic Number,The method contains a magic number: 6,44
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,main,Magic Number,The method contains a magic number: 2,44
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,main,Magic Number,The method contains a magic number: 3,44
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,main,Magic Number,The method contains a magic number: 4,44
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,main,Magic Number,The method contains a magic number: 5,44
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,ProducerPerformance,Long Parameter List,The method has 6 parameters. ,67
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,ProducerPerformance,Long Statement,The length of the statement "BinaryTopicProduceRequest.BinaryTopicProduceRecord record=new BinaryTopicProduceRequest.BinaryTopicProduceRecord(null`"payload"`null);" is 134.,67
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,ProducerPerformance,Long Statement,The length of the statement "BinaryTopicProduceRequest.BinaryTopicProduceRecord[] records=new BinaryTopicProduceRequest.BinaryTopicProduceRecord[recordsPerIteration];" is 137.,67
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,ProducerPerformance,Magic Number,The method contains a magic number: 1024,67
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,ProducerPerformance,Magic Number,The method contains a magic number: 1024,67
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,doIteration,Long Statement,The length of the statement "throw new RuntimeException(String.format("Unexpected HTTP error status %d: %s"`responseStatus`errorMessage.getMessage()));" is 122.,94
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ProducerPerformance,doIteration,Magic Number,The method contains a magic number: 400,94
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,main,Long Statement,The length of the statement "System.out.println("Usage: java " + ConsumerPerformance.class.getName() + " rest_url topic_name "+ "num_records target_records_sec");" is 133.,50
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,main,Magic Number,The method contains a magic number: 4,50
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,main,Magic Number,The method contains a magic number: 2,50
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,main,Magic Number,The method contains a magic number: 3,50
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,ConsumerPerformance,Long Statement,The length of the statement "CreateConsumerInstanceRequest consumerConfig=new CreateConsumerInstanceRequest(null`null`null`"earliest"`null`null`null);" is 121.,74
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,ConsumerPerformance,Long Statement,The length of the statement "CreateConsumerInstanceResponse createResponse=(CreateConsumerInstanceResponse)request(baseUrl + "/consumers/" + groupId`"POST"`createPayload`Integer.toString(createPayload.length)`new TypeReference<CreateConsumerInstanceResponse>(){" is 232.,74
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,ConsumerPerformance,Long Statement,The length of the statement "request(instanceUrl + "/subscription"`"POST"`subscribePayload`Integer.toString(subscribePayload.length)`new TypeReference<ConsumerSubscriptionResponse>(){" is 154.,74
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,ConsumerPerformance,Magic Number,The method contains a magic number: 100000,74
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,doIteration,Long Statement,The length of the statement "List<UndecodedConsumerRecord> records=request(targetUrl`"GET"`null`null`new TypeReference<List<UndecodedConsumerRecord>>(){" is 123.,129
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,doIteration,Magic Number,The method contains a magic number: 3,129
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,doIteration,Magic Number,The method contains a magic number: 4,129
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,request,Long Parameter List,The method has 5 parameters. ,146
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,request,Long Statement,The length of the statement "throw new RuntimeException(String.format("Unexpected HTTP error status %d for %s request to %s: %s"`responseStatus`method`target`errorMessage.getMessage()));" is 157.,146
confluentinc_kafka-rest,io.confluent.kafkarest.tools,ConsumerPerformance,request,Magic Number,The method contains a magic number: 400,146
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFutures,allAsList,Long Statement,The length of the statement "return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).thenApply(none -> futures.stream().map(CompletableFuture::join).collect(Collectors.toList()));" is 168.,28
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_catchingFailure_catchesFailure,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`NumberFormatException.class`error -> CompletableFuture.completedFuture(0));" is 208.,27
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_catchingDifferentException_propagatesFailure,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`NumberFormatException.class`error -> CompletableFuture.completedFuture(0));" is 208.,40
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_multiCatch_correctHandlerTriggered,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`NumberFormatException.class`error -> CompletableFuture.completedFuture(0))`NullPointerException.class`error -> CompletableFuture.completedFuture(1));" is 317.,57
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,completedStage_catchingFailure_propagatesResult,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`NumberFormatException.class`error -> CompletableFuture.completedFuture(0));" is 208.,73
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,completedStage_catchingFailure_propagatesResult,Magic Number,The method contains a magic number: 103,73
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_checkedException_catchingFailure_catchesFailure,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`IOException.class`error -> CompletableFuture.completedFuture(0));" is 198.,86
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_checkedException_catchingDifferentException_propagatesFailure,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`NumberFormatException.class`error -> CompletableFuture.completedFuture(0));" is 208.,99
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_checkedException_multiCatch_correctHandlerTriggered,Long Statement,The length of the statement "CompletableFuture<Integer> throwing=CompletableFutures.catchingCompose(CompletableFutures.catchingCompose(CompletableFutures.catchingCompose(future.thenApply(str -> str.length() + Integer.parseInt(str))`NumberFormatException.class`error -> CompletableFuture.completedFuture(0))`NullPointerException.class`error -> CompletableFuture.completedFuture(1))`IOException.class`error -> CompletableFuture.completedFuture(3));" is 417.,116
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_checkedException_multiCatch_correctHandlerTriggered,Magic Number,The method contains a magic number: 3,116
confluentinc_kafka-rest,io.confluent.kafkarest.common,CompletableFuturesTest,failingStage_checkedException_multiCatch_correctHandlerTriggered,Magic Number,The method contains a magic number: 3,116
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getList(KafkaRestConfig.ADVERTISED_LISTENERS_CONFIG).stream().map(URI::create).collect(Collectors.toList())).qualifiedBy(new AdvertisedListenersConfigImpl()).to(new TypeLiteral<List<URI>>(){" is 202.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(new HashSet<>(config.getList(KafkaRestConfig.API_ENDPOINTS_ALLOWLIST_CONFIG))).qualifiedBy(new ApiEndpointsAllowlistConfigImpl()).to(new TypeLiteral<Set<String>>(){" is 169.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(new HashSet<>(config.getList(KafkaRestConfig.API_ENDPOINTS_BLOCKLIST_CONFIG))).qualifiedBy(new ApiEndpointsBlocklistConfigImpl()).to(new TypeLiteral<Set<String>>(){" is 169.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getAvroSerializerConfigs()).qualifiedBy(new AvroSerializerConfigsImpl()).to(new TypeLiteral<Map<String`Object>>(){" is 126.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getJsonSerializerConfigs()).qualifiedBy(new JsonSerializerConfigsImpl()).to(new TypeLiteral<Map<String`Object>>(){" is 126.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getJsonschemaSerializerConfigs()).qualifiedBy(new JsonschemaSerializerConfigsImpl()).to(new TypeLiteral<Map<String`Object>>(){" is 138.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getList(RestConfig.LISTENERS_CONFIG).stream().map(URI::create).collect(Collectors.toList())).qualifiedBy(new ListenersConfigImpl()).to(new TypeLiteral<List<URI>>(){" is 176.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(schemaRegistryConfig.getMaxSchemasPerSubject()).qualifiedBy(new MaxSchemasPerSubjectConfigImpl()).to(Integer.class);" is 121.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getInt(KafkaRestConfig.PRODUCE_MAX_BYTES_PER_SECOND)).qualifiedBy(new ProduceRateLimitBytesConfigImpl()).to(Integer.class);" is 135.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getInt(KafkaRestConfig.PRODUCE_MAX_REQUESTS_PER_SECOND)).qualifiedBy(new ProduceRateLimitCountConfigImpl()).to(Integer.class);" is 138.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getInt(KafkaRestConfig.PRODUCE_MAX_REQUESTS_GLOBAL_PER_SECOND)).qualifiedBy(new ProduceRateLimitCountGlobalConfigImpl()).to(Integer.class);" is 151.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getInt(KafkaRestConfig.PRODUCE_MAX_BYTES_GLOBAL_PER_SECOND)).qualifiedBy(new ProduceRateLimitBytesGlobalConfigImpl()).to(Integer.class);" is 148.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(Duration.ofMillis(config.getInt(KafkaRestConfig.PRODUCE_RATE_LIMIT_CACHE_EXPIRY_MS))).qualifiedBy(new ProduceRateLimitCacheExpiryConfigImpl()).to(Duration.class);" is 167.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getBoolean(KafkaRestConfig.PRODUCE_RATE_LIMIT_ENABLED)).qualifiedBy(new ProduceRateLimitEnabledConfigImpl()).to(Boolean.class);" is 139.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getInt(KafkaRestConfig.PRODUCE_RESPONSE_THREAD_POOL_SIZE)).qualifiedBy(new ProduceResponseThreadPoolSizeImpl()).to(Integer.class);" is 142.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getProtobufSerializerConfigs()).qualifiedBy(new ProtobufSerializerConfigsImpl()).to(new TypeLiteral<Map<String`Object>>(){" is 134.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getStreamingConnectionMaxDuration()).qualifiedBy(new StreamingConnectionMaxDurationConfigImpl()).to(Duration.class);" is 128.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getStreamingConnectionMaxDurationGracePeriod()).qualifiedBy(new StreamingConnectionMaxDurationGracePeriodImpl()).to(Duration.class);" is 144.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(config.getSchemaRegistryConfigs()).qualifiedBy(new SchemaRegistryConfigsImpl()).to(new TypeLiteral<Map<String`Object>>(){" is 126.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(schemaRegistryConfig.requestHeaders()).qualifiedBy(new SchemaRegistryRequestHeadersConfigImpl()).to(new TypeLiteral<Map<String`String>>(){" is 143.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,ConfigModule,configure,Long Statement,The length of the statement "bind(schemaRegistryConfig.getSchemaRegistryUrls().stream().map(URI::create).collect(Collectors.toList())).qualifiedBy(new SchemaRegistryUrlsConfigImpl()).to(new TypeLiteral<List<URI>>(){" is 186.,55
confluentinc_kafka-rest,io.confluent.kafkarest.config,SchemaRegistryConfig,getSubjectNameStrategy,Long Statement,The length of the statement "return new SubjectNameStrategyImpl((SubjectNameStrategy)keySubjectNameStrategy()`(SubjectNameStrategy)valueSubjectNameStrategy());" is 130.,44
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitExceededException,RateLimitExceededException,Long Statement,The length of the statement "super(Response.Status.TOO_MANY_REQUESTS`"Request rate limit exceeded"`"The rate limit of requests per second has been exceeded.");" is 130.,28
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitModule,configure,Long Statement,The length of the statement "bindFactory(RequestRateLimiterGenericFactory.class).qualifiedBy(new RequestRateLimiterGenericImpl()).to(RequestRateLimiter.class).in(Singleton.class);" is 150.,33
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitModule,configure,Long Statement,The length of the statement "bindFactory(RequestRateLimiterProduceCountFactory.class).qualifiedBy(new ProduceRateLimiterCountImpl()).to(RequestRateLimiter.class).in(PerLookup.class);" is 153.,33
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitModule,configure,Long Statement,The length of the statement "bindFactory(RequestRateLimiterProduceBytesFactory.class).qualifiedBy(new ProduceRateLimiterBytesImpl()).to(RequestRateLimiter.class).in(PerLookup.class);" is 153.,33
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitModule,configure,Long Statement,The length of the statement "bindFactory(RequestRateLimiterProduceCountGlobalFactory.class).qualifiedBy(new ProduceRateLimiterCountGlobalImpl()).to(RequestRateLimiter.class).in(Singleton.class);" is 165.,33
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitModule,configure,Long Statement,The length of the statement "bindFactory(RequestRateLimiterProduceBytesGlobalFactory.class).qualifiedBy(new ProduceRateLimiterBytesGlobalImpl()).to(RequestRateLimiter.class).in(Singleton.class);" is 165.,33
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RequestRateLimiterFactory,provide,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@1d154608,35
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,Resilience4JRateLimiter,create,Long Statement,The length of the statement "RateLimiterConfig config=RateLimiterConfig.custom().timeoutDuration(timeout).limitRefreshPeriod(Duration.ofSeconds(1)).limitForPeriod(permitsPerSecond).build();" is 160.,32
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,Resilience4jRateLimitTest,getWarmupRequests,Magic Number,The method contains a magic number: 750,36
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,Resilience4jRateLimitTest,getTotalRequests,Magic Number,The method contains a magic number: 1750,41
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitDisabledTest,rateLimitDisabled_doesNotRateLimit,Magic Number,The method contains a magic number: 1000,42
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,RateLimitDisabledTest,rateLimitDisabled_doesNotRateLimit,Magic Number,The method contains a magic number: 1000,42
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,DoNotRateLimitTest,doNotRateLimitOnClass,Magic Number,The method contains a magic number: 1000,47
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,DoNotRateLimitTest,doNotRateLimitOnClass,Magic Number,The method contains a magic number: 1000,47
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,DoNotRateLimitTest,doNotRateLimitOnMethod,Magic Number,The method contains a magic number: 1000,53
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,DoNotRateLimitTest,doNotRateLimitOnMethod,Magic Number,The method contains a magic number: 1000,53
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,GuavaRateLimitTest,getWarmupRequests,Magic Number,The method contains a magic number: 500,36
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,GuavaRateLimitTest,getTotalRequests,Magic Number,The method contains a magic number: 1500,41
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,GuavaRateLimitTest,getSlack,Magic Number,The method contains a magic number: 10,46
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitTest,setUp,Magic Number,The method contains a magic number: 4,69
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitTest,hammerAtConstantRate,Long Statement,The length of the statement "List<Response> responses=IntStream.range(0`totalRequests).mapToObj(i -> executor.schedule(() -> target(path).request(MediaType.APPLICATION_JSON_TYPE).get()`i * rate.toMillis()`TimeUnit.MILLISECONDS)).collect(Collectors.toList()).stream().map(future -> {" is 253.,83
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitTest,hammerAtConstantRate,Long Statement,The length of the statement "fail(String.format("Expected HTTP 200 or HTTP 429` but got HTTP %d instead: %s"`status`response.readEntity(String.class)));" is 123.,83
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitTest,hammerAtConstantRate,Long Statement,The length of the statement "return (int)responses.subList(warmupRequests`responses.size()).stream().filter(response -> response.getStatus() == Status.OK.getStatusCode()).count();" is 150.,83
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitTest,hammerAtConstantRate,Magic Number,The method contains a magic number: 200,83
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitTest,hammerAtConstantRate,Magic Number,The method contains a magic number: 429,83
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitEnabledTest,rateLimitWithDefaultCost,Magic Number,The method contains a magic number: 500,58
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitEnabledTest,rateLimitWithDefaultCost,Magic Number,The method contains a magic number: 500,58
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitEnabledTest,rateLimitWithClassCost,Magic Number,The method contains a magic number: 250,70
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitEnabledTest,rateLimitWithClassCost,Magic Number,The method contains a magic number: 250,70
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitEnabledTest,rateLimitWithMethodCost,Magic Number,The method contains a magic number: 125,76
confluentinc_kafka-rest,io.confluent.kafkarest.ratelimit,AbstractRateLimitEnabledTest,rateLimitWithMethodCost,Magic Number,The method contains a magic number: 125,76
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImpl,produce,Long Parameter List,The method has 7 parameters. ,45
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImpl,produce,Long Statement,The length of the statement "producer.send(new ProducerRecord<>(topicName`partitionId.orElse(null)`timestamp.toEpochMilli()`key.map(ByteString::toByteArray).orElse(null)`value.map(ByteString::toByteArray).orElse(null)`headers.entries().stream().map(header -> new RecordHeader(header.getKey()`header.getValue().map(ByteString::toByteArray).orElse(null))).collect(Collectors.toList()))`(metadata`exception) -> {" is 380.,45
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,listTopicConfigs,Long Statement,The length of the statement "return listConfigs(clusterId`new ConfigResource(ConfigResource.Type.TOPIC`topicName)`TopicConfig.builder().setClusterId(clusterId).setTopicName(topicName));" is 156.,37
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,listTopicConfigs,Long Statement,The length of the statement "List<ConfigResource> topicResources=topicNames.stream().map(topicName -> new ConfigResource(ConfigResource.Type.TOPIC`topicName)).collect(Collectors.toList());" is 159.,45
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,listTopicConfigs,Long Statement,The length of the statement "return listConfigs(clusterId`topicResources`TopicConfig.builder().setClusterId(clusterId).setTopicName("")).thenApply(configs -> configs.entrySet().stream().collect(Collectors.toMap(e -> e.getKey().name()`e -> e.getValue().stream().map(config -> TopicConfig.create(config.getClusterId()`e.getKey().name()`config.getName()`config.getValue()`config.isDefault()`config.isReadOnly()`config.isSensitive()`config.getSource()`config.getSynonyms())).collect(Collectors.toList()))));" is 474.,45
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,getTopicConfig,Long Statement,The length of the statement "return getConfig(clusterId`new ConfigResource(ConfigResource.Type.TOPIC`topicName)`TopicConfig.builder().setClusterId(clusterId).setTopicName(topicName)`name);" is 159.,79
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,updateTopicConfig,Long Statement,The length of the statement "return safeUpdateConfig(clusterId`new ConfigResource(ConfigResource.Type.TOPIC`topicName)`TopicConfig.builder().setClusterId(clusterId).setTopicName(topicName)`name`newValue);" is 175.,89
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,resetTopicConfig,Long Statement,The length of the statement "return safeResetConfig(clusterId`new ConfigResource(ConfigResource.Type.TOPIC`topicName)`TopicConfig.builder().setClusterId(clusterId).setTopicName(topicName)`name);" is 165.,100
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImpl,alterTopicConfigs,Long Statement,The length of the statement "return safeAlterConfigs(clusterId`new ConfigResource(ConfigResource.Type.TOPIC`topicName)`TopicConfig.builder().setClusterId(clusterId).setTopicName(topicName)`commands);" is 170.,109
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManager,searchAcls,Long Parameter List,The method has 8 parameters. ,29
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManager,createAcl,Long Parameter List,The method has 8 parameters. ,43
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManager,deleteAcls,Long Parameter List,The method has 8 parameters. ,57
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchema,Long Parameter List,The method has 8 parameters. ,50
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromSchemaId,Long Parameter List,The method has 5 parameters. ,89
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromSchemaId,Long Statement,The length of the statement "String actualSubject=subject.orElse(subjectNameStrategy.orElse(defaultSubjectNameStrategy).subjectName(topicName`isKey`schema));" is 128.,89
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaVersion,Long Statement,The length of the statement "throw handleRestClientException(e`"Error when fetching schema version. subject = %s` schema = %s"`subject`schema.canonicalString());" is 132.,114
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromSchemaVersion,Long Parameter List,The method has 5 parameters. ,126
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromSchemaVersion,Long Statement,The length of the statement "throw new BadRequestException(String.format("Schema does not exist for subject: %s` version: %s"`actualSubject`schemaVersion)`e);" is 129.,126
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromSchemaVersion,Long Statement,The length of the statement "parsedSchema=schemaProvider.parseSchema(schema`false).orElseThrow(() -> Errors.invalidSchemaException(String.format("Error when fetching schema by version. subject = %s` version = %d"`actualSubject`schemaVersion)));" is 215.,126
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromRawSchema,Long Parameter List,The method has 6 parameters. ,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromRawSchema,Long Statement,The length of the statement "schema=schemaProvider.parseSchema(rawSchema`emptyList()`true).orElseThrow(() -> Errors.invalidSchemaException(String.format("Error when parsing raw schema. format = %s` schema = %s"`format`rawSchema)));" is 202.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromRawSchema,Long Statement,The length of the statement "String actualSubject=subject.orElse(subjectNameStrategy.orElse(defaultSubjectNameStrategy).subjectName(topicName`isKey`schema));" is 128.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaFromRawSchema,Long Statement,The length of the statement "throw handleRestClientException(e`"Error when registering schema. format = %s` subject = %s` schema = %s"`format`actualSubject`schema.canonicalString());" is 153.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,findLatestSchema,Long Statement,The length of the statement "throw new BadRequestException(String.format("Schema subject not supported for schema type = %s"`metadata.getSchemaType())`e);" is 125.,241
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,findLatestSchema,Long Statement,The length of the statement "schema=schemaProvider.parseSchema(new Schema(null`metadata)`false).orElseThrow(() -> Errors.invalidSchemaException(String.format("Error when fetching latest schema version. subject = %s"`actualSubject)));" is 204.,241
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,getSchemaSubjectUnsafe,Long Statement,The length of the statement "IllegalArgumentException error=new IllegalArgumentException(String.format("Cannot use%s schema_subject_strategy%s without schema_id or schema."`subjectNameStrategy.map(requestStrategy -> "").orElse(" default")`subjectNameStrategy.map(requestStrategy -> "=" + strategy).orElse("")));" is 282.,286
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,handleRestClientException,Long Statement,The length of the statement "if (cause instanceof RestClientException && ((RestClientException)cause).getErrorCode() == KAFKA_AUTHORIZATION_ERROR_CODE) {" is 124.,333
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImpl,handleRestClientException,Long Statement,The length of the statement "return new RestException(String.format(message`args)`Status.FORBIDDEN.getStatusCode()`KAFKA_AUTHORIZATION_ERROR_CODE`cause);" is 124.,333
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManager,getConsumerAssignment,Long Parameter List,The method has 5 parameters. ,33
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,searchAcls,Long Parameter List,The method has 8 parameters. ,56
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,searchAcls,Long Statement,The length of the statement "AclBindingFilter aclBindingFilter=new AclBindingFilter(new ResourcePatternFilter(resourceType.toAdminResourceType()`resourceName`patternType.toAdminPatternType())`new AccessControlEntryFilter(principal`host`operation.toAclOperation()`permission.toAclPermissionType()));" is 269.,56
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,searchAcls,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenApply(cluster -> adminClient.describeAcls(aclBindingFilter)).thenCompose(describeAclsResult -> KafkaFutures.toCompletableFuture(describeAclsResult.values())).thenApply(aclBindings -> aclBindings.stream().map(aclBinding -> toAcl(clusterId`aclBinding)).collect(Collectors.toList()));" is 418.,56
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,createAcl,Long Parameter List,The method has 8 parameters. ,86
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,createAcl,Long Statement,The length of the statement "AclBinding aclBinding=new AclBinding(new ResourcePattern(resourceType.toAdminResourceType()`resourceName`patternType.toAdminPatternType())`new AccessControlEntry(principal`host`operation.toAclOperation()`permission.toAclPermissionType()));" is 239.,86
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,createAcls,Long Statement,The length of the statement "List<AclBinding> aclBindings=acls.stream().map(acl -> new AclBinding(new ResourcePattern(acl.getResourceType().toAdminResourceType()`acl.getResourceName()`acl.getPatternType().toAdminPatternType())`new AccessControlEntry(acl.getPrincipal()`acl.getHost()`acl.getOperation().toAclOperation()`acl.getPermission().toAclPermissionType()))).collect(Collectors.toList());" is 364.,106
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,deleteAcls,Long Parameter List,The method has 8 parameters. ,127
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,deleteAcls,Long Statement,The length of the statement "AclBindingFilter aclBindingFilter=new AclBindingFilter(new ResourcePatternFilter(resourceType.toAdminResourceType()`resourceName`patternType.toAdminPatternType())`new AccessControlEntryFilter(principal`host`operation.toAclOperation()`permission.toAclPermissionType()));" is 269.,127
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,deleteAcls,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenApply(cluster -> adminClient.deleteAcls(singletonList(aclBindingFilter))).thenCompose(deleteAclsResult -> KafkaFutures.toCompletableFuture(deleteAclsResult.values().get(aclBindingFilter))).thenApply(filterResults -> filterResults.values().stream().map(FilterResult::binding).filter(Objects::nonNull).map(binding -> toAcl(clusterId`binding)).collect(Collectors.toList()));" is 508.,127
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,submitBindings,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenApply(cluster -> adminClient.createAcls(aclBindings)).thenCompose(createAclsResult -> {" is 224.,164
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImpl,submitBindings,Long Statement,The length of the statement "return CompletableFuture.allOf(results.stream().map(f -> KafkaFutures.toCompletableFuture(f)).collect(Collectors.toList()).toArray(new CompletableFuture[results.size()]));" is 171.,164
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceController,produce,Long Parameter List,The method has 7 parameters. ,31
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImpl,listConsumerGroups,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s could not be found."`clusterId)).thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.listConsumerGroups().all())).thenCompose(listings -> getConsumerGroups(clusterId`listings.stream().map(ConsumerGroupListing::groupId).collect(Collectors.toList())));" is 369.,44
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImpl,getConsumerGroup,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s could not be found."`clusterId)).thenCompose(cluster -> getConsumerGroups(clusterId`singletonList(consumerGroupId))).thenApply(consumerGroups -> consumerGroups.stream().findAny());" is 283.,61
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImpl,getConsumerGroups,Long Statement,The length of the statement "return KafkaFutures.toCompletableFuture(adminClient.describeConsumerGroups(consumerGroupIds).all()).thenApply(descriptions -> descriptions.values().stream().filter(description -> !description.isSimpleConsumerGroup() || description.state() != ConsumerGroupState.DEAD).map(description -> ConsumerGroup.fromConsumerGroupDescription(clusterId`description)).collect(Collectors.toList()));" is 383.,72
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerThrowing,serialize,Long Parameter List,The method has 5 parameters. ,27
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerThrowing,serialize,Long Statement,The length of the statement "throw Errors.messageSerializationException("Schema Registry not defined` no Schema " + "Registry client available to serialize message.");" is 138.,27
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConsumerLagManager,getCurrentOffsets,Long Statement,The length of the statement "return KafkaFutures.toCompletableFuture(kafkaAdminClient.listConsumerGroupOffsets(consumerGroupId`new ListConsumerGroupOffsetsOptions()).partitionsToOffsetAndMetadata());" is 170.,45
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConsumerLagManager,getLatestOffsets,Long Statement,The length of the statement "Map<TopicPartition`OffsetSpec> latestOffsetSpecs=currentOffsets.keySet().stream().collect(Collectors.toMap(Function.identity()`topicPartition -> OffsetSpec.latest()));" is 167.,53
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConsumerLagManager,getLatestOffsets,Long Statement,The length of the statement "return KafkaFutures.toCompletableFuture(kafkaAdminClient.listOffsets(latestOffsetSpecs`new ListOffsetsOptions(ISOLATION_LEVEL)).all());" is 135.,53
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,listConfigs,Long Statement,The length of the statement "return listConfigs(clusterId`Collections.singletonList(resourceId)`prototype).thenApply(result -> result.get(resourceId));" is 122.,53
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,listConfigs,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.describeConfigs(resourceIds`new DescribeConfigsOptions().includeSynonyms(true)).all())).thenApply(configsMap -> configsMap.entrySet().stream().collect(Collectors.toMap(e -> e.getKey()`e -> e.getValue().entries().stream().map(entry -> prototype.setName(entry.name()).setValue(entry.value()).setDefault(entry.isDefault()).setReadOnly(entry.isReadOnly()).setSensitive(entry.isSensitive()).setSource(ConfigSource.fromAdminConfigSource(entry.source())).setSynonyms(entry.synonyms().stream().map(ConfigSynonym::fromAdminConfigSynonym).collect(Collectors.toList())).build()).collect(Collectors.toList()))));" is 801.,59
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,getConfig,Long Statement,The length of the statement "return listConfigs(clusterId`resourceId`prototype).thenApply(configs -> findEntityByKey(configs`AbstractConfig::getName`name));" is 127.,98
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,safeUpdateConfig,Long Parameter List,The method has 5 parameters. ,104
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,safeUpdateConfig,Long Statement,The length of the statement "return getConfig(clusterId`resourceId`prototype`name).thenApply(config -> checkEntityExists(config`"Config %s cannot be found for %s %s in cluster %s."`name`resourceId.type()`resourceId.name()`clusterId)).thenCompose(config -> alterConfigs(resourceId`singletonList(AlterConfigCommand.set(name`newValue))));" is 306.,104
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,unsafeUpdateConfig,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> alterConfigs(resourceId`singletonList(AlterConfigCommand.set(name`newValue))));" is 235.,124
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,safeResetConfig,Long Statement,The length of the statement "return getConfig(clusterId`resourceId`prototype`name).thenApply(config -> checkEntityExists(config`"Config %s cannot be found for %s %s in cluster %s."`name`resourceId.type()`resourceId.name()`clusterId)).thenCompose(config -> alterConfigs(resourceId`singletonList(AlterConfigCommand.delete(name))));" is 300.,138
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,unsafeResetConfig,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> alterConfigs(resourceId`singletonList(AlterConfigCommand.delete(name))));" is 229.,155
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,safeAlterConfigs,Long Statement,The length of the statement "throw new NotFoundException(String.format("Config %s cannot be found for %s %s in cluster %s."`command.getName()`resourceId.type()`resourceId.name()`clusterId));" is 161.,168
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,unsafeAlterConfigs,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> alterConfigs(resourceId`commands));" is 191.,191
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AbstractConfigManager,alterConfigs,Long Statement,The length of the statement "return KafkaFutures.toCompletableFuture(adminClient.incrementalAlterConfigs(singletonMap(resourceId`commands.stream().map(AlterConfigCommand::toAlterConfigOp).collect(Collectors.toList()))).values().get(resourceId));" is 216.,203
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerThrowing,getSchema,Long Parameter List,The method has 8 parameters. ,26
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImpl,listConsumerLags,Long Statement,The length of the statement "return consumerGroupManager.getConsumerGroup(clusterId`consumerGroupId).thenApply(consumerGroup -> checkEntityExists(consumerGroup`"Consumer Group %s could not be found."`consumerGroupId)).thenCompose(consumerGroup -> getCurrentOffsets(consumerGroupId).thenApply(fetchedCurrentOffsets -> checkOffsetsExist(fetchedCurrentOffsets`"Consumer group offsets could not be found.")).thenCompose(fetchedCurrentOffsets -> getLatestOffsets(fetchedCurrentOffsets).thenApply(latestOffsets -> createConsumerLagList(clusterId`consumerGroup`fetchedCurrentOffsets`latestOffsets))));" is 565.,51
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImpl,getConsumerLag,Long Statement,The length of the statement "return listConsumerLags(clusterId`consumerGroupId).thenApply(lags -> lags.stream().filter(lag -> lag.getTopicName().equals(topicName)).filter(lag -> lag.getPartitionId() == partitionId).filter(lag -> lag.getConsumerGroupId().equals(consumerGroupId)).findAny());" is 261.,80
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImpl,createConsumerLagList,Long Statement,The length of the statement "Optional<Consumer> consumer=Optional.ofNullable(partitionAssignment.get(Partition.create(clusterId`topicPartition.topic()`topicPartition.partition()`emptyList())));" is 164.,93
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImpl,createConsumerLagList,Long Statement,The length of the statement "consumerLags.add(ConsumerLag.builder().setClusterId(clusterId).setConsumerGroupId(consumerGroup.getConsumerGroupId()).setTopicName(topicPartition.topic()).setPartitionId(topicPartition.partition()).setConsumerId(consumer.map(Consumer::getConsumerId).orElse("")).setInstanceId(consumer.flatMap(Consumer::getInstanceId)).setClientId(consumer.map(Consumer::getClientId).orElse("")).setCurrentOffset(currentOffset.get()).setLogEndOffset(latestOffset.get()).build());" is 462.,93
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImpl,createConsumerLagList,Long Statement,The length of the statement "log.debug("missing offset for consumerId={} topic={} partition={} " + "current={} latest={}"`consumer.map(Consumer::getConsumerId).orElse("")`topicPartition.topic()`topicPartition.partition()`currentOffset.orElse(null)`latestOffset.orElse(null));" is 246.,93
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImpl,listClusterConfigs,Long Statement,The length of the statement "return listConfigs(clusterId`new ConfigResource(type.getAdminType()`"")`ClusterConfig.builder().setClusterId(clusterId).setType(type));" is 135.,36
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImpl,getClusterConfig,Long Statement,The length of the statement "return getConfig(clusterId`new ConfigResource(type.getAdminType()`"")`ClusterConfig.builder().setClusterId(clusterId).setType(type)`name);" is 138.,45
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManager,createTopic,Long Parameter List,The method has 6 parameters. ,66
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerManagerImpl,listBrokers,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenApply(Cluster::getBrokers);" is 164.,38
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImpl,listConsumerAssignments,Long Statement,The length of the statement "return consumerManager.getConsumer(clusterId`consumerGroupId`consumerId).thenApply(consumer -> checkEntityExists(consumer`"Consumer %s does not exist."`consumerId)).thenApply(consumer -> consumer.getAssignedPartitions().stream().map(partition -> ConsumerAssignment.builder().setClusterId(clusterId).setConsumerGroupId(consumerGroupId).setConsumerId(consumerId).setTopicName(partition.getTopicName()).setPartitionId(partition.getPartitionId()).build()).collect(Collectors.toList()));" is 482.,37
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImpl,getConsumerAssignment,Long Parameter List,The method has 5 parameters. ,59
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImpl,getConsumerAssignment,Long Statement,The length of the statement "return listConsumerAssignments(clusterId`consumerGroupId`consumerId).thenApply(assignments -> assignments.stream().filter(assignment -> assignment.getTopicName().equals(topicName)).filter(assignment -> assignment.getPartitionId() == partitionId).findAny());" is 257.,59
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,listBrokerConfigs,Long Statement,The length of the statement "return listConfigs(clusterId`new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(brokerId))`BrokerConfig.builder().setClusterId(clusterId).setBrokerId(brokerId));" is 171.,39
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,listAllBrokerConfigs,Long Statement,The length of the statement "List<ConfigResource> brokerResources=brokerIds.stream().map(brokerId -> new ConfigResource(Type.BROKER`String.valueOf(brokerId))).collect(Collectors.toList());" is 159.,47
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,listAllBrokerConfigs,Long Statement,The length of the statement "return listConfigs(clusterId`brokerResources`BrokerConfig.builder().setClusterId(clusterId).setBrokerId(-1)).thenApply(configs -> configs.entrySet().stream().collect(Collectors.toMap(e -> Integer.parseInt(e.getKey().name())`e -> e.getValue().stream().map(config -> BrokerConfig.create(config.getClusterId()`Integer.parseInt(e.getKey().name())`config.getName()`config.getValue()`config.isDefault()`config.isReadOnly()`config.isSensitive()`config.getSource()`config.getSynonyms())).collect(Collectors.toList()))));" is 512.,47
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,getBrokerConfig,Long Statement,The length of the statement "return getConfig(clusterId`new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(brokerId))`BrokerConfig.builder().setClusterId(clusterId).setBrokerId(brokerId)`name);" is 174.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,updateBrokerConfig,Long Statement,The length of the statement "return safeUpdateConfig(clusterId`new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(brokerId))`BrokerConfig.builder().setClusterId(clusterId).setBrokerId(brokerId)`name`newValue);" is 190.,91
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,resetBrokerConfig,Long Statement,The length of the statement "return safeResetConfig(clusterId`new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(brokerId))`BrokerConfig.builder().setClusterId(clusterId).setBrokerId(brokerId)`name);" is 180.,102
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImpl,alterBrokerConfigs,Long Statement,The length of the statement "return safeAlterConfigs(clusterId`new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(brokerId))`BrokerConfig.builder().setClusterId(clusterId).setBrokerId(brokerId)`commands);" is 185.,111
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImpl,getLocalCluster,Long Statement,The length of the statement "DescribeClusterResult describeClusterResult=adminClient.describeCluster(new DescribeClusterOptions().includeAuthorizedOperations(false));" is 137.,57
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImpl,getLocalCluster,Long Statement,The length of the statement "return CompletableFuture.completedFuture(Cluster.builder()).thenCombine(KafkaFutures.toCompletableFuture(describeClusterResult.clusterId())`(clusterBuilder`clusterId) -> {" is 171.,57
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImpl,getLocalCluster,Long Statement,The length of the statement "return clusterBuilder.addAllBrokers(nodes.stream().filter(node -> node != null && !node.isEmpty()).map(node -> Broker.fromNode(clusterBuilder.build().getClusterId()`node)).collect(Collectors.toList()));" is 202.,57
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacade,RecordSerializerFacade,Long Identifier,The length of the parameter schemaRecordSerializerProvider is 30.,33
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacade,RecordSerializerFacade,Long Identifier,The length of the field schemaRecordSerializerProvider is 30.,33
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacade,serialize,Long Identifier,The length of the field schemaRecordSerializerProvider is 30.,41
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacade,serialize,Long Parameter List,The method has 5 parameters. ,41
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImpl,listReplicas,Long Statement,The length of the statement "return partitionManager.getPartition(clusterId`topicName`partitionId).thenApply(partition -> checkEntityExists(partition`"Partition %d of topic %s could not be found on cluster %s."`partitionId`topicName`clusterId)).thenApply(Partition::getReplicas);" is 250.,50
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImpl,getReplica,Long Statement,The length of the statement "return listReplicas(clusterId`topicName`partitionId).thenApply(replicas -> findEntityByKey(replicas`PartitionReplica::getBrokerId`brokerId));" is 141.,66
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImpl,searchReplicasByBrokerId,Long Statement,The length of the statement "return brokerManager.getBroker(clusterId`brokerId).thenApply(broker -> checkEntityExists(broker`"Broker %d cannot be found."`brokerId)).thenCompose(broker -> {" is 159.,73
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImpl,searchReplicasByBrokerId,Long Statement,The length of the statement ").thenCompose(logDirs -> CompletableFutures.allAsList(logDirs.values().stream().flatMap(logDir -> logDir.replicaInfos.keySet().stream()).map(partition -> getReplica(clusterId`partition.topic()`partition.partition()`brokerId)).collect(Collectors.toList()))).thenApply(replicas -> replicas.stream().filter(Optional::isPresent).map(Optional::get).collect(Collectors.toList()));" is 374.,73
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializer,serialize,Long Parameter List,The method has 5 parameters. ,27
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializer,serialize,Long Parameter List,The method has 5 parameters. ,26
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerImpl,serialize,Long Parameter List,The method has 5 parameters. ,65
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerImpl,serialize,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@1c6910d5,65
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerImpl,serializeProtobuf,Long Parameter List,The method has 5 parameters. ,118
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImpl,listReassignments,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.listPartitionReassignments().reassignments())).thenApply(reassignments -> {" is 276.,46
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImpl,listReassignments,Long Statement,The length of the statement "return reassignments.entrySet().stream().map(reassignment -> toReassignment(clusterId`reassignment)).sorted(Comparator.comparing(Reassignment::getTopicName).thenComparing(Reassignment::getPartitionId)).collect(Collectors.toList());" is 231.,46
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImpl,searchReassignmentsByTopicName,Long Statement,The length of the statement "return listReassignments(clusterId).thenApply(reassignments -> reassignments.stream().filter(reassignment -> reassignment.getTopicName().equals(topicName)).sorted(Comparator.comparing(Reassignment::getTopicName).thenComparing(Reassignment::getPartitionId)).collect(Collectors.toList()));" is 287.,69
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImpl,getReassignment,Long Statement,The length of the statement "return listReassignments(clusterId).thenApply(reassignments -> reassignments.stream().filter(reassignment -> reassignment.getTopicName().equals(topicName)).filter(reassignment -> reassignment.getPartitionId() == partitionId).findAny());" is 236.,83
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImpl,toReassignment,Long Statement,The length of the statement "return Reassignment.create(clusterId`reassignment.getKey().topic()`reassignment.getKey().partition()`reassignment.getValue().addingReplicas()`reassignment.getValue().removingReplicas());" is 186.,95
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,NoSchemaRecordSerializer,serialize,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@4c0a3319,41
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,listTopics,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.listTopics().listings())).thenCompose(topicListings -> {" is 257.,58
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,listTopics,Long Statement,The length of the statement "return describeTopics(clusterId`topicListings.stream().map(TopicListing::name).collect(Collectors.toList())`includeAuthorizedOperations);" is 137.,58
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,listLocalTopics,Long Statement,The length of the statement "return clusterManager.getLocalCluster().thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.listTopics().listings()).thenCompose(topicListings -> {" is 163.,78
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,listLocalTopics,Long Statement,The length of the statement "return describeTopics(cluster.getClusterId()`topicListings.stream().map(TopicListing::name).collect(Collectors.toList())`false);" is 128.,78
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,getTopic,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> describeTopics(clusterId`singletonList(topicName)`includeAuthorizedOperations)).thenApply(topics -> {" is 257.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,getTopic,Long Statement,The length of the statement "throw new IllegalStateException(String.format("More than one topic exists with name %s in cluster %s."`topicName`clusterId));" is 125.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,getLocalTopic,Long Statement,The length of the statement "return clusterManager.getLocalCluster().thenCompose(cluster -> describeTopics(cluster.getClusterId()`singletonList(topicName)`false)).thenApply(topics -> {" is 155.,125
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,describeTopics,Long Statement,The length of the statement "return KafkaFutures.toCompletableFuture(adminClient.describeTopics(topicNames`new DescribeTopicsOptions().includeAuthorizedOperations(includeAuthorizedOperations)).all()).thenApply(topics -> topics.values().stream().map(topicDescription -> toTopic(clusterId`topicDescription)).collect(Collectors.toList()));" is 307.,146
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,toTopic,Long Statement,The length of the statement "return Topic.create(clusterId`topicDescription.name()`topicDescription.partitions().stream().map(partition -> toPartition(clusterId`topicDescription.name()`partition)).collect(Collectors.toList())`(short)topicDescription.partitions().get(0).replicas().size()`topicDescription.isInternal()`topicDescription.authorizedOperations() == null ? emptySet() : topicDescription.authorizedOperations().stream().map(Acl.Operation::fromAclOperation).collect(Collectors.toSet()));" is 467.,162
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,toPartition,Long Statement,The length of the statement "replicas.add(PartitionReplica.create(clusterId`topicName`partitionInfo.partition()`replica.id()`replica.equals(partitionInfo.leader())`inSyncReplicas.contains(replica)));" is 170.,178
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,createTopic,Long Parameter List,The method has 6 parameters. ,195
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,createTopic,Long Statement,The length of the statement "NewTopic createTopicRequest=replicasAssignments.isEmpty() ? new NewTopic(topicName`partitionsCount`replicationFactor).configs(nullableConfigs) : new NewTopic(topicName`replicasAssignments).configs(nullableConfigs);" is 214.,195
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,createTopic,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.createTopics(singletonList(createTopicRequest)).all()));" is 257.,195
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImpl,deleteTopic,Long Statement,The length of the statement "return clusterManager.getCluster(clusterId).thenApply(cluster -> checkEntityExists(cluster`"Cluster %s cannot be found."`clusterId)).thenCompose(cluster -> KafkaFutures.toCompletableFuture(adminClient.deleteTopics(singletonList(topicName)).all()));" is 248.,224
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImpl,listConsumers,Long Statement,The length of the statement "return consumerGroupManager.getConsumerGroup(clusterId`consumerGroupId).thenApply(consumerGroup -> checkEntityExists(consumerGroup`"Consumer Group %s does not exist."`consumerGroupId)).thenApply(ConsumerGroup::getConsumers);" is 224.,37
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImpl,getConsumer,Long Statement,The length of the statement "return listConsumers(clusterId`consumerGroupId).thenApply(consumers -> findEntityByKey(consumers`Consumer::getConsumerId`consumerId));" is 134.,48
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManager,getSchema,Long Parameter List,The method has 8 parameters. ,26
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImpl,getConsumerGroupLagSummary,Long Statement,The length of the statement "return consumerGroupManager.getConsumerGroup(clusterId`consumerGroupId).thenApply(consumerGroup -> checkEntityExists(consumerGroup`"Consumer Group %s could not be found."`consumerGroupId)).thenCompose(consumerGroup -> getCurrentOffsets(consumerGroupId).thenApply(fetchedCurrentOffsets -> checkOffsetsExist(fetchedCurrentOffsets`"Consumer group offsets could not be found.")).thenCompose(fetchedCurrentOffsets -> getLatestOffsets(fetchedCurrentOffsets).thenApply(latestOffsets -> Optional.of(createConsumerGroupLagSummary(clusterId`consumerGroup`fetchedCurrentOffsets`latestOffsets)))));" is 586.,51
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImpl,createConsumerGroupLagSummary,Long Statement,The length of the statement "ConsumerGroupLagSummary.Builder consumerGroupLagSummary=ConsumerGroupLagSummary.builder().setClusterId(clusterId).setConsumerGroupId(consumerGroup.getConsumerGroupId());" is 169.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImpl,createConsumerGroupLagSummary,Long Statement,The length of the statement "Optional<Consumer> consumer=Optional.ofNullable(partitionAssignment.get(Partition.create(clusterId`topicPartition.topic()`topicPartition.partition()`emptyList())));" is 164.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImpl,createConsumerGroupLagSummary,Long Statement,The length of the statement "consumerGroupLagSummary.addOffset(topicPartition.topic()`consumer.map(Consumer::getConsumerId).orElse("")`consumer.flatMap(Consumer::getInstanceId)`consumer.map(Consumer::getClientId).orElse("")`topicPartition.partition()`currentOffset.get()`latestOffset.get());" is 262.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImpl,createConsumerGroupLagSummary,Long Statement,The length of the statement "log.debug("missing offset for consumerId={} topic={} partition={} " + "current={} latest={}"`consumer.map(Consumer::getConsumerId).orElse("")`topicPartition.topic()`topicPartition.partition()`currentOffset.orElse(null)`latestOffset.orElse(null));" is 246.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,listPartitions,Long Statement,The length of the statement "return topicManager.getTopic(clusterId`topicName).thenApply(topic -> checkEntityExists(topic`"Topic %s cannot be found."`topic)).thenApply(Topic::getPartitions).thenCompose(this::withOffsets);" is 192.,53
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,listLocalPartitions,Long Statement,The length of the statement "return topicManager.getLocalTopic(topicName).thenApply(topic -> checkEntityExists(topic`"Topic %s cannot be found."`topic)).thenApply(Topic::getPartitions).thenCompose(this::withOffsets);" is 187.,62
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,getPartition,Long Statement,The length of the statement "return topicManager.getTopic(clusterId`topicName).thenApply(topic -> checkEntityExists(topic`"Topic %s cannot be found."`topic)).thenApply(Topic::getPartitions).thenApply(partitions -> findEntityByKey(partitions`Partition::getPartitionId`partitionId)).thenApply(partition -> partition.map(Collections::singletonList).orElse(emptyList())).thenCompose(this::withOffsets).thenApply(partitions -> partitions.stream().findAny());" is 424.,71
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,getLocalPartition,Long Statement,The length of the statement "return topicManager.getLocalTopic(topicName).thenApply(topic -> checkEntityExists(topic`"Topic %s cannot be found."`topic)).thenApply(Topic::getPartitions).thenApply(partitions -> findEntityByKey(partitions`Partition::getPartitionId`partitionId)).thenApply(partition -> partition.map(Collections::singletonList).orElse(emptyList())).thenCompose(this::withOffsets).thenApply(partitions -> partitions.stream().findAny());" is 419.,85
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,withOffsets,Long Statement,The length of the statement "CompletableFuture<ListOffsetsResultInfo> earliestFuture=KafkaFutures.toCompletableFuture(earliestResponse.partitionResult(toTopicPartition(partition)));" is 152.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,withOffsets,Long Statement,The length of the statement "CompletableFuture<ListOffsetsResultInfo> latestFuture=KafkaFutures.toCompletableFuture(latestResponse.partitionResult(toTopicPartition(partition)));" is 148.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImpl,withOffsets,Long Statement,The length of the statement "CompletableFuture<Partition> partitionWithOffset=earliestFuture.thenCombine(latestFuture`(earliest`latest) -> Partition.create(partition.getClusterId()`partition.getTopicName()`partition.getPartitionId()`partition.getReplicas()`earliest.offset()`latest.offset()));" is 264.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,listClusterConfigs_existingCluster_returnsConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`"")))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 179.,136
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,listClusterConfigs_existingCluster_returnsConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`CONFIG)));" is 147.,136
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,listClusterConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`"")))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 179.,157
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`"")))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 179.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`CONFIG)));" is 147.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "ClusterConfig config=clusterConfigManager.getClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`CONFIG_1.getName()).get().get();" is 128.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`"")))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 179.,200
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`CONFIG)));" is 147.,200
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "Optional<ClusterConfig> config=clusterConfigManager.getClusterConfig(CLUSTER_ID`ClusterConfig.Type.BROKER`"foobar").get();" is 122.,200
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,getClusterConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`"")))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 179.,222
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,updateClusterConfig_existingConfig_updatesConfigs,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`singletonList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET))))).andReturn(alterConfigsResult);" is 246.,244
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,updateClusterConfig_existingConfig_updatesConfigs,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`KafkaFuture.completedFuture(null)));" is 145.,244
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,resetClusterConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`singletonList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 242.,288
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,resetClusterConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`KafkaFuture.completedFuture(null)));" is 145.,288
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,alterClusterConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`Arrays.asList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET)`new AlterConfigOp(new ConfigEntry(CONFIG_2.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 334.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,alterClusterConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`"")`KafkaFuture.completedFuture(null)));" is 145.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,alterClusterConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "clusterConfigManager.alterClusterConfigs(CLUSTER_ID`ClusterConfig.Type.BROKER`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 201.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterConfigManagerImplTest,alterClusterConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "clusterConfigManager.alterClusterConfigs(CLUSTER_ID`ClusterConfig.Type.BROKER`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 201.,365
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,listReplicas_existingPartition_returnsReplicas,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(completedFuture(Optional.of(PARTITION_1)));" is 129.,132
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,listReplicas_nonExistingPartition_throwsNotFound,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(completedFuture(Optional.empty()));" is 121.,144
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,listReplicas_nonExistingTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(failedFuture(new NotFoundException()));" is 125.,158
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,getReplica_existingReplica_returnsReplica,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(completedFuture(Optional.of(PARTITION_1)));" is 129.,172
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,getReplica_existingReplica_returnsReplica,Long Statement,The length of the statement "Optional<PartitionReplica> replica=replicaManager.getReplica(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1`REPLICA_1_1.getBrokerId()).get();" is 131.,172
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,getReplica_nonExistingReplica_returnEmpty,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(completedFuture(Optional.of(PARTITION_1)));" is 129.,186
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,getReplica_nonExistingReplica_returnEmpty,Magic Number,The method contains a magic number: 100,186
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,getReplica_nonExistingPartition_throwsNotFound,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(completedFuture(Optional.empty()));" is 121.,198
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,getReplica_nonExistingTopicOrCluster_throwsNotFound,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(failedFuture(new NotFoundException()));" is 125.,214
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,searchByBrokerId_existingBroker_returnsReplicas,Long Statement,The length of the statement "expect(describeLogDirsResult.values()).andReturn(singletonMap(BROKER_ID_1`KafkaFuture.completedFuture(singletonMap(TOPIC_NAME`new LogDirInfo(null`partitions)))));" is 162.,230
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,searchByBrokerId_existingBroker_returnsReplicas,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_1)).andReturn(completedFuture(Optional.of(PARTITION_1)));" is 129.,230
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReplicaManagerImplTest,searchByBrokerId_existingBroker_returnsReplicas,Long Statement,The length of the statement "expect(partitionManager.getPartition(CLUSTER_ID`TOPIC_NAME`PARTITION_ID_2)).andReturn(completedFuture(Optional.of(PARTITION_2)));" is 129.,230
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,setUp,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Identifier,The length of the field listConsumerGroupOffsetsResult is 30.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 132.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "expect(kafkaAdminClient.listConsumerGroupOffsets(eq(CONSUMER_GROUP_ID)`anyObject(ListConsumerGroupOffsetsOptions.class))).andReturn(listConsumerGroupOffsetsResult);" is 164.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "expect(listConsumerGroupOffsetsResult.partitionsToOffsetAndMetadata()).andReturn(KafkaFuture.completedFuture(OFFSET_AND_METADATA_MAP));" is 135.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "expect(kafkaAdminClient.listOffsets(capture(capturedOffsetSpec)`capture(capturedListOffsetsOptions))).andReturn(new ListOffsetsResult(LATEST_OFFSETS_MAP));" is 155.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "ConsumerGroupLagSummary consumerGroupLagSummary=consumerGroupLagSummaryManager.getConsumerGroupLagSummary(CLUSTER_ID`CONSUMER_GROUP_ID).get().get();" is 148.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_nonExistingConsumerGroup_throwsNotFound,Long Identifier,The length of the field consumerGroupLagSummaryManager is 30.,203
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupLagSummaryManagerImplTest,getConsumerGroupLagSummary_nonExistingConsumerGroup_throwsNotFound,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.empty()));" is 121.,203
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,setUp,Long Statement,The length of the statement "schemaRegistryClient=(MockSchemaRegistryClient)MockSchemaRegistry.getClientForScope(SCHEMA_REGISTRY_SCOPE`Arrays.asList(new AvroSchemaProvider()`new JsonSchemaProvider()`new ProtobufSchemaProvider()));" is 201.,82
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,setUp,Long Statement,The length of the statement "recordSerializer=new RecordSerializerFacade(new NoSchemaRecordSerializer(SCHEMA_SERIALIZER_CONFIGS)`() -> new SchemaRecordSerializerImpl(schemaRegistryClient`SCHEMA_SERIALIZER_CONFIGS`SCHEMA_SERIALIZER_CONFIGS`SCHEMA_SERIALIZER_CONFIGS));" is 238.,82
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,noSchemaRegistryClientConfigured,Long Statement,The length of the statement "RecordSerializerFacade myRecordSerializer=new RecordSerializerFacade(new NoSchemaRecordSerializer(SCHEMA_SERIALIZER_CONFIGS)`() -> new SchemaRecordSerializerThrowing());" is 169.,103
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,noSchemaRegistryClientConfigured,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> myRecordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.empty()`TextNode.valueOf(BaseEncoding.base64().encode("foobar".getBytes(StandardCharsets.UTF_8)))`true));" is 270.,103
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,noSchemaRegistryClientConfigured,Long Statement,The length of the statement "assertEquals("Error serializing message. Schema Registry not defined` " + "no Schema Registry client available to serialize message."`rcve.getMessage());" is 153.,103
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,noSchemaRegistryClientConfigured,Magic Number,The method contains a magic number: 42207,103
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBinaryKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`TextNode.valueOf(BaseEncoding.base64().encode("foobar".getBytes(StandardCharsets.UTF_8)))`true).get();" is 201.,130
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBinaryValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`TextNode.valueOf(BaseEncoding.base64().encode("foobar".getBytes(StandardCharsets.UTF_8)))`false).get();" is 202.,146
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullBinaryKey_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`true);" is 138.,162
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullBinaryValue_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`false);" is 139.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidBinaryKey_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`TextNode.valueOf("fooba")`true));" is 155.,188
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidBinaryValue_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.BINARY`TOPIC_NAME`Optional.empty()`TextNode.valueOf("fooba")`false));" is 156.,201
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeStringJsonKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`TextNode.valueOf("foobar")`true).get();" is 136.,214
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`IntNode.valueOf(123)`true).get();" is 130.,229
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonKey_returnsSerialized,Magic Number,The method contains a magic number: 123,229
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`FloatNode.valueOf(123.456F)`true).get();" is 137.,244
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonKey_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,244
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBooleanJsonKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`BooleanNode.valueOf(true)`true).get();" is 135.,259
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonKey_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,293
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullJsonKey_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`true);" is 136.,312
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeStringJsonValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`TextNode.valueOf("foobar")`false).get();" is 137.,325
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`IntNode.valueOf(123)`false).get();" is 131.,340
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonValue_returnsSerialized,Magic Number,The method contains a magic number: 123,340
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`FloatNode.valueOf(123.456F)`false).get();" is 138.,355
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonValue_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,355
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBooleanJsonValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`BooleanNode.valueOf(true)`false).get();" is 136.,370
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonValue_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,404
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullJsonValue_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.JSON`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`false);" is 137.,423
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeStringAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`true).get();" is 196.,436
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`IntNode.valueOf(123)`true).get();" is 190.,459
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 123,459
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 123,459
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`FloatNode.valueOf(123.456F)`true).get();" is 197.,482
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,482
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,482
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBooleanAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`BooleanNode.valueOf(true)`true).get();" is 195.,505
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBytesAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`true).get();" is 196.,528
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeRecordAvroKey_returnsSerialized,Long Statement,The length of the statement "AvroSchema schema=new AvroSchema("{" + " \"name\": \"foobar\"`" + " \"type\": \"record\"`"+ " \"fields\": ["+ " {\"name\": \"foo\"` \"type\": \"int\"}`"+ " {\"name\": \"bar\"` \"type\": \"boolean\"}"+ " ]"+ "}");" is 212.,553
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeRecordAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true).get();" is 174.,553
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeEnumAvroKey_returnsSerialized,Long Statement,The length of the statement "AvroSchema schema=new AvroSchema("{" + " \"name\": \"foobar\"`" + " \"type\": \"enum\"`"+ " \"symbols\": [\"foo\"` \"bar\"]"+ "}");" is 131.,591
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeEnumAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foo")`true).get();" is 193.,591
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true).get();" is 174.,620
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 2,620
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 3,620
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 2,620
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 3,620
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeMapAvroKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true).get();" is 174.,647
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeMapAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 2,647
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeMapAvroKey_returnsSerialized,Magic Number,The method contains a magic number: 2,647
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullAvroKeyNullSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`true);" is 136.,676
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullAvroKeyNonNullableSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`NullNode.getInstance()`true);" is 196.,689
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNonNullAvroKeyNullSchema_throwsSerializationException,Long Statement,The length of the statement "assertThrows(RestConstraintViolationException.class`() -> recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.empty()`TextNode.valueOf("foobar")`true));" is 167.,706
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidAvroKey_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`true));" is 214.,720
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeStringAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`false).get();" is 197.,737
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`IntNode.valueOf(123)`false).get();" is 191.,760
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 123,760
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 123,760
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`FloatNode.valueOf(123.456F)`false).get();" is 198.,783
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,783
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,783
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBooleanAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`BooleanNode.valueOf(true)`false).get();" is 196.,806
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBytesAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`false).get();" is 197.,829
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeRecordAvroValue_returnsSerialized,Long Statement,The length of the statement "AvroSchema schema=new AvroSchema("{" + " \"name\": \"foobar\"`" + " \"type\": \"record\"`"+ " \"fields\": ["+ " {\"name\": \"foo\"` \"type\": \"int\"}`"+ " {\"name\": \"bar\"` \"type\": \"boolean\"}"+ " ]"+ "}");" is 212.,854
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeRecordAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false).get();" is 175.,854
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeEnumAvroValue_returnsSerialized,Long Statement,The length of the statement "AvroSchema schema=new AvroSchema("{" + " \"name\": \"foobar\"`" + " \"type\": \"enum\"`"+ " \"symbols\": [\"foo\"` \"bar\"]"+ "}");" is 131.,892
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeEnumAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foo")`false).get();" is 194.,892
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false).get();" is 175.,921
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 2,921
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 3,921
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 2,921
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 3,921
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeMapAvroValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false).get();" is 175.,948
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeMapAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 2,948
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeMapAvroValue_returnsSerialized,Magic Number,The method contains a magic number: 2,948
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullAvroValueNullSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`false);" is 137.,977
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullAvroValueNonNullableSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`NullNode.getInstance()`false);" is 197.,990
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNonNullAvroValueNullSchema_throwsSerializationException,Long Statement,The length of the statement "assertThrows(RestConstraintViolationException.class`() -> recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.empty()`TextNode.valueOf("foobar")`false));" is 168.,1007
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidAvroValue_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.AVRO`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`false));" is 215.,1020
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeStringJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`true).get();" is 202.,1037
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`IntNode.valueOf(123)`true).get();" is 196.,1059
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonschemaKey_returnsSerialized,Magic Number,The method contains a magic number: 123,1059
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonschemaKey_returnsSerialized,Magic Number,The method contains a magic number: 123,1059
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`FloatNode.valueOf(123.456F)`true).get();" is 203.,1081
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonschemaKey_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,1081
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBooleanJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`BooleanNode.valueOf(true)`true).get();" is 201.,1103
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "JsonSchema schema=new JsonSchema("{" + " \"type\": \"object\"`" + " \"properties\": {"+ " \"foo\": {\"type\": \"integer\"}`"+ " \"bar\": {\"type\": \"boolean\"}"+ " }"+ "}");" is 174.,1125
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true).get();" is 180.,1125
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonschemaKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true).get();" is 180.,1163
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonschemaKey_returnsSerialized,Magic Number,The method contains a magic number: 2,1163
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonschemaKey_returnsSerialized,Magic Number,The method contains a magic number: 2,1163
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullJsonschemaKeyNullSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`true);" is 142.,1190
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullJsonschemaKeyNonNullableSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`NullNode.getInstance()`true);" is 202.,1203
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNonNullJsonschemaKeyNullSchema_throwsSerializationException,Long Statement,The length of the statement "assertThrows(RestConstraintViolationException.class`() -> recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.empty()`TextNode.valueOf("foobar")`true));" is 173.,1220
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidJsonschemaKey_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`true));" is 220.,1233
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeStringJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`false).get();" is 203.,1250
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`IntNode.valueOf(123)`false).get();" is 197.,1272
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonschemaValue_returnsSerialized,Magic Number,The method contains a magic number: 123,1272
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeIntJsonschemaValue_returnsSerialized,Magic Number,The method contains a magic number: 123,1272
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`FloatNode.valueOf(123.456F)`false).get();" is 204.,1294
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeFloatJsonschemaValue_returnsSerialized,Magic Number,The method contains a magic number: 123.456F,1294
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeBooleanJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`BooleanNode.valueOf(true)`false).get();" is 202.,1316
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "JsonSchema schema=new JsonSchema("{" + " \"type\": \"object\"`" + " \"properties\": {"+ " \"foo\": {\"type\": \"integer\"}`"+ " \"bar\": {\"type\": \"boolean\"}"+ " }"+ "}");" is 174.,1338
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false).get();" is 181.,1338
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonschemaValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false).get();" is 181.,1376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonschemaValue_returnsSerialized,Magic Number,The method contains a magic number: 2,1376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeArrayJsonschemaValue_returnsSerialized,Magic Number,The method contains a magic number: 2,1376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullJsonschemaValueNullSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`false);" is 143.,1403
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullJsonschemaValueNonNullableSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`NullNode.getInstance()`false);" is 203.,1416
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNonNullJsonschemaValueNullSchema_throwsSerializationException,Long Statement,The length of the statement "assertThrows(RestConstraintViolationException.class`() -> recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.empty()`TextNode.valueOf("foobar")`false));" is 174.,1433
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidJsonschemaValue_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.JSONSCHEMA`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`TextNode.valueOf("foobar")`false));" is 221.,1446
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectProtobufKey_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true).get();" is 178.,1463
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullProtobfuKeyNullSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`true);" is 140.,1493
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullProtobufKeyNonNullableSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`NullNode.getInstance()`true);" is 200.,1506
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNonNullProtobufKeyNullSchema_throwsSerializationException,Long Statement,The length of the statement "assertThrows(RestConstraintViolationException.class`() -> recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.empty()`node`true));" is 149.,1524
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidProtobufKey_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`true));" is 196.,1541
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectProtobufValue_returnsSerialized,Long Statement,The length of the statement "ProtobufSchema schema=new ProtobufSchema("syntax = \"proto3\"; message ObjectValueKey { int32 foo = 1; bool bar = 2; }");" is 121.,1562
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeObjectProtobufValue_returnsSerialized,Long Statement,The length of the statement "ByteString serialized=recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false).get();" is 179.,1562
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullProtobfuValueNullSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.empty()`NullNode.getInstance()`false);" is 141.,1592
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNullProtobufValueNonNullableSchema_returnsEmpty,Long Statement,The length of the statement "Optional<ByteString> serialized=recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`NullNode.getInstance()`false);" is 201.,1605
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeNonNullProtobufValueNullSchema_throwsSerializationException,Long Statement,The length of the statement "assertThrows(RestConstraintViolationException.class`() -> recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.empty()`node`false));" is 150.,1624
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,RecordSerializerFacadeTest,serializeInvalidProtobufValue_throwsBadRequestException,Long Statement,The length of the statement "assertThrows(BadRequestException.class`() -> recordSerializer.serialize(EmbeddedFormat.PROTOBUF`TOPIC_NAME`Optional.of(RegisteredSchema.create(subject`schemaId`SCHEMA_VERSION`schema))`node`false));" is 197.,1641
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(earliestResultInfo1));" is 130.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_2))).andReturn(KafkaFuture.completedFuture(earliestResultInfo2));" is 130.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_3))).andReturn(KafkaFuture.completedFuture(earliestResultInfo3));" is 130.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(latestResultInfo1));" is 126.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_2))).andReturn(KafkaFuture.completedFuture(latestResultInfo2));" is 126.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_3))).andReturn(KafkaFuture.completedFuture(latestResultInfo3));" is 126.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "replay(adminClient`earliestResult`earliestResultInfo1`earliestResultInfo2`earliestResultInfo3`latestResult`latestResultInfo1`latestResultInfo2`latestResultInfo3`topicManager);" is 175.,177
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(earliestResultInfo1));" is 130.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_2))).andReturn(KafkaFuture.completedFuture(earliestResultInfo2));" is 130.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_3))).andReturn(KafkaFuture.completedFuture(earliestResultInfo3));" is 130.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(latestResultInfo1));" is 126.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_2))).andReturn(KafkaFuture.completedFuture(latestResultInfo2));" is 126.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_3))).andReturn(KafkaFuture.completedFuture(latestResultInfo3));" is 126.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,listLocalPartitions_existingTopic_returnsPartitions,Long Statement,The length of the statement "replay(adminClient`earliestResult`earliestResultInfo1`earliestResultInfo2`earliestResultInfo3`latestResult`latestResultInfo1`latestResultInfo2`latestResultInfo3`topicManager);" is 175.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,getPartition_existingPartition_returnsPartition,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(earliestResultInfo1));" is 130.,305
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,getPartition_existingPartition_returnsPartition,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(latestResultInfo1));" is 126.,305
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,getPartition_nonExistingPartition_returnsEmpty,Magic Number,The method contains a magic number: 100,333
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,getLocalPartition_existingPartition_returnsPartition,Long Statement,The length of the statement "expect(earliestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(earliestResultInfo1));" is 130.,373
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,getLocalPartition_existingPartition_returnsPartition,Long Statement,The length of the statement "expect(latestResult.partitionResult(toTopicPartition(PARTITION_1))).andReturn(KafkaFuture.completedFuture(latestResultInfo1));" is 126.,373
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,PartitionManagerImplTest,getLocalPartition_nonExistingPartition_returnsEmpty,Magic Number,The method contains a magic number: 100,401
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,listTopics_existingCluster_returnsTopicsWithAuthOperations,Long Statement,The length of the statement "expect(listTopicsResult.listings()).andReturn(KafkaFuture.completedFuture(singletonList(new TopicListing("topic-4"`false))));" is 125.,461
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,listTopics_existingCluster_returnsTopicsWithAuthOperations,Long Statement,The length of the statement "expect(describeTopicResult.all()).andReturn(KafkaFuture.completedFuture(createTopicDescriptionMap(TOPIC_DESCRIPTION_4)));" is 121.,461
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,getTopic_existingCluster_returnsTopicsWithAuthOperations,Long Statement,The length of the statement "expect(describeTopicResult.all()).andReturn(KafkaFuture.completedFuture(createTopicDescriptionMap(TOPIC_DESCRIPTION_4)));" is 121.,478
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,listTopics_existingCluster_returnsTopics,Long Statement,The length of the statement "expect(describeTopicResult.all()).andReturn(KafkaFuture.completedFuture(createTopicDescriptionMap(TOPIC_DESCRIPTION_1`TOPIC_DESCRIPTION_2`TOPIC_DESCRIPTION_3)));" is 161.,492
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,listLocalTopics_returnsTopics,Long Statement,The length of the statement "expect(describeTopicResult.all()).andReturn(KafkaFuture.completedFuture(createTopicDescriptionMap(TOPIC_DESCRIPTION_1`TOPIC_DESCRIPTION_2`TOPIC_DESCRIPTION_3)));" is 161.,526
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,getTopic_existingTopic_returnsTopic,Long Statement,The length of the statement "expect(describeTopicResult.all()).andReturn(KafkaFuture.completedFuture(createTopicDescriptionMap(TOPIC_DESCRIPTION_1)));" is 121.,558
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,getLocalTopic_existingTopic_returnsTopic,Long Statement,The length of the statement "expect(describeTopicResult.all()).andReturn(KafkaFuture.completedFuture(createTopicDescriptionMap(TOPIC_DESCRIPTION_1)));" is 121.,600
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_createsTopic,Long Statement,The length of the statement "expect(adminClient.createTopics(singletonList(new NewTopic(TOPIC_1.getName()`TOPIC_1.getPartitions().size()`TOPIC_1.getReplicationFactor()).configs(singletonMap("cleanup.policy"`"compact"))))).andReturn(createTopicsResult);" is 223.,627
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_createsTopic,Long Statement,The length of the statement "topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.of(TOPIC_1.getReplicationFactor())`emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact"))).get();" is 214.,627
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_defaultPartitionsCount_createsTopic,Long Statement,The length of the statement "expect(adminClient.createTopics(singletonList(new NewTopic(TOPIC_1.getName()`Optional.empty()`Optional.of(TOPIC_1.getReplicationFactor())).configs(singletonMap("cleanup.policy"`"compact"))))).andReturn(createTopicsResult);" is 222.,655
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_defaultPartitionsCount_createsTopic,Long Statement,The length of the statement "topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.empty()`Optional.of(TOPIC_1.getReplicationFactor())`emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact"))).get();" is 187.,655
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_defaultReplicationFactor_createsTopic,Long Statement,The length of the statement "expect(adminClient.createTopics(singletonList(new NewTopic(TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.empty()).configs(singletonMap("cleanup.policy"`"compact"))))).andReturn(createTopicsResult);" is 222.,683
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_defaultReplicationFactor_createsTopic,Long Statement,The length of the statement "topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.empty()`emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact"))).get();" is 187.,683
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_customReplicasAssignments_createsTopic,Long Statement,The length of the statement "expect(adminClient.createTopics(singletonList(new NewTopic(TOPIC_1.getName()`replicasAssignments).configs(singletonMap("cleanup.policy"`"compact"))))).andReturn(createTopicsResult);" is 181.,712
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingTopic_customReplicasAssignments_createsTopic,Long Statement,The length of the statement "topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.empty()`Optional.empty()`replicasAssignments`singletonMap("cleanup.policy"`Optional.of("compact"))).get();" is 169.,712
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_existingTopic_throwsTopicExists,Long Statement,The length of the statement "expect(adminClient.createTopics(singletonList(new NewTopic(TOPIC_1.getName()`TOPIC_1.getPartitions().size()`TOPIC_1.getReplicationFactor()).configs(singletonMap("cleanup.policy"`"compact"))))).andReturn(createTopicsResult);" is 223.,750
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_existingTopic_throwsTopicExists,Long Statement,The length of the statement "topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.of(TOPIC_1.getReplicationFactor())`emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact"))).get();" is 214.,750
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicManagerImplTest,createTopic_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "topicManager.createTopic(CLUSTER_ID`TOPIC_1.getName()`Optional.of(TOPIC_1.getPartitions().size())`Optional.of(TOPIC_1.getReplicationFactor())`emptyMap()`singletonMap("cleanup.policy"`Optional.of("compact"))).get();" is 214.,783
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_nonExistingTopic_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,195
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_multipleExistingTopics_returnsConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(Arrays.asList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`new ConfigResource(ConfigResource.Type.TOPIC`ALT_TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 247.,228
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_multipleExistingTopics_returnsConfigs,Long Statement,The length of the statement "Map<String`List<TopicConfig>> configs=topicConfigManager.listTopicConfigs(CLUSTER_ID`Arrays.asList(TOPIC_NAME`ALT_TOPIC_NAME)).get();" is 133.,228
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_multipleExistingTopics_returnsConfigs,Long Statement,The length of the statement "assertEquals(new HashSet<>(Arrays.asList(ALT_CONFIG_1`ALT_CONFIG_2`ALT_CONFIG_3))`new HashSet<>(configs.get(ALT_TOPIC_NAME)));" is 126.,228
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,listTopicConfigs_multipleTopicsOneNonExistingTopic_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(Arrays.asList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`new ConfigResource(ConfigResource.Type.TOPIC`ALT_TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 247.,263
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,getTopicConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,303
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,getTopicConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,303
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,getTopicConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,323
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,getTopicConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,323
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,getTopicConfig_nonExistingTopic_throwsUnknownTopicOrPartition,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,343
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`singletonList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET))))).andReturn(alterConfigsResult);" is 253.,376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_existingConfig_updatesConfig,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`KafkaFuture.completedFuture(null)));" is 152.,376
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,411
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,411
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,updateTopicConfig_nonExistingTopic_throwsUnknownTopicOrPartition,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,435
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,476
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,476
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`singletonList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 249.,476
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`KafkaFuture.completedFuture(null)));" is 152.,476
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,509
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,509
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,resetTopicConfig_nonExistingTopic_throwsUnknownTopicOrPartition,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,533
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,570
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,570
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`Arrays.asList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET)`new AlterConfigOp(new ConfigEntry(CONFIG_2.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 341.,570
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`KafkaFuture.completedFuture(null)));" is 152.,570
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "topicConfigManager.alterTopicConfigs(CLUSTER_ID`TOPIC_NAME`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 182.,570
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "topicConfigManager.alterTopicConfigs(CLUSTER_ID`TOPIC_NAME`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 182.,613
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_nonExistingTopic_alterConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,633
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_nonExistingTopic_alterConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,633
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_nonExistingTopic_alterConfigs,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`Arrays.asList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET)`new AlterConfigOp(new ConfigEntry(CONFIG_2.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 341.,633
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_nonExistingTopic_alterConfigs,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`KafkaFutures.failedFuture(new UnknownTopicOrPartitionException())));" is 184.,633
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_nonExistingTopic_alterConfigs,Long Statement,The length of the statement "topicConfigManager.alterTopicConfigs(CLUSTER_ID`TOPIC_NAME`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 182.,633
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_oneNonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 186.,679
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_oneNonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`TOPIC_NAME)`CONFIG)));" is 154.,679
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,TopicConfigManagerImplTest,alterTopicConfigs_oneNonExistingConfig_throwsNotFound,Long Statement,The length of the statement "topicConfigManager.alterTopicConfigs(CLUSTER_ID`TOPIC_NAME`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete("foobar"))).get();" is 172.,679
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerTest,errorWhenNoSchemaRegistryDefined,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaRecordSerializer.serialize(EmbeddedFormat.AVRO`"topic"`Optional.empty()`null`true));" is 186.,28
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerTest,errorWhenNoSchemaRegistryDefined,Long Statement,The length of the statement "assertEquals("Error serializing message. Schema Registry not defined` " + "no Schema Registry client available to serialize message."`rcve.getMessage());" is 153.,28
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaRecordSerializerTest,errorWhenNoSchemaRegistryDefined,Magic Number,The method contains a magic number: 42207,28
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerManagerImplTest,getBroker_nonExistingBroker_returnsEmpty,Magic Number,The method contains a magic number: 4,109
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImplTest,listClusters_returnListWithOwnCluster,Long Statement,The length of the statement "List<Cluster> expected=singletonList(Cluster.create(CLUSTER_ID`Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Arrays.asList(Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Broker.create(CLUSTER_ID`NODE_2.id()`NODE_2.host()`NODE_2.port()`NODE_2.rack())`Broker.create(CLUSTER_ID`NODE_3.id()`NODE_3.host()`NODE_3.port()`NODE_3.rack()))));" is 400.,67
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImplTest,listClusters_noController_returnListWithOwnClusterWithoutController,Long Statement,The length of the statement "List<Cluster> expected=singletonList(Cluster.create(CLUSTER_ID`null`Arrays.asList(Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Broker.create(CLUSTER_ID`NODE_2.id()`NODE_2.host()`NODE_2.port()`NODE_2.rack())`Broker.create(CLUSTER_ID`NODE_3.id()`NODE_3.host()`NODE_3.port()`NODE_3.rack()))));" is 325.,109
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImplTest,getCluster_ownClusterId_returnsOwnCluster,Long Statement,The length of the statement "Cluster expected=Cluster.create(CLUSTER_ID`Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Arrays.asList(Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Broker.create(CLUSTER_ID`NODE_2.id()`NODE_2.host()`NODE_2.port()`NODE_2.rack())`Broker.create(CLUSTER_ID`NODE_3.id()`NODE_3.host()`NODE_3.port()`NODE_3.rack())));" is 379.,171
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ClusterManagerImplTest,getLocalCluster_returnsCluster,Long Statement,The length of the statement "Cluster expected=Cluster.create(CLUSTER_ID`Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Arrays.asList(Broker.create(CLUSTER_ID`NODE_1.id()`NODE_1.host()`NODE_1.port()`NODE_1.rack())`Broker.create(CLUSTER_ID`NODE_2.id()`NODE_2.host()`NODE_2.port()`NODE_2.rack())`Broker.create(CLUSTER_ID`NODE_3.id()`NODE_3.host()`NODE_3.port()`NODE_3.rack())));" is 379.,207
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,listConsumerLags_returnsConsumerLags,Long Identifier,The length of the field listConsumerGroupOffsetsResult is 30.,213
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 132.,213
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "expect(kafkaAdminClient.listConsumerGroupOffsets(eq(CONSUMER_GROUP_ID)`anyObject(ListConsumerGroupOffsetsOptions.class))).andReturn(listConsumerGroupOffsetsResult);" is 164.,213
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "expect(listConsumerGroupOffsetsResult.partitionsToOffsetAndMetadata()).andReturn(KafkaFuture.completedFuture(OFFSET_AND_METADATA_MAP));" is 135.,213
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "expect(kafkaAdminClient.listOffsets(capture(capturedOffsetSpec)`capture(capturedListOffsetsOptions))).andReturn(new ListOffsetsResult(LATEST_OFFSETS_MAP));" is 155.,213
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_returnsConsumerLag,Long Identifier,The length of the field listConsumerGroupOffsetsResult is 30.,238
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 132.,238
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "expect(kafkaAdminClient.listConsumerGroupOffsets(eq(CONSUMER_GROUP_ID)`anyObject(ListConsumerGroupOffsetsOptions.class))).andReturn(listConsumerGroupOffsetsResult);" is 164.,238
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "expect(listConsumerGroupOffsetsResult.partitionsToOffsetAndMetadata()).andReturn(KafkaFuture.completedFuture(OFFSET_AND_METADATA_MAP));" is 135.,238
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "expect(kafkaAdminClient.listOffsets(capture(capturedOffsetSpec)`capture(capturedListOffsetsOptions))).andReturn(new ListOffsetsResult(LATEST_OFFSETS_MAP));" is 155.,238
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 2,238
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Identifier,The length of the field listConsumerGroupOffsetsResult is 30.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "final Consumer consumer=Consumer.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER_GROUP_ID).setConsumerId("").setClientId("").setHost("11.12.12.14").setAssignedPartitions(Collections.singletonList(Partition.create(CLUSTER_ID`"topic-1"`1`emptyList()))).build();" is 274.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "final ConsumerGroup consumerGroup=ConsumerGroup.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER_GROUP_ID).setSimple(true).setPartitionAssignor("org.apache.kafka.clients.consumer.RangeAssignor").setState(State.STABLE).setCoordinator(BROKER_1).setConsumers(Collections.singletonList(consumer)).build();" is 315.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "final ConsumerLag expectedConsumerLag=ConsumerLag.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER_GROUP_ID).setTopicName("topic-1").setPartitionId(1).setConsumerId("").setClientId("").setCurrentOffset(0L).setLogEndOffset(100L).build();" is 250.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.of(consumerGroup)));" is 131.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "expect(kafkaAdminClient.listConsumerGroupOffsets(eq(CONSUMER_GROUP_ID)`anyObject(ListConsumerGroupOffsetsOptions.class))).andReturn(listConsumerGroupOffsetsResult);" is 164.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "expect(listConsumerGroupOffsetsResult.partitionsToOffsetAndMetadata()).andReturn(KafkaFuture.completedFuture(OFFSET_AND_METADATA_MAP));" is 135.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Long Statement,The length of the statement "expect(kafkaAdminClient.listOffsets(capture(capturedOffsetSpec)`capture(capturedListOffsetsOptions))).andReturn(new ListOffsetsResult(LATEST_OFFSETS_MAP));" is 155.,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingPartitionAssignment_returnsConsumerLag,Magic Number,The method contains a magic number: 100L,265
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingConsumerLag_returnsEmpty,Long Identifier,The length of the field listConsumerGroupOffsetsResult is 30.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingConsumerLag_returnsEmpty,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP_ID)).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 132.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingConsumerLag_returnsEmpty,Long Statement,The length of the statement "expect(kafkaAdminClient.listConsumerGroupOffsets(eq(CONSUMER_GROUP_ID)`anyObject(ListConsumerGroupOffsetsOptions.class))).andReturn(listConsumerGroupOffsetsResult);" is 164.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingConsumerLag_returnsEmpty,Long Statement,The length of the statement "expect(listConsumerGroupOffsetsResult.partitionsToOffsetAndMetadata()).andReturn(KafkaFuture.completedFuture(OFFSET_AND_METADATA_MAP));" is 135.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingConsumerLag_returnsEmpty,Long Statement,The length of the statement "expect(kafkaAdminClient.listOffsets(capture(capturedOffsetSpec)`capture(capturedListOffsetsOptions))).andReturn(new ListOffsetsResult(LATEST_OFFSETS_MAP));" is 155.,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerLagManagerImplTest,getConsumerLag_nonExistingConsumerLag_returnsEmpty,Magic Number,The method contains a magic number: 2,331
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_returnsConsumerAssignments,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId())).andReturn(completedFuture(Optional.of(CONSUMER)));" is 153.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_returnsConsumerAssignments,Long Statement,The length of the statement "List<ConsumerAssignment> assignments=consumerAssignmentManager.listConsumerAssignments(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId()).get();" is 160.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_returnsConsumerAssignments,Long Statement,The length of the statement "assertEquals(Arrays.asList(ConsumerAssignment.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER.getConsumerGroupId()).setConsumerId(CONSUMER.getConsumerId()).setTopicName("topic-1").setPartitionId(1).build()`ConsumerAssignment.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER.getConsumerGroupId()).setConsumerId(CONSUMER.getConsumerId()).setTopicName("topic-2").setPartitionId(2).build()`ConsumerAssignment.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER.getConsumerGroupId()).setConsumerId(CONSUMER.getConsumerId()).setTopicName("topic-3").setPartitionId(3).build())`assignments);" is 623.,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_returnsConsumerAssignments,Magic Number,The method contains a magic number: 2,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_returnsConsumerAssignments,Magic Number,The method contains a magic number: 3,81
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_nonExistentConsumer_throwsNotFound,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId())).andReturn(completedFuture(Optional.empty()));" is 148.,121
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,listConsumerAssignments_nonExistentConsumer_throwsNotFound,Long Statement,The length of the statement "consumerAssignmentManager.listConsumerAssignments(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId()).get();" is 123.,121
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignments_returnsConsumerAssignment,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId())).andReturn(completedFuture(Optional.of(CONSUMER)));" is 153.,140
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignments_returnsConsumerAssignment,Long Statement,The length of the statement "ConsumerAssignment assignment=consumerAssignmentManager.getConsumerAssignment(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId()`"topic-1"`1).get().get();" is 169.,140
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignments_returnsConsumerAssignment,Long Statement,The length of the statement "assertEquals(ConsumerAssignment.builder().setClusterId(CLUSTER_ID).setConsumerGroupId(CONSUMER.getConsumerGroupId()).setConsumerId(CONSUMER.getConsumerId()).setTopicName("topic-1").setPartitionId(1).build()`assignment);" is 219.,140
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignment_nonExistingConsumer_throwsNotFound,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId())).andReturn(completedFuture(Optional.empty()));" is 148.,166
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignment_nonExistingConsumer_throwsNotFound,Long Statement,The length of the statement "consumerAssignmentManager.getConsumerAssignment(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId()`"topic-1"`1).get();" is 133.,166
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignment_nonExistingConsumerAssignment_returnsEmpty,Long Statement,The length of the statement "expect(consumerManager.getConsumer(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId())).andReturn(completedFuture(Optional.of(CONSUMER)));" is 153.,185
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignment_nonExistingConsumerAssignment_returnsEmpty,Long Statement,The length of the statement "Optional<ConsumerAssignment> assignment=consumerAssignmentManager.getConsumerAssignment(CLUSTER_ID`CONSUMER.getConsumerGroupId()`CONSUMER.getConsumerId()`"foobar"`100).get();" is 174.,185
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerAssignmentManagerImplTest,getConsumerAssignment_nonExistingConsumerAssignment_returnsEmpty,Magic Number,The method contains a magic number: 100,185
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,listAllReassignments_existingCluster_returnsReassignments,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,126
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,listAllReassignments_timeoutException_throwsTimeoutException,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,139
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,searchReassignmentsByTopic_existingCluster_returnsReassignments,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,168
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,searchReassignmentsByTopic_nonExistingTopic_returnsEmpty,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,195
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,getReassignment_existingClusterTopicPartition_returnsReassignment,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,209
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,getReassignment_nonExistingTopic_returnsEmpty,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,235
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,getReassignment_nonExistingTopic_returnsEmpty,Magic Number,The method contains a magic number: 3,235
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,getReassignment_nonExistingPartition_returnsEmpty,Long Identifier,The length of the field listPartitionReassignmentsResult is 32.,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ReassignmentManagerImplTest,getReassignment_nonExistingPartition_returnsEmpty,Magic Number,The method contains a magic number: 4,248
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,setUp,Long Statement,The length of the statement "producer=new MockProducer<>(CLUSTER`false`new RoundRobinPartitioner()`new ByteArraySerializer()`new ByteArraySerializer());" is 123.,87
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result1=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-1"))`Optional.of(ByteString.copyFromUtf8("value-1"))`Instant.ofEpochMilli(1000));" is 249.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result2=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-2"))`Optional.of(ByteString.copyFromUtf8("value-2"))`Instant.ofEpochMilli(2000));" is 249.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result3=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-3"))`Optional.of(ByteString.copyFromUtf8("value-3"))`Instant.ofEpochMilli(3000));" is 249.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "assertProducerRecordsEquals(Arrays.asList(new ProducerRecord<>("topic-1"`1`1000L`"key-1".getBytes(StandardCharsets.UTF_8)`"value-1".getBytes(StandardCharsets.UTF_8)`emptyList())`new ProducerRecord<>("topic-1"`1`2000L`"key-2".getBytes(StandardCharsets.UTF_8)`"value-2".getBytes(StandardCharsets.UTF_8)`emptyList())`new ProducerRecord<>("topic-1"`1`3000L`"key-3".getBytes(StandardCharsets.UTF_8)`"value-3".getBytes(StandardCharsets.UTF_8)`emptyList()))`producer.history());" is 471.,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 1000,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 2000,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 3000,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 2,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 1000L,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 2000L,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 3000L,99
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result1=produceController.produce("cluster-1"`"topic-1"`Optional.empty()`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-1"))`Optional.of(ByteString.copyFromUtf8("value-1"))`Instant.ofEpochMilli(1000));" is 251.,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result2=produceController.produce("cluster-1"`"topic-1"`Optional.empty()`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-2"))`Optional.of(ByteString.copyFromUtf8("value-2"))`Instant.ofEpochMilli(2000));" is 251.,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result3=produceController.produce("cluster-1"`"topic-1"`Optional.empty()`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-3"))`Optional.of(ByteString.copyFromUtf8("value-3"))`Instant.ofEpochMilli(3000));" is 251.,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Long Statement,The length of the statement "assertProducerRecordsEquals(Arrays.asList(new ProducerRecord<>("topic-1"`null`1000L`"key-1".getBytes(StandardCharsets.UTF_8)`"value-1".getBytes(StandardCharsets.UTF_8)`emptyList())`new ProducerRecord<>("topic-1"`null`2000L`"key-2".getBytes(StandardCharsets.UTF_8)`"value-2".getBytes(StandardCharsets.UTF_8)`emptyList())`new ProducerRecord<>("topic-1"`null`3000L`"key-3".getBytes(StandardCharsets.UTF_8)`"value-3".getBytes(StandardCharsets.UTF_8)`emptyList()))`producer.history());" is 480.,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 1000,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 2000,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 3000,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 2,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 1000L,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 2000L,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithNullPartitionIdKeyAndValue_produces,Magic Number,The method contains a magic number: 3000L,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result1=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.empty()`Optional.of(ByteString.copyFromUtf8("value-1"))`Instant.ofEpochMilli(1000));" is 220.,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result2=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.empty()`Optional.of(ByteString.copyFromUtf8("value-2"))`Instant.ofEpochMilli(2000));" is 220.,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result3=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.empty()`Optional.of(ByteString.copyFromUtf8("value-3"))`Instant.ofEpochMilli(3000));" is 220.,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Long Statement,The length of the statement "assertProducerRecordsEquals(Arrays.asList(new ProducerRecord<>("topic-1"`1`1000L`null`"value-1".getBytes(StandardCharsets.UTF_8)`emptyList())`new ProducerRecord<>("topic-1"`1`2000L`null`"value-2".getBytes(StandardCharsets.UTF_8)`emptyList())`new ProducerRecord<>("topic-1"`1`3000L`null`"value-3".getBytes(StandardCharsets.UTF_8)`emptyList()))`producer.history());" is 363.,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 1000,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 2000,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 3000,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 2,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 1000L,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 2000L,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdNullKeyAndValue_produces,Magic Number,The method contains a magic number: 3000L,239
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result1=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-1"))`Optional.empty()`Instant.ofEpochMilli(1000));" is 218.,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result2=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-2"))`Optional.empty()`Instant.ofEpochMilli(2000));" is 218.,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result3=produceController.produce("cluster-1"`"topic-1"`Optional.of(1)`ImmutableMultimap.of()`Optional.of(ByteString.copyFromUtf8("key-3"))`Optional.empty()`Instant.ofEpochMilli(3000));" is 218.,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Long Statement,The length of the statement "assertProducerRecordsEquals(Arrays.asList(new ProducerRecord<>("topic-1"`1`1000L`"key-1".getBytes(StandardCharsets.UTF_8)`null`emptyList())`new ProducerRecord<>("topic-1"`1`2000L`"key-2".getBytes(StandardCharsets.UTF_8)`null`emptyList())`new ProducerRecord<>("topic-1"`1`3000L`"key-3".getBytes(StandardCharsets.UTF_8)`null`emptyList()))`producer.history());" is 357.,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 1000,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 2000,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 3000,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 2,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 1000L,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 2000L,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithPartitionIdKeyAndNullValue_produces,Magic Number,The method contains a magic number: 3000L,309
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result1=produceController.produce("cluster-1"`"topic-1"`Optional.empty()`ImmutableMultimap.of("X"`Optional.of(ByteString.copyFromUtf8("X")))`Optional.of(ByteString.copyFromUtf8("key-1"))`Optional.of(ByteString.copyFromUtf8("value-1"))`Instant.ofEpochMilli(1000));" is 296.,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result2=produceController.produce("cluster-1"`"topic-1"`Optional.empty()`ImmutableMultimap.of("Y"`Optional.of(ByteString.copyFromUtf8("Y")))`Optional.of(ByteString.copyFromUtf8("key-2"))`Optional.of(ByteString.copyFromUtf8("value-2"))`Instant.ofEpochMilli(2000));" is 296.,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Long Statement,The length of the statement "CompletableFuture<ProduceResult> result3=produceController.produce("cluster-1"`"topic-1"`Optional.empty()`ImmutableMultimap.of("Z"`Optional.of(ByteString.copyFromUtf8("Z")))`Optional.of(ByteString.copyFromUtf8("key-3"))`Optional.of(ByteString.copyFromUtf8("value-3"))`Instant.ofEpochMilli(3000));" is 296.,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Long Statement,The length of the statement "assertProducerRecordsEquals(Arrays.asList(new ProducerRecord<>("topic-1"`null`1000L`"key-1".getBytes(StandardCharsets.UTF_8)`"value-1".getBytes(StandardCharsets.UTF_8)`singletonList(new RecordHeader("X"`ByteString.copyFromUtf8("X").toByteArray())))`new ProducerRecord<>("topic-1"`null`2000L`"key-2".getBytes(StandardCharsets.UTF_8)`"value-2".getBytes(StandardCharsets.UTF_8)`singletonList(new RecordHeader("Y"`ByteString.copyFromUtf8("Y").toByteArray())))`new ProducerRecord<>("topic-1"`null`3000L`"key-3".getBytes(StandardCharsets.UTF_8)`"value-3".getBytes(StandardCharsets.UTF_8)`singletonList(new RecordHeader("Z"`ByteString.copyFromUtf8("Z").toByteArray()))))`producer.history());" is 684.,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 1000,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 2000,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 3000,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 2,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 1000L,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 2000L,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,produceWithKeyAndValueAndHeaders_produces,Magic Number,The method contains a magic number: 3000L,379
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,assertProducerRecordsEquals,Long Identifier,The length of the field BYTE_ARRAY_TO_BYTE_STRING_RECORD_FUNCTION is 41.,449
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ProduceControllerImplTest,assertProducerRecordsEquals,Long Statement,The length of the statement "assertEquals(expected.stream().map(BYTE_ARRAY_TO_BYTE_STRING_RECORD_FUNCTION).collect(Collectors.toList())`actual.stream().map(BYTE_ARRAY_TO_BYTE_STRING_RECORD_FUNCTION).collect(Collectors.toList()));" is 200.,449
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,searchAcls_returnsMatchedAcls,Long Statement,The length of the statement "expect(clusterManager.getCluster(CLUSTER_ID)).andReturn(completedFuture(Optional.of(Cluster.create(CLUSTER_ID`null`emptyList()))));" is 131.,128
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,searchAcls_returnsMatchedAcls,Long Statement,The length of the statement "expect(adminClient.describeAcls(new AclBindingFilter(new ResourcePatternFilter(ResourceType.ANY`null`PatternType.ANY)`new AccessControlEntryFilter(null`null`AclOperation.ANY`AclPermissionType.ANY)))).andReturn(describeAclsResult);" is 230.,128
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,searchAcls_returnsMatchedAcls,Long Statement,The length of the statement "List<Acl> acls=aclManager.searchAcls(CLUSTER_ID`Acl.ResourceType.ANY`null`Acl.PatternType.ANY`null`null`Acl.Operation.ANY`Acl.Permission.ANY).get();" is 148.,128
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,searchAcls_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "aclManager.searchAcls(CLUSTER_ID`Acl.ResourceType.ANY`null`Acl.PatternType.ANY`null`null`Acl.Operation.ANY`Acl.Permission.ANY).get();" is 133.,164
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,createAcl_createsAcl,Long Statement,The length of the statement "expect(clusterManager.getCluster(CLUSTER_ID)).andReturn(completedFuture(Optional.of(Cluster.create(CLUSTER_ID`null`emptyList()))));" is 131.,187
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,createAcl_createsAcl,Long Statement,The length of the statement "aclManager.createAcl(CLUSTER_ID`Acl.ResourceType.CLUSTER`"*"`Acl.PatternType.LITERAL`"User:alice"`"*"`Acl.Operation.READ`Acl.Permission.ALLOW).get();" is 149.,187
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,createAcl_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "aclManager.createAcl(CLUSTER_ID`Acl.ResourceType.CLUSTER`"*"`Acl.PatternType.LITERAL`"User:alice"`"*"`Acl.Operation.READ`Acl.Permission.ALLOW).get();" is 149.,213
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,createAcls_createsAcls,Long Statement,The length of the statement "expect(clusterManager.getCluster(CLUSTER_ID)).andReturn(completedFuture(Optional.of(Cluster.create(CLUSTER_ID`null`emptyList()))));" is 131.,236
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,createAcls_createsAcls,Long Statement,The length of the statement "List<Acl> acls=Arrays.asList(Acl.builder().setClusterId(CLUSTER_ID).setOperation(Acl.Operation.valueOf(ACL_BINDING_1.entry().operation().name())).setHost(ACL_BINDING_1.entry().host()).setPermission(Acl.Permission.valueOf(ACL_BINDING_1.entry().permissionType().name())).setPrincipal(ACL_BINDING_1.entry().principal()).setPatternType(Acl.PatternType.valueOf(ACL_BINDING_1.pattern().patternType().name())).setResourceName(ACL_BINDING_1.pattern().name()).setResourceType(Acl.ResourceType.valueOf(ACL_BINDING_1.pattern().resourceType().name())).build()`Acl.builder().setClusterId(CLUSTER_ID).setOperation(Acl.Operation.valueOf(ACL_BINDING_2.entry().operation().name())).setHost(ACL_BINDING_2.entry().host()).setPermission(Acl.Permission.valueOf(ACL_BINDING_2.entry().permissionType().name())).setPrincipal(ACL_BINDING_2.entry().principal()).setPatternType(Acl.PatternType.valueOf(ACL_BINDING_2.pattern().patternType().name())).setResourceName(ACL_BINDING_2.pattern().name()).setResourceType(Acl.ResourceType.valueOf(ACL_BINDING_2.pattern().resourceType().name())).build());" is 1068.,236
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,deleteAcls_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "AclBindingFilter aclBindingFilter=new AclBindingFilter(new ResourcePatternFilter(ResourceType.ANY`null`PatternType.ANY)`new AccessControlEntryFilter(null`null`AclOperation.ANY`AclPermissionType.ANY));" is 200.,301
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,deleteAcls_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "expect(clusterManager.getCluster(CLUSTER_ID)).andReturn(completedFuture(Optional.of(Cluster.create(CLUSTER_ID`null`emptyList()))));" is 131.,301
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,deleteAcls_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "expect(deleteAclsResult.values()).andReturn(singletonMap(aclBindingFilter`KafkaFuture.completedFuture(deleteFilterResults)));" is 125.,301
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,deleteAcls_deletesAndReturnsMatchedAcls,Long Statement,The length of the statement "List<Acl> acls=aclManager.deleteAcls(CLUSTER_ID`Acl.ResourceType.ANY`null`Acl.PatternType.ANY`null`null`Acl.Operation.ANY`Acl.Permission.ANY).get();" is 148.,301
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,AclManagerImplTest,deleteAcls_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "aclManager.deleteAcls(CLUSTER_ID`Acl.ResourceType.ANY`null`Acl.PatternType.ANY`null`null`Acl.Operation.ANY`Acl.Permission.ANY).get();" is 133.,344
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,137
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,137
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,listBrokerConfigs_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,161
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,getBrokerConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,196
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,getBrokerConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,196
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,getBrokerConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,220
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,getBrokerConfig_nonExistingConfig_returnsEmpty,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,220
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,getBrokerConfig_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,244
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_existingConfig_updatesConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,279
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_existingConfig_updatesConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,279
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_existingConfig_updatesConfigs,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`singletonList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET))))).andReturn(alterConfigsResult);" is 269.,279
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_existingConfig_updatesConfigs,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`KafkaFuture.completedFuture(null)));" is 168.,279
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,318
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,318
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,updateBrokerConfig_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,346
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,389
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,389
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`singletonList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 265.,389
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_existingConfig_resetsConfig,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`KafkaFuture.completedFuture(null)));" is 168.,389
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,426
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,426
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,resetBrokerConfig_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,454
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,493
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,493
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`Arrays.asList(new AlterConfigOp(new ConfigEntry(CONFIG_1.getName()`"new-value")`AlterConfigOp.OpType.SET)`new AlterConfigOp(new ConfigEntry(CONFIG_2.getName()`null)`AlterConfigOp.OpType.DELETE))))).andReturn(alterConfigsResult);" is 357.,493
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "expect(alterConfigsResult.values()).andReturn(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`KafkaFuture.completedFuture(null)));" is 168.,493
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_existingConfigs_alterConfigs,Long Statement,The length of the statement "brokerConfigManager.alterBrokerConfigs(CLUSTER_ID`BROKER_ID`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 183.,493
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "brokerConfigManager.alterBrokerConfigs(CLUSTER_ID`BROKER_ID`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete(CONFIG_2.getName()))).get();" is 183.,540
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_oneNonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(adminClient.describeConfigs(eq(singletonList(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))))`anyObject(DescribeConfigsOptions.class))).andReturn(describeConfigsResult);" is 202.,560
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_oneNonExistingConfig_throwsNotFound,Long Statement,The length of the statement "expect(describeConfigsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(new ConfigResource(ConfigResource.Type.BROKER`String.valueOf(BROKER_ID))`CONFIG)));" is 170.,560
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,BrokerConfigManagerImplTest,alterBrokerConfigs_oneNonExistingConfig_throwsNotFound,Long Statement,The length of the statement "brokerConfigManager.alterBrokerConfigs(CLUSTER_ID`BROKER_ID`Arrays.asList(AlterConfigCommand.set(CONFIG_1.getName()`"new-value")`AlterConfigCommand.delete("foobar"))).get();" is 173.,560
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,setUp,Long Statement,The length of the statement "consumerGroupListings=new ConsumerGroupListing[]{createMock(ConsumerGroupListing.class)`createMock(ConsumerGroupListing.class)};" is 128.,268
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,setUp,Long Statement,The length of the statement "consumerGroupDescriptions=new ConsumerGroupDescription[]{createMock(ConsumerGroupDescription.class)`createMock(ConsumerGroupDescription.class)};" is 144.,268
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,setUp,Long Statement,The length of the statement "memberDescriptions=new MemberDescription[][]{{createMock(MemberDescription.class)`createMock(MemberDescription.class)`createMock(MemberDescription.class)}`{createMock(MemberDescription.class)`createMock(MemberDescription.class)`createMock(MemberDescription.class)}};" is 266.,268
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,setUp,Long Statement,The length of the statement "memberAssignments=new MemberAssignment[][]{{createMock(MemberAssignment.class)`createMock(MemberAssignment.class)`createMock(MemberAssignment.class)}`{createMock(MemberAssignment.class)`createMock(MemberAssignment.class)`createMock(MemberAssignment.class)}};" is 258.,268
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,listConsumerGroups_returnsConsumerGroups,Long Statement,The length of the statement "expect(adminClient.describeConsumerGroups(Arrays.stream(CONSUMER_GROUPS).map(ConsumerGroup::getConsumerGroupId).collect(Collectors.toList()))).andReturn(describeConsumerGroupsResult);" is 183.,308
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,listConsumerGroups_returnsConsumerGroups,Long Statement,The length of the statement "expect(describeConsumerGroupsResult.all()).andReturn(KafkaFuture.completedFuture(IntStream.range(0`CONSUMER_GROUPS.length).boxed().collect(Collectors.toMap(i -> CONSUMER_GROUPS[i].getConsumerGroupId()`i -> consumerGroupDescriptions[i]))));" is 239.,308
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,listConsumerGroups_returnsConsumerGroups,Long Statement,The length of the statement "expect(memberAssignments[i][j].topicPartitions()).andStubReturn(CONSUMERS[i][j].getAssignedPartitions().stream().map(Partition::toTopicPartition).collect(Collectors.toSet()));" is 175.,308
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "expect(adminClient.describeConsumerGroups(singletonList(CONSUMER_GROUPS[0].getConsumerGroupId()))).andReturn(describeConsumerGroupsResult);" is 139.,385
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "expect(describeConsumerGroupsResult.all()).andReturn(KafkaFuture.completedFuture(singletonMap(CONSUMER_GROUPS[0].getConsumerGroupId()`consumerGroupDescriptions[0])));" is 166.,385
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "expect(memberAssignments[0][j].topicPartitions()).andStubReturn(CONSUMERS[0][j].getAssignedPartitions().stream().map(Partition::toTopicPartition).collect(Collectors.toSet()));" is 175.,385
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "ConsumerGroup consumerGroup=consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUPS[0].getConsumerGroupId()).get().get();" is 130.,385
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,getConsumerGroup_nonExistingConsumerGroup_returnsEmpty,Long Statement,The length of the statement "expect(adminClient.describeConsumerGroups(singletonList(CONSUMER_GROUPS[0].getConsumerGroupId()))).andReturn(describeConsumerGroupsResult);" is 139.,454
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerGroupManagerImplTest,getConsumerGroup_nonExistingConsumerGroup_returnsEmpty,Long Statement,The length of the statement "Optional<ConsumerGroup> consumerGroup=consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUPS[0].getConsumerGroupId()).get();" is 134.,454
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,setUp,Long Statement,The length of the statement "schemaRegistryClient=(MockSchemaRegistryClient)MockSchemaRegistry.getClientForScope(UUID.randomUUID().toString()`Arrays.asList(new AvroSchemaProvider()`new JsonSchemaProvider()`new ProtobufSchemaProvider()));" is 208.,67
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(schemaId)`Optional.empty()`Optional.empty()`true);" is 172.,86
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_subject,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of(subject)`Optional.empty()`Optional.of(schemaId)`Optional.empty()`Optional.empty()`true);" is 176.,106
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_subjectNameStrategy,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.of(strategy)`Optional.of(schemaId)`Optional.empty()`Optional.empty()`true);" is 177.,127
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(schemaVersion)`Optional.empty()`true);" is 177.,149
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subject,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of(subject)`Optional.empty()`Optional.empty()`Optional.of(schemaVersion)`Optional.empty()`true);" is 181.,169
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subjectNameStrategy,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.of(strategy)`Optional.empty()`Optional.of(schemaVersion)`Optional.empty()`true);" is 182.,190
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_rawSchema,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.AVRO)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("{\"type\": \"int\"}")`true);" is 201.,212
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_rawSchema_subject,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.AVRO)`Optional.of(subject)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("{\"type\": \"int\"}")`true);" is 205.,232
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_rawSchema_subjectNameStrategy,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.AVRO)`Optional.empty()`Optional.of(strategy)`Optional.empty()`Optional.empty()`Optional.of("{\"type\": \"int\"}")`true);" is 206.,253
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`true);" is 167.,275
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema_subject,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of(subject)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`true);" is 171.,295
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema_subjectNameStrategy,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.of(strategy)`Optional.empty()`Optional.empty()`Optional.empty()`true);" is 172.,316
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_jsonschema_rawSchema,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.JSONSCHEMA)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("{\"type\": \"string\"}")`true);" is 210.,338
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_protobuf_rawSchema,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.PROTOBUF)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("syntax = \"proto3\"; message MyKey { string foo = 1; }")`true);" is 240.,358
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema_notIsKey,Long Statement,The length of the statement "RegisteredSchema actual=schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`false);" is 168.,378
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_nonExistingSchemaId,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(1000)`Optional.empty()`Optional.empty()`true));" is 241.,398
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_nonExistingSchemaId,Long Statement,The length of the statement "assertEquals("Error serializing message. Error when fetching schema by id. schemaId = 1000\nSubject " + "Not Found; error code: 40401"`rcve.getMessage());" is 154.,398
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_nonExistingSchemaId,Magic Number,The method contains a magic number: 1000,398
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_nonExistingSchemaId,Magic Number,The method contains a magic number: 42207,398
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_schemaIdNotInSubject,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(schemaId)`Optional.empty()`Optional.empty()`true));" is 245.,420
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_schemaIdNotInSubject,Long Statement,The length of the statement "assertEquals("Error serializing message. Error when fetching schema version. " + "subject = topic-1-key` " + "schema = \"int\"\nSubject Not Found; error code: 40401"`rcve.getMessage());" is 185.,420
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaId_schemaIdNotInSubject,Magic Number,The method contains a magic number: 42207,420
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_rawSchema_invalidSchema,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.AVRO)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("foobar")`true));" is 261.,446
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_rawSchema_invalidSchema,Magic Number,The method contains a magic number: 42205,446
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_jsonschema_rawSchema_invalidSchema,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.JSONSCHEMA)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("foobar")`true));" is 267.,467
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_jsonschema_rawSchema_invalidSchema,Magic Number,The method contains a magic number: 42205,467
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_protobuf_rawSchema_invalidSchema,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.PROTOBUF)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("foobar")`true));" is 265.,488
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_protobuf_rawSchema_invalidSchema,Magic Number,The method contains a magic number: 42205,488
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema_noSchema,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`true));" is 240.,509
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema_noSchema,Long Statement,The length of the statement "assertEquals("Error serializing message. Error when fetching latest schema version. " + "subject = " + "topic-1-key\nSubject Not Found; error code: 40401"`rcve.getMessage());" is 174.,509
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_latestSchema_noSchema,Magic Number,The method contains a magic number: 42207,509
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subjectNameStrategy_strategyDependsOnSchema,Long Statement,The length of the statement "BadRequestException bre=assertThrows(BadRequestException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.of(strategy)`Optional.empty()`Optional.of(schemaVersion)`Optional.empty()`true));" is 228.,532
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subjectNameStrategy_strategyDependsOnSchema,Magic Number,The method contains a magic number: 400,532
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subjectNameStrategy_strategyReturnsNull,Long Statement,The length of the statement "IllegalArgumentException rcve=assertThrows(IllegalArgumentException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.of(strategy)`Optional.empty()`Optional.of(100)`Optional.empty()`true));" is 229.,558
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subjectNameStrategy_strategyReturnsNull,Long Statement,The length of the statement "assertTrue(rcve.getMessage().startsWith("Cannot use schema_subject_strategy=" + "io.confluent.kafkarest.controllers." + "SchemaManagerImplTest"+ "$NullReturningSubjectNameStrategy@"));" is 184.,558
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchema_avro_schemaVersion_subjectNameStrategy_strategyReturnsNull,Magic Number,The method contains a magic number: 100,558
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,schemaRegistryDisabledReturnsError,Long Statement,The length of the statement "RestConstraintViolationException e=assertThrows(RestConstraintViolationException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`true));" is 239.,586
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,schemaRegistryDisabledReturnsError,Magic Number,The method contains a magic number: 42206,586
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,rawSchemaWithUnsupportedSchemaVersionThrowsException,Long Statement,The length of the statement "BadRequestException iae=assertThrows(BadRequestException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(0)`Optional.empty()`true));" is 211.,608
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,rawSchemaWithUnsupportedSchemaVersionThrowsException,Magic Number,The method contains a magic number: 400,608
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchemaFromSchemaVersionThrowsInvalidSchemaException,Long Statement,The length of the statement "RestConstraintViolationException iae=assertThrows(RestConstraintViolationException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.of(0)`Optional.empty()`true));" is 246.,627
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchemaFromSchemaVersionThrowsInvalidSchemaException,Magic Number,The method contains a magic number: 42205,627
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchemaFromSchemaVersionThrowsInvalidBadRequestException,Long Statement,The length of the statement "BadRequestException iae=assertThrows(BadRequestException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.of(0)`Optional.empty()`true));" is 220.,658
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,getSchemaFromSchemaVersionThrowsInvalidBadRequestException,Magic Number,The method contains a magic number: 400,658
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingSchemaBySchemaVersion,Long Statement,The length of the statement "RestConstraintViolationException iae=assertThrows(RestConstraintViolationException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.of(123)`Optional.empty()`true));" is 248.,690
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingSchemaBySchemaVersion,Long Statement,The length of the statement "assertEquals("Invalid schema: Error when fetching schema by version. subject = subject1` version = 123"`iae.getMessage());" is 122.,690
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingSchemaBySchemaVersion,Magic Number,The method contains a magic number: 123,690
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingSchemaBySchemaVersion,Magic Number,The method contains a magic number: 123,690
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingSchemaBySchemaVersion,Magic Number,The method contains a magic number: 42205,690
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaNotSupportedWithFormat,Long Statement,The length of the statement "BadRequestException iae=assertThrows(BadRequestException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.of(EmbeddedFormat.JSON)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of("rawSchema")`true));" is 237.,721
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaCantParseSchema,Long Statement,The length of the statement "BadRequestException rcve=assertThrows(BadRequestException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.of(embeddedFormatMock)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(TextNode.valueOf("rawSchema").toString())`true));" is 268.,739
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaCantParseSchema,Long Statement,The length of the statement "assertEquals("Raw schema not supported with format = " + "EasyMock for class " + "io.confluent.kafkarest.entities.EmbeddedFormat"`rcve.getMessage());" is 149.,739
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaCantParseSchema,Magic Number,The method contains a magic number: 400,739
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaNotSupportedWithSchema,Long Statement,The length of the statement "expect(schemaProviderMock.parseSchema(TextNode.valueOf("rawSchema").toString()`emptyList()`true)).andReturn(Optional.empty());" is 126.,775
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaNotSupportedWithSchema,Long Statement,The length of the statement "BadRequestException bre=assertThrows(BadRequestException.class`() -> schemaManager.getSchema(TOPIC_NAME`Optional.of(embeddedFormatMock)`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(TextNode.valueOf("rawSchema").toString())`true));" is 265.,775
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaNotSupportedWithSchema,Long Statement,The length of the statement "assertEquals("Raw schema not supported with format = " + "EasyMock for class " + "io.confluent.kafkarest.entities.EmbeddedFormat"`bre.getMessage());" is 148.,775
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRawSchemaNotSupportedWithSchema,Magic Number,The method contains a magic number: 400,775
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchema,Long Statement,The length of the statement "expect(schemaProviderMock.parseSchema(TextNode.valueOf("rawString").toString()`emptyList()`true)).andReturn(Optional.of(parsedSchemaMock));" is 139.,811
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchema,Long Statement,The length of the statement "expect(schemaRegistryClientMock.register("subject1"`parsedSchemaMock)).andThrow(new IOException("Can't register Schema"));" is 122.,811
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchema,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.of(embeddedFormatMock)`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(TextNode.valueOf("rawString").toString())`true));" is 301.,811
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchema,Long Statement,The length of the statement "assertEquals("Error serializing message. Error when registering schema. " + "format = EasyMock for class " + "io.confluent.kafkarest.entities.EmbeddedFormat` "+ "subject = subject1` "+ "schema = null\n"+ "Can't register Schema"`rcve.getMessage());" is 247.,811
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchema,Magic Number,The method contains a magic number: 42207,811
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchemaUnauthorized,Long Statement,The length of the statement "expect(schemaProviderMock.parseSchema(TextNode.valueOf("rawString").toString()`emptyList()`true)).andReturn(Optional.of(parsedSchemaMock));" is 139.,858
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchemaUnauthorized,Long Statement,The length of the statement "expect(schemaRegistryClientMock.register("subject1"`parsedSchemaMock)).andThrow(new RestClientException("User is denied operation Write on Subject: subject1"`Status.FORBIDDEN.getStatusCode()`KAFKA_AUTHORIZATION_ERROR_CODE));" is 224.,858
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchemaUnauthorized,Long Statement,The length of the statement "RestException rcve=assertThrows(RestException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.of(embeddedFormatMock)`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.empty()`Optional.of(TextNode.valueOf("rawString").toString())`true));" is 263.,858
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorRegisteringSchemaUnauthorized,Long Statement,The length of the statement "assertEquals("Error when registering schema. format = EasyMock for class " + "io.confluent.kafkarest.entities.EmbeddedFormat` subject = subject1` schema = null"`rcve.getMessage());" is 180.,858
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingLatestSchemaBySchemaVersionInvalidSchema,Long Statement,The length of the statement "SchemaMetadata schemaMetadata=new SchemaMetadata(-1`0`EmbeddedFormat.AVRO.name()`Collections.emptyList()`TextNode.valueOf("schema").toString());" is 144.,905
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingLatestSchemaBySchemaVersionInvalidSchema,Long Statement,The length of the statement "RestConstraintViolationException rcve=assertThrows(RestConstraintViolationException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`true));" is 249.,905
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingLatestSchemaBySchemaVersionInvalidSchema,Magic Number,The method contains a magic number: 42205,905
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingLatestSchemaBySchemaVersionBadRequest,Long Statement,The length of the statement "BadRequestException bre=assertThrows(BadRequestException.class`() -> mySchemaManager.getSchema(TOPIC_NAME`Optional.empty()`Optional.of("subject1")`Optional.empty()`Optional.empty()`Optional.empty()`Optional.empty()`true));" is 222.,942
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,SchemaManagerImplTest,errorFetchingLatestSchemaBySchemaVersionBadRequest,Magic Number,The method contains a magic number: 400,942
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImplTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId())).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 150.,149
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImplTest,listConsumerGroups_nonExistentConsumerGroup_throwsNotFound,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId())).andReturn(completedFuture(Optional.empty()));" is 139.,161
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImplTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId())).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 150.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImplTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "Consumer consumer=consumerManager.getConsumer(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId()`CONSUMERS[0].getConsumerId()).get().get();" is 135.,175
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImplTest,getConsumer_nonExistingConsumerGroup_throwsNotFound,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId())).andReturn(completedFuture(Optional.empty()));" is 139.,191
confluentinc_kafka-rest,io.confluent.kafkarest.controllers,ConsumerManagerImplTest,getConsumer_nonExistingConsumer_returnsEmpty,Long Statement,The length of the statement "expect(consumerGroupManager.getConsumerGroup(CLUSTER_ID`CONSUMER_GROUP.getConsumerGroupId())).andReturn(completedFuture(Optional.of(CONSUMER_GROUP)));" is 150.,208
confluentinc_kafka-rest,io.confluent.kafkarest.response,JsonStreamMessageBodyReader,readFrom,Long Parameter List,The method has 6 parameters. ,47
confluentinc_kafka-rest,io.confluent.kafkarest.response,CrnFactoryImpl,create,Magic Number,The method contains a magic number: 2,37
confluentinc_kafka-rest,io.confluent.kafkarest.response,CrnFactoryImpl,create,Magic Number,The method contains a magic number: 2,37
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImpl,UrlFactoryImpl,Long Parameter List,The method has 5 parameters. ,36
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImpl,computeBaseUrl,Long Parameter List,The method has 5 parameters. ,65
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImpl,computeAuthority,Long Parameter List,The method has 5 parameters. ,89
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImpl,computeAuthority,Long Statement,The length of the statement "return Stream.of(computeAuthorityFromAdvertisedListeners(advertisedListenersConfig`requestUriInfo)`computeAuthorityFromHostNameAndPort(hostNameConfig`portConfig`listenersConfig`requestUriInfo)).filter(Optional::isPresent).map(Optional::get).findFirst().orElse(requestUriInfo.getAbsolutePath().getAuthority());" is 309.,89
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponse,fromWithClock,Long Parameter List,The method has 5 parameters. ,138
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponse,resume,Long Statement,The length of the statement "responseQueue.push(CompletableFuture.completedFuture(ResultOrError.error(EXCEPTION_MAPPER.toErrorResponse(new StatusCodeException(Status.REQUEST_TIMEOUT`"Streaming connection open for longer than allowed"`"Connection will be closed.")))));" is 239.,155
confluentinc_kafka-rest,io.confluent.kafkarest.response,CrnFactoryImplTest,create_oddComponents_throwsIllegalArgument,Empty catch clause,The method has an empty catch block.,38
confluentinc_kafka-rest,io.confluent.kafkarest.response,FakeAsyncResponseTest,getValue_supended_throwsIllegalStateException,Empty catch clause,The method has an empty catch block.,56
confluentinc_kafka-rest,io.confluent.kafkarest.response,FakeAsyncResponseTest,getException_supended_throwsIllegalStateException,Empty catch clause,The method has an empty catch block.,68
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testGracePeriodExceededExceptionThrown,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 372.,45
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testGracePeriodExceededExceptionThrown,Long Statement,The length of the statement "ProduceResponse produceResponse=ProduceResponse.builder().setClusterId("clusterId").setTopicName("topicName").setPartitionId(1).setOffset(1L).setErrorCode(HttpStatus.OK_200).build();" is 182.,45
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testGracePeriodExceededExceptionThrown,Long Statement,The length of the statement "StreamingResponseFactory streamingResponseFactory=new StreamingResponseFactory(mockedChunkedOutputFactory`DURATION`DURATION);" is 125.,45
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutput,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 372.,111
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutput,Long Statement,The length of the statement "ProduceResponse produceResponse=ProduceResponse.builder().setClusterId("clusterId").setTopicName("topicName").setPartitionId(1).setOffset(1L).setErrorCode(HttpStatus.OK_200).build();" is 182.,111
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutput,Long Statement,The length of the statement "StreamingResponseFactory streamingResponseFactory=new StreamingResponseFactory(mockedChunkedOutputFactory`DURATION`DURATION);" is 125.,111
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutput,Long Statement,The length of the statement "StreamingResponse<ProduceRequest> streamingResponse=streamingResponseFactory.from(new JsonStream<>(() -> requestsMappingIterator));" is 131.,111
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextMappingException,Long Statement,The length of the statement "expect(requests.hasNext()).andThrow(new RuntimeJsonMappingException("Error thrown by mapping iterator describing problem."));" is 125.,175
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextMappingException,Long Statement,The length of the statement "ResultOrError resultOrError=ResultOrError.error(ErrorResponse.create(400`"Bad Request: Error processing JSON: " + "Error thrown by mapping iterator describing problem."));" is 171.,175
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextMappingException,Long Statement,The length of the statement "StreamingResponseFactory streamingResponseFactory=new StreamingResponseFactory(mockedChunkedOutputFactory`DURATION`DURATION);" is 125.,175
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextMappingException,Magic Number,The method contains a magic number: 400,175
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextRuntimeException,Long Statement,The length of the statement "expect(requests.hasNext()).andThrow(new RuntimeException("IO error thrown by mapping iterator describing" + " problem."));" is 122.,217
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextRuntimeException,Long Statement,The length of the statement "ResultOrError resultOrError=ResultOrError.error(ErrorResponse.create(400`"Bad Request: Error processing message: " + "IO error thrown by mapping iterator describing problem."));" is 177.,217
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextRuntimeException,Long Statement,The length of the statement "StreamingResponseFactory streamingResponseFactory=new StreamingResponseFactory(mockedChunkedOutputFactory`DURATION`DURATION);" is 125.,217
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testHasNextRuntimeException,Magic Number,The method contains a magic number: 400,217
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 372.,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Long Statement,The length of the statement "ProduceResponse produceResponse=ProduceResponse.builder().setClusterId("clusterId").setTopicName("topicName").setPartitionId(1).setOffset(1L).setErrorCode(HttpStatus.OK_200).build();" is 182.,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Long Statement,The length of the statement "ResultOrError error=ResultOrError.error(ErrorResponse.create(408`"Streaming connection open for longer than allowed: Connection will be closed."));" is 147.,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Long Statement,The length of the statement "StreamingResponseFactory streamingResponseFactory=new StreamingResponseFactory(mockedChunkedOutputFactory`Duration.ofMillis(timeout)`Duration.ofMillis(50));" is 156.,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Long Statement,The length of the statement "StreamingResponse<ProduceRequest> streamingResponse=StreamingResponse.fromWithClock(new JsonStream<>(() -> requestsMappingIterator)`mockedChunkedOutputFactory`Duration.ofMillis(timeout)`Duration.ofMillis(50)`clock);" is 215.,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Magic Number,The method contains a magic number: 10,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Magic Number,The method contains a magic number: 408,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Magic Number,The method contains a magic number: 5,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Magic Number,The method contains a magic number: 500,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Magic Number,The method contains a magic number: 50,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,StreamingResponseTest,testWriteToChunkedOutputAfterTimeout,Magic Number,The method contains a magic number: 50,257
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,create_withHostNameAndPortConfig_returnsUrlRelativeToHostNameAndPortConfig,Magic Number,The method contains a magic number: 2000,36
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,create_withAdvertisedListenerSameScheme_returnsUrlRelativeToAdvertisedListenerSameScheme,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl(""`0`singletonList(URI.create("http://advertised.listener:2000"))`singletonList(URI.create("http://listener:3000"))`requestUriInfo);" is 173.,51
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,create_withAdvertisedListenerDifferentSchemeAndListenerSameScheme_returnsUrlRelativeToRequestUri,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl(""`0`singletonList(URI.create("https://advertised.listener:2000"))`singletonList(URI.create("http://listener:3000"))`requestUriInfo);" is 174.,72
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,create_withListenerSameScheme_returnsUrlRelativeToRequestUri,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl(""`0`emptyList()`singletonList(URI.create("http://listener:2000"))`requestUriInfo);" is 124.,93
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,create_withListenerDifferentScheme_returnsUrlRelativeToRequestUri,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl(""`0`emptyList()`singletonList(URI.create("https://listener:2000"))`requestUriInfo);" is 125.,113
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateHostAndAdvertisedListenerReturnsRelativeToAdvertisedListener,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl("hostname"`2000`singletonList(URI.create("http://advertised.listener:2000"))`emptyList()`requestUriInfo);" is 146.,173
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateHostAndAdvertisedListenerReturnsRelativeToAdvertisedListener,Magic Number,The method contains a magic number: 2000,173
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateHostAndListenerReturnsRelativeToListener,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl("hostname"`2000`emptyList()`singletonList(URI.create("http://listener:2000"))`requestUriInfo);" is 135.,193
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateHostAndListenerReturnsRelativeToListener,Magic Number,The method contains a magic number: 2000,193
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateAdvertisedListenerAndListenerReturnsRelativeToAdvertisedListener,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl(""`0`singletonList(URI.create("http://advertised.listener:2000"))`singletonList(URI.create("http://listener:2000"))`requestUriInfo);" is 173.,213
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateHostAdvertisedListenerAndListenerReturnsRelativeToAdvertisedListener,Long Statement,The length of the statement "UrlFactory urlFactory=new UrlFactoryImpl("hostname"`2000`singletonList(URI.create("http://advertised.listener:2000"))`singletonList(URI.create("http://listener:2000"))`requestUriInfo);" is 184.,233
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,testCreateHostAdvertisedListenerAndListenerReturnsRelativeToAdvertisedListener,Magic Number,The method contains a magic number: 2000,233
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,urlBuilder_urlEncodesQueryParamValues,Long Statement,The length of the statement "String url=urlBuilder.appendPathSegment("foobar").putQueryParameter("foo"`"b a r").putQueryParameter("foz"`"b!a@z").build();" is 124.,253
confluentinc_kafka-rest,io.confluent.kafkarest.response,UrlFactoryImplTest,urlBuilder_urlEncodesQueryParamValues,Magic Number,The method contains a magic number: 2000,253
confluentinc_kafka-rest,io.confluent.kafkarest.exceptions,RestConstraintViolationExceptionMapper,toResponse,Long Statement,The length of the statement "return Response.status(exception.getStatus()).entity(ErrorResponse.create(exception.getStatus()`String.format("Error: %s : %s"`exception.getErrorCode()`exception.getMessage()))).build();" is 186.,26
confluentinc_kafka-rest,io.confluent.kafkarest.exceptions,StatusCodeException,StatusCodeException,Long Parameter List,The method has 5 parameters. ,58
confluentinc_kafka-rest,io.confluent.kafkarest.exceptions,KafkaRestExceptionMapper,toResponse,Magic Number,The method contains a magic number: 40801,30
confluentinc_kafka-rest,io.confluent.kafkarest.exceptions.v2,V2ExceptionMapper,toResponse,Long Statement,The length of the statement "return Response.status(exception.getStatus()).entity(ErrorResponse.create(exception.getCode()`String.format("%s: %s"`exception.getTitle()`exception.getDetail()))).build();" is 171.,24
confluentinc_kafka-rest,io.confluent.kafkarest.exceptions.v3,V3ExceptionMapper,toResponse,Long Statement,The length of the statement "return Response.status(exception.getStatus()).entity(ErrorResponse.create(exception.getCode()`String.format("%s: %s"`exception.getTitle()`exception.getDetail()))).build();" is 171.,24
confluentinc_kafka-rest,io.confluent.kafkarest.v2,BinaryKafkaConsumerState,createConsumerRecord,Long Statement,The length of the statement "return new ConsumerRecordAndSize<>(io.confluent.kafkarest.entities.ConsumerRecord.create(record.topic()`record.key() != null ? ByteString.copyFrom(record.key()) : null`record.value() != null ? ByteString.copyFrom(record.value()) : null`record.partition()`record.offset())`approxSize);" is 284.,41
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Long Statement,The length of the statement "int maxThreadCount=config.getInt(CONSUMER_MAX_THREADS_CONFIG) < 0 ? Integer.MAX_VALUE : config.getInt(CONSUMER_MAX_THREADS_CONFIG);" is 131.,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Long Statement,The length of the statement "this.executor=new KafkaConsumerThreadPoolExecutor(0`maxThreadCount`60L`TimeUnit.SECONDS`new SynchronousQueue<Runnable>()`new RejectedExecutionHandler(){" is 152.,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Long Statement,The length of the statement "log.debug("The runnable {} was rejected execution because the thread pool is saturated." + " Delaying execution for {}ms."`r`retry.toMillis());" is 143.,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Long Statement,The length of the statement "log.debug("The runnable {} was rejected execution because the thread pool is saturated." + " Executing on calling thread."`r);" is 126.,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Magic Number,The method contains a magic number: 60L,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Magic Number,The method contains a magic number: 25,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,KafkaConsumerManager,Magic Number,The method contains a magic number: 76,110
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,rejectedExecution,Long Statement,The length of the statement "log.debug("The runnable {} was rejected execution because the thread pool is saturated." + " Delaying execution for {}ms."`r`retry.toMillis());" is 143.,127
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,rejectedExecution,Long Statement,The length of the statement "log.debug("The runnable {} was rejected execution because the thread pool is saturated." + " Executing on calling thread."`r);" is 126.,127
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,rejectedExecution,Magic Number,The method contains a magic number: 25,127
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,rejectedExecution,Magic Number,The method contains a magic number: 76,127
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,getConsumerInstanceProperties,Complex Method,Cyclomatic complexity of the method is 9,237
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,getConsumerInstanceProperties,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@606e9e31,237
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,createConsumerState,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@577cb132,295
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,readRecords,Long Parameter List,The method has 6 parameters. ,323
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,readRecords,Long Statement,The length of the statement "final KafkaConsumerReadTask<?`?`?`?> task=new KafkaConsumerReadTask<KafkaKeyT`KafkaValueT`ClientKeyT`ClientValueT>(state`timeout`maxBytes`callback`config);" is 155.,323
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManager,commitOffsets,Long Parameter List,The method has 5 parameters. ,470
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,commitOffsets,Long Statement,The length of the statement "offsetMap.put(new TopicPartition(t.getTopic()`t.getPartition())`new OffsetAndMetadata(t.getOffset() + 1`t.getMetadata()));" is 122.,107
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,seek,Long Statement,The length of the statement "consumer.seek(new TopicPartition(partition.getTopic()`partition.getPartition())`new OffsetAndMetadata(partition.getOffset()`partition.getMetadata().orElse("")));" is 161.,163
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,seek,Long Statement,The length of the statement "Map<TopicPartition`Optional<String>> metadata=request.getTimestamps().stream().collect(Collectors.toMap(partition -> new TopicPartition(partition.getTopic()`partition.getPartition())`ConsumerSeekRequest.PartitionTimestamp::getMetadata));" is 237.,163
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,seek,Long Statement,The length of the statement "Map<TopicPartition`OffsetAndTimestamp> offsets=consumer.offsetsForTimes(request.getTimestamps().stream().collect(Collectors.toMap(partition -> new TopicPartition(partition.getTopic()`partition.getPartition())`partition -> partition.getTimestamp().toEpochMilli())));" is 265.,163
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,seek,Long Statement,The length of the statement "consumer.seek(offset.getKey()`new OffsetAndMetadata(offset.getValue().offset()`metadata.get(offset.getKey()).orElse("")));" is 122.,163
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,committed,Long Statement,The length of the statement "offsets.add(new TopicPartitionOffsetMetadata(partition.topic()`partition.partition()`offsetMetadata.offset()`offsetMetadata.metadata()));" is 137.,263
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerState,getOffsetForTime,Long Statement,The length of the statement "Map<TopicPartition`OffsetAndTimestamp> response=consumer.offsetsForTimes(singletonMap(new TopicPartition(topic`partition)`timestamp.toEpochMilli()));" is 149.,320
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,KafkaConsumerReadTask,Long Parameter List,The method has 5 parameters. ,63
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,KafkaConsumerReadTask,Long Statement,The length of the statement "Duration defaultRequestTimeout=parent.getConsumerInstanceConfig().getRequestWaitMs() != null ? Duration.ofMillis(parent.getConsumerInstanceConfig().getRequestWaitMs()) : Duration.ofMillis(config.getInt(KafkaRestConfig.CONSUMER_REQUEST_TIMEOUT_MS_CONFIG));" is 255.,63
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,KafkaConsumerReadTask,Long Statement,The length of the statement "this.requestTimeout=timeout.isNegative() || timeout.isZero() ? defaultRequestTimeout : Collections.min(Arrays.asList(timeout`defaultRequestTimeout));" is 149.,63
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,KafkaConsumerReadTask,Long Statement,The length of the statement "int responseMinBytes=parent.getConsumerInstanceConfig().getResponseMinBytes() != null ? parent.getConsumerInstanceConfig().getResponseMinBytes() : config.getInt(KafkaRestConfig.PROXY_FETCH_MIN_BYTES_CONFIG);" is 207.,63
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,doPartialRead,Complex Conditional,The conditional expression requestTimedOut || exceededMaxResponseBytes || exceededMinResponseBytes is complex.,92
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,doPartialRead,Long Statement,The length of the statement "log.trace("KafkaConsumerReadTask exiting read with id={} messages={} bytes={}` backing off if not" + " complete"`this`messages.size()`bytesConsumed);" is 149.,92
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerReadTask,doPartialRead,Long Statement,The length of the statement "log.trace("Finishing KafkaConsumerReadTask id={} requestTimedOut={} " + "exceededMaxResponseBytes={} exceededMinResponseBytes={}"`this`requestTimedOut`exceededMaxResponseBytes`exceededMinResponseBytes);" is 202.,92
confluentinc_kafka-rest,io.confluent.kafkarest.v2,JsonKafkaConsumerState,createConsumerRecord,Long Statement,The length of the statement "return new ConsumerRecordAndSize<>(io.confluent.kafkarest.entities.ConsumerRecord.create(record.topic()`key`value`record.partition()`record.offset())`approxSize);" is 162.,39
confluentinc_kafka-rest,io.confluent.kafkarest.v2,SchemaKafkaConsumerState,SchemaKafkaConsumerState,Long Parameter List,The method has 5 parameters. ,36
confluentinc_kafka-rest,io.confluent.kafkarest.v2,SchemaKafkaConsumerState,createConsumerRecord,Long Statement,The length of the statement "return new ConsumerRecordAndSize<>(io.confluent.kafkarest.entities.ConsumerRecord.create(record.topic()`keyNode.getJson()`valueNode.getJson()`record.partition()`record.offset())`keyNode.getSize() + valueNode.getSize());" is 219.,46
confluentinc_kafka-rest,io.confluent.kafkarest.v2,LoadTest,testMultipleConsumerMultipleGroups,Complex Method,Cyclomatic complexity of the method is 8,196
confluentinc_kafka-rest,io.confluent.kafkarest.v2,LoadTest,testMultipleConsumerMultipleGroups,Magic Number,The method contains a magic number: 5,196
confluentinc_kafka-rest,io.confluent.kafkarest.v2,LoadTest,testMultipleConsumerMultipleGroups,Magic Number,The method contains a magic number: 10,196
confluentinc_kafka-rest,io.confluent.kafkarest.v2,LoadTest,testMultipleConsumerMultipleGroups,Magic Number,The method contains a magic number: 30,196
confluentinc_kafka-rest,io.confluent.kafkarest.v2,LoadTest,testMultipleConsumerMultipleGroups,Magic Number,The method contains a magic number: 5,196
confluentinc_kafka-rest,io.confluent.kafkarest.v2,LoadTest,bootstrapConsumer,Long Statement,The length of the statement "consumerManager.subscribe(consumer.groupName`cid`new ConsumerSubscriptionRecord(Collections.singletonList(topicName)`null));" is 124.,240
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_returnsBeginningAndEnd,Long Statement,The length of the statement "expect(partitionManager.getLocalPartition(TOPIC_NAME`PARTITION.getPartitionId())).andReturn(completedFuture(Optional.of(PARTITION)));" is 133.,98
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_returnsBeginningAndEnd,Long Statement,The length of the statement "String response=target("/topics/{topic}/partitions/{partition}/offsets").resolveTemplate("topic"`TOPIC_NAME).resolveTemplate("partition"`PARTITION.getPartitionId()).request().get(String.class);" is 193.,98
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_returnsBeginningAndEnd,Long Statement,The length of the statement "assertEquals(String.format("{\"beginning_offset\":%d`\"end_offset\":%d}"`PARTITION.getEarliestOffset()`PARTITION.getLatestOffset())`response);" is 142.,98
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_topicDoesNotExist_returns404,Long Statement,The length of the statement "expect(partitionManager.getLocalPartition(TOPIC_NAME`PARTITION.getPartitionId())).andReturn(failedFuture(new NotFoundException()));" is 131.,120
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_topicDoesNotExist_returns404,Long Statement,The length of the statement "Response response=target("/topics/{topic}/partitions/{partition}/offsets").resolveTemplate("topic"`TOPIC_NAME).resolveTemplate("partition"`PARTITION.getPartitionId()).request().get();" is 183.,120
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_partitionDoesNotExist_returns404,Long Statement,The length of the statement "expect(partitionManager.getLocalPartition(TOPIC_NAME`PARTITION.getPartitionId())).andReturn(completedFuture(Optional.empty()));" is 127.,138
confluentinc_kafka-rest,io.confluent.kafkarest.v2,PartitionsResourceTest,getOffsets_partitionDoesNotExist_returns404,Long Statement,The length of the statement "Response response=target("/topics/{topic}/partitions/{partition}/offsets").resolveTemplate("topic"`TOPIC_NAME).resolveTemplate("partition"`PARTITION.getPartitionId()).request().get();" is 183.,138
confluentinc_kafka-rest,io.confluent.kafkarest.v2,MockConsumer,updateOffsetForTime,Long Statement,The length of the statement "SortedSet<OffsetAndTimestamp> offsets=offsetForTimes.computeIfAbsent(new TopicPartition(topic`partition)`key -> new TreeSet<>(Comparator.comparing(OffsetAndTimestamp::timestamp)));" is 180.,50
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerRequestTimeoutms,Magic Number,The method contains a magic number: 0.5,179
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerRequestTimeoutms,Magic Number,The method contains a magic number: 0.7,179
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerWaitMs,Magic Number,The method contains a magic number: 400,201
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerWaitMs,Magic Number,The method contains a magic number: 40,201
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerWaitMs,Magic Number,The method contains a magic number: 0.5,201
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerRequestTimeoutmsAndMinBytes,Magic Number,The method contains a magic number: 100,232
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerRequestTimeoutmsAndMinBytes,Magic Number,The method contains a magic number: 200,232
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerRequestTimeoutmsAndMinBytes,Magic Number,The method contains a magic number: 2,232
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerMinAndMaxBytes,Long Statement,The length of the statement "final List<ConsumerRecord<ByteString`ByteString>> referenceRecords=Arrays.asList(scheduledRecords.get(0)`scheduledRecords.get(1)`scheduledRecords.get(2));" is 154.,276
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerMinAndMaxBytes,Magic Number,The method contains a magic number: 10,276
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerMinAndMaxBytes,Magic Number,The method contains a magic number: 2,276
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerMinAndMaxBytes,Magic Number,The method contains a magic number: 3,276
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerMinAndMaxBytes,Magic Number,The method contains a magic number: 0.5,276
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Long Statement,The length of the statement "final List<ConsumerRecord<ByteString`ByteString>> referenceRecords=Arrays.asList(scheduledRecords.get(0)`scheduledRecords.get(1)`scheduledRecords.get(2));" is 154.,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Long Statement,The length of the statement "ConsumerInstanceConfig config=ConsumerInstanceConfig.create(null`null`EmbeddedFormat.BINARY`null`null`sampleRecordSize * 2`null);" is 129.,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Magic Number,The method contains a magic number: 5,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Magic Number,The method contains a magic number: 6,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Magic Number,The method contains a magic number: 2,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Magic Number,The method contains a magic number: 3,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Magic Number,The method contains a magic number: 2,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumeMinBytesIsOverridablePerConsumer,Magic Number,The method contains a magic number: 0.5,317
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerNormalOps,Magic Number,The method contains a magic number: 1.10,364
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Long Statement,The length of the statement "consumerManager.readRecords(groupName`consumer.cid()`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`(records`e) -> latch.countDown());" is 155.,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Long Statement,The length of the statement "assertTrue(pollTimestampsMillis.size() >= 2`String.format("Expected at least 2 poll calls` but got %d instead."`pollTimestampsMillis.size()));" is 142.,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Long Statement,The length of the statement "assertTrue(smallWindowCount <= 2`String.format("Expected at most 2 poll calls in window [%d` %d]` but got %d instead."`pollTimestampsMillis.get(i)`lastTimestampMillis`smallWindowCount));" is 186.,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Long Statement,The length of the statement "assertTrue(pollTimestampsMillis.get(i + 1) - pollTimestampsMillis.get(i) <= 2 * backoffMillis`String.format("Expected at least 1 poll call in window (%d` %d)` but got none instead."`pollTimestampsMillis.get(i)`pollTimestampsMillis.get(i + 1)));" is 244.,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Long Statement,The length of the statement "assertTrue(timeoutTimestampMillis - lastTimestampMillis < 2 * backoffMillis`String.format("Expected at least 1 poll call in window (%d` %d]` but got none instead."`lastTimestampMillis`timeoutTimestampMillis));" is 209.,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Magic Number,The method contains a magic number: 5000L,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Magic Number,The method contains a magic number: 500L,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Magic Number,The method contains a magic number: 2,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Magic Number,The method contains a magic number: 2,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Magic Number,The method contains a magic number: 2,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsControlsPollCalls,Magic Number,The method contains a magic number: 2,412
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsUpdatesReadTaskExpiry,Long Statement,The length of the statement "consumerManager.readRecords(groupName`consumer.cid()`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`new ConsumerReadCallback<ByteString`ByteString>(){" is 171.,488
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsUpdatesReadTaskExpiry,Magic Number,The method contains a magic number: 100,488
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsUpdatesReadTaskExpiry,Magic Number,The method contains a magic number: 1000,488
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testBackoffMsUpdatesReadTaskExpiry,Magic Number,The method contains a magic number: 700,488
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerExpirationIsUpdated,Long Statement,The length of the statement "consumerManager.readRecords(groupName`consumer.cid()`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`new ConsumerReadCallback<ByteString`ByteString>(){" is 171.,522
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testConsumerExpirationIsUpdated,Magic Number,The method contains a magic number: 100,522
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,awaitRead,Magic Number,The method contains a magic number: 1.10,569
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Long Statement,The length of the statement "EasyMock.expect(consumerFactory.createConsumer(EasyMock.capture(capturedConsumerConfig))).andReturn(consumer1).andReturn(consumer2).andReturn(consumer3);" is 153.,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Long Statement,The length of the statement "consumerManager.readRecords("a"`consumer1.cid()`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`callback);" is 126.,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Long Statement,The length of the statement "consumerManager.readRecords("a"`consumer2.cid()`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`callback);" is 126.,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Long Statement,The length of the statement "consumerManager.readRecords("c"`consumer3.cid()`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`callback);" is 126.,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Magic Number,The method contains a magic number: 10000,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Magic Number,The method contains a magic number: 20,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Magic Number,The method contains a magic number: 75,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Magic Number,The method contains a magic number: 2,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Magic Number,The method contains a magic number: 20,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,testReadRecordsPopulatesDelayedReadTaskWhenExecutorFull,Magic Number,The method contains a magic number: 75,574
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,bootstrapConsumer,Long Statement,The length of the statement "consumerManager.subscribe(consumer.groupName`cid`new ConsumerSubscriptionRecord(Collections.singletonList(topicName)`null));" is 124.,647
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,bootstrapConsumer,Long Statement,The length of the statement "List<ConsumerRecord<ByteString`ByteString>> referenceRecords=Arrays.asList(ConsumerRecord.create(topicName`ByteString.copyFromUtf8("k1")`ByteString.copyFromUtf8("v1")`0`0)`ConsumerRecord.create(topicName`ByteString.copyFromUtf8("k2")`ByteString.copyFromUtf8("v2")`0`1)`ConsumerRecord.create(topicName`ByteString.copyFromUtf8("k3")`ByteString.copyFromUtf8("v3")`0`2));" is 367.,647
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,bootstrapConsumer,Long Statement,The length of the statement "consumer.addRecord(new org.apache.kafka.clients.consumer.ConsumerRecord<>(record.getTopic()`record.getPartition()`record.getOffset()`record.getKey().toByteArray()`record.getValue().toByteArray()));" is 197.,647
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,bootstrapConsumer,Magic Number,The method contains a magic number: 2,647
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,readFromDefault,Long Statement,The length of the statement "consumerManager.readRecords(groupName`cid`BinaryKafkaConsumerState.class`Duration.ofMillis(-1)`Long.MAX_VALUE`new ConsumerReadCallback<ByteString`ByteString>(){" is 160.,688
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,schedulePoll,Long Statement,The length of the statement "return Arrays.asList(binaryConsumerRecord(fromOffset)`binaryConsumerRecord(fromOffset + 1)`binaryConsumerRecord(fromOffset + 2));" is 129.,710
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,schedulePoll,Magic Number,The method contains a magic number: 2,710
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,schedulePoll,Magic Number,The method contains a magic number: 2,710
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,run,Magic Number,The method contains a magic number: 2,713
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,binaryConsumerRecord,Long Statement,The length of the statement "return ConsumerRecord.create(topicName`ByteString.copyFromUtf8(String.format("k%d"`offset))`ByteString.copyFromUtf8(String.format("v%d"`offset))`0`offset);" is 155.,726
confluentinc_kafka-rest,io.confluent.kafkarest.v2,KafkaConsumerManagerTest,record,Long Statement,The length of the statement "return new org.apache.kafka.clients.consumer.ConsumerRecord<>(topicName`0`offset`String.format("k%d"`offset).getBytes()`String.format("v%d"`offset).getBytes());" is 160.,735
confluentinc_kafka-rest,io.confluent.kafkarest.extension,ResourceAccesslistFeature,configure,Long Statement,The length of the statement "boolean blocked=isBlockedByAccesslist(resourceInfo`apiEndpointsAllowlistConfig`true) || isBlockedByAccesslist(resourceInfo`apiEndpointsBlocklistConfig`false);" is 158.,73
confluentinc_kafka-rest,io.confluent.kafkarest.extension,ResourceAccesslistFeature,isOptionsProcessor,Long Statement,The length of the statement "return resourceInfo.getResourceClass() != null && resourceInfo.getResourceClass().getEnclosingClass() != null && resourceInfo.getResourceClass().getEnclosingClass().equals(OptionsMethodProcessor.class);" is 202.,91
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProvider,getConverter,Long Statement,The length of the statement "List<Method> jsonValueMethods=Arrays.stream(rawType.getMethods()).filter(method -> method.getAnnotation(JsonValue.class) != null).collect(Collectors.toList());" is 159.,39
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProvider,getConverter,Long Statement,The length of the statement "throw new RuntimeException(String.format("@JsonValue annotated method in %s does not return String."`rawType.getName()));" is 121.,39
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProviderTest,enumWithNoJsonValueMatchesConstantName,Long Statement,The length of the statement "ParamConverter<EnumWithNoJsonValue> converter=converterProvider.getConverter(EnumWithNoJsonValue.class`EnumWithNoJsonValue.class`new Annotation[0]);" is 148.,32
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProviderTest,enumWithSingleJsonValueMatchesOnJsonValue,Long Statement,The length of the statement "ParamConverter<EnumWithSingleJsonValue> converter=converterProvider.getConverter(EnumWithSingleJsonValue.class`EnumWithSingleJsonValue.class`new Annotation[0]);" is 160.,43
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProviderTest,enumWithMultipleJsonValueThrowsException,Long Statement,The length of the statement "assertThrows(RuntimeException.class`() -> converterProvider.getConverter(EnumWithMultipleJsonValue.class`EnumWithMultipleJsonValue.class`new Annotation[0]));" is 157.,54
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProviderTest,enumWithPrivateJsonValueThrowsException,Long Statement,The length of the statement "assertThrows(RuntimeException.class`() -> converterProvider.getConverter(EnumWithPrivateJsonValue.class`EnumWithPrivateJsonValue.class`new Annotation[0]));" is 155.,66
confluentinc_kafka-rest,io.confluent.kafkarest.extension,EnumConverterProviderTest,enumWithNonStringJsonValueThrowsException,Long Statement,The length of the statement "assertThrows(RuntimeException.class`() -> converterProvider.getConverter(EnumWithNonStringJsonValue.class`EnumWithNonStringJsonValue.class`new Annotation[0]));" is 159.,76
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SchemaRegistryFixture,SchemaRegistryFixture,Long Parameter List,The method has 7 parameters. ,63
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SchemaRegistryFixture,beforeEach,Long Statement,The length of the statement "client=new CachedSchemaRegistryClient(singletonList(baseUri.toString())`MAX_SCHEMAS_PER_SUBJECT_DEFAULT`Arrays.asList(new AvroSchemaProvider()`new JsonSchemaProvider()`new ProtobufSchemaProvider())`getClientConfigs());" is 218.,82
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SchemaRegistryFixture,createConfigs,Long Statement,The length of the statement "properties.put(SchemaRegistryConfig.LISTENERS_CONFIG`String.format("%s://localhost:0"`certificates != null ? "https" : "http"));" is 128.,97
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SchemaRegistryFixture,getKafkaConfigs,Long Statement,The length of the statement "properties.put("kafkastore.sasl.jaas.config"`String.format("org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"%s\" " + "password=\"%s\";"`kafkaUser`kafkaPassword));" is 195.,113
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SchemaRegistryFixture,afterEach,Empty catch clause,The method has an empty catch block.,146
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SslFixture,beforeEach,Long Statement,The length of the statement "TestSslUtils.createTrustStore(trustStoreLocation.toString()`new Password(trustStorePassword)`keys.entrySet().stream().collect(Collectors.toMap(Entry::getKey`entry -> entry.getValue().getCertificate())));" is 203.,62
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SslFixture,generateKeys,Long Statement,The length of the statement "TestSslUtils.createKeyStore(keyStoreLocation.toString()`new Password(keyStorePassword)`new Password(keyPassword)`keyName`keyPair.getPrivate()`certificate);" is 155.,74
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SslFixture,generateKeys,Magic Number,The method contains a magic number: 30,74
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SslFixture,afterEach,Empty catch clause,The method has an empty catch block.,96
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SslFixture,afterEach,Empty catch clause,The method has an empty catch block.,96
confluentinc_kafka-rest,io.confluent.kafkarest.testing,SslFixture,getSslContext,Long Statement,The length of the statement "SslConfigurator sslConfig=SslConfigurator.newInstance().securityProtocol(SSL_PROTOCOL).keyStoreFile(key.getKeyStoreLocation().toString()).keyStoreType(KEY_STORE_TYPE).keyStorePassword(key.getKeyStorePassword()).keyManagerFactoryAlgorithm(KEY_MANAGER_ALGORITHM).keyPassword(key.getKeyPassword()).trustStoreFile(getTrustStoreLocation().toString()).trustStoreType(TRUST_STORE_TYPE).trustStorePassword(getTrustStorePassword()).trustManagerFactoryAlgorithm(TRUST_MANAGER_ALGORITHM);" is 477.,155
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaRestFixture,KafkaRestFixture,Long Parameter List,The method has 7 parameters. ,53
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaRestFixture,getKafkaConfigs,Long Statement,The length of the statement "properties.put("client.sasl.jaas.config"`String.format("org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"%s\" " + "password=\"%s\";"`kafkaUser`kafkaPassword));" is 191.,95
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaRestFixture,afterEach,Empty catch clause,The method has an empty catch block.,130
confluentinc_kafka-rest,io.confluent.kafkarest.testing,JvmPropertyFileLoginModuleFixture,beforeEach,Long Statement,The length of the statement "Files.write(jaasConfig`ImmutableList.of(name + " {"`" org.eclipse.jetty.jaas.spi.PropertyFileLoginModule required"`" file=\"" + passConfig + "\""`" debug=\"true\";"`"};"));" is 172.,62
confluentinc_kafka-rest,io.confluent.kafkarest.testing,JvmPropertyFileLoginModuleFixture,beforeEach,Long Statement,The length of the statement "Files.write(passConfig`users.entrySet().stream().map(entry -> entry.getKey() + ": " + entry.getValue().toString()).collect(Collectors.toList()));" is 145.,62
confluentinc_kafka-rest,io.confluent.kafkarest.testing,JvmPropertyFileLoginModuleFixture,afterEach,Empty catch clause,The method has an empty catch block.,83
confluentinc_kafka-rest,io.confluent.kafkarest.testing,JvmPropertyFileLoginModuleFixture,afterEach,Empty catch clause,The method has an empty catch block.,83
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaBrokerFixture,KafkaBrokerFixture,Long Parameter List,The method has 8 parameters. ,76
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaBrokerFixture,getBrokerSecurityConfigs,Long Statement,The length of the statement "properties.setProperty(KafkaConfig.ListenerSecurityProtocolMapProp()`String.format("EXTERNAL:%s`INTERNAL:%s"`securityProtocol`securityProtocol));" is 145.,116
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaBrokerFixture,getBrokerPlainSaslJaasConfig,Long Statement,The length of the statement "String userEntries=users.entrySet().stream().map(entry -> String.format("user_%s=\"%s\""`entry.getKey()`entry.getValue())).collect(Collectors.joining(" "));" is 156.,134
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaBrokerFixture,getBrokerPlainSaslJaasConfig,Long Statement,The length of the statement "return "org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"kafka\" " + "password=\"kafka-pass\" " + userEntries + ";";" is 148.,134
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaBrokerFixture,afterEach,Empty catch clause,The method has an empty catch block.,170
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaBrokerFixture,getClientSaslJaasConfig,Long Statement,The length of the statement "return "org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"kafka\" " + "password=\"kafka-pass\";";" is 128.,211
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaClusterFixture,getRecord,Long Parameter List,The method has 5 parameters. ,146
confluentinc_kafka-rest,io.confluent.kafkarest.testing,KafkaClusterFixture,getRecord,Long Statement,The length of the statement "List<ConsumerRecord<K`V>> records=consumer.poll(Duration.ofSeconds(1)).records(new TopicPartition(topicName`partitionId));" is 122.,146
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,createConsumerInstance,Complex Conditional,The conditional expression id != null || name != null || format != null is complex.,69
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,createConsumerInstance,Long Parameter List,The method has 5 parameters. ,69
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,createConsumerInstance,Long Statement,The length of the statement "config=new CreateConsumerInstanceRequest(id`name`format != null ? format.toString() : null`autoOffsetReset`null`null`null);" is 123.,69
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,startConsumeMessages,Long Parameter List,The method has 5 parameters. ,95
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,startConsumeMessages,Long Parameter List,The method has 5 parameters. ,116
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,startConsumeMessages,Long Statement,The length of the statement "CreateConsumerInstanceResponse instanceResponse=TestUtils.tryReadEntityOrLog(createResponse`CreateConsumerInstanceResponse.class);" is 130.,116
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,startConsumeMessages,Long Statement,The length of the statement "assertTrue(instanceResponse.getBaseUri().contains(instanceResponse.getInstanceId())`"Base URI should contain the consumer instance ID");" is 136.,116
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,startConsumeMessages,Long Statement,The length of the statement "Response subscribeResponse=request(instanceResponse.getBaseUri() + "/subscription").accept(Versions.KAFKA_V2_JSON).post(Entity.entity(subscribeRequest`Versions.KAFKA_V2_JSON));" is 176.,116
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,consumeMessages,Long Parameter List,The method has 7 parameters. ,216
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,pause,Empty catch clause,The method has an empty catch block.,266
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,consumeForTimeout,Long Statement,The length of the statement "final long timeoutSlack=restConfig.getInt(KafkaRestConfig.CONSUMER_ITERATOR_BACKOFF_MS_CONFIG) + restConfig.getInt(KafkaRestConfig.CONSUMER_ITERATOR_TIMEOUT_MS_CONFIG) + ONE_SECOND_MS;" is 184.,274
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,consumeForTimeout,Long Statement,The length of the statement "assertTrue((elapsed - timeout) < timeoutSlack`"Consumer request should timeout approximately within the request timeout period");" is 129.,274
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,seekToTimestamp,Long Statement,The length of the statement "Response response=request(instanceUri + "/positions").post(Entity.entity(String.format("{\"timestamps\":" + "[{\"topic\": \"%s\"` \"partition\": %d` \"timestamp\": \"%s\"}]}"`topicName`partitionId`DateTimeFormatter.ISO_INSTANT.format(timestamp))`Versions.KAFKA_V2_JSON));" is 271.,306
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractConsumerTest,consumeForNotFoundError,Long Statement,The length of the statement "assertErrorResponse(Response.Status.NOT_FOUND`response`Errors.CONSUMER_INSTANCE_NOT_FOUND_ERROR_CODE`Errors.CONSUMER_INSTANCE_NOT_FOUND_MESSAGE`Versions.KAFKA_V2_JSON_BINARY);" is 175.,332
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerAvroTest,setUp,Magic Number,The method contains a magic number: 3,78
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerAvroTest,testConsumeOnlyValues,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsOnlyValues`Versions.KAFKA_V2_JSON_AVRO`Versions.KAFKA_V2_JSON_AVRO`avroConsumerRecordType`converter`SchemaConsumerRecord::toConsumerRecord);" is 175.,87
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerAvroTest,testConsumeWithKeys,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_AVRO`Versions.KAFKA_V2_JSON_AVRO`avroConsumerRecordType`converter`SchemaConsumerRecord::toConsumerRecord);" is 173.,104
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerAvroTest,testConsumeTimeout,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_AVRO`Versions.KAFKA_V2_JSON_AVRO`avroConsumerRecordType`converter`SchemaConsumerRecord::toConsumerRecord);" is 173.,121
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerAvroTest,testDeleteConsumer,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_AVRO`Versions.KAFKA_V2_JSON_AVRO`avroConsumerRecordType`converter`SchemaConsumerRecord::toConsumerRecord);" is 173.,142
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,setUp,Magic Number,The method contains a magic number: 3,109
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToTopic,Long Statement,The length of the statement "TestUtils.assertTopicContains(plaintextBrokerList`topicName`payload.toProduceRequest().getRecords()`null`KafkaAvroDeserializer.class.getName()`KafkaAvroDeserializer.class.getName()`deserializerProps`false);" is 206.,126
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToTopic,Magic Number,The method contains a magic number: 2,126
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToTopicWithPartitionsAndKeys,Long Identifier,The length of the field topicRecordsWithPartitionsAndKeys is 33.,157
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToTopicWithPartitionsAndKeys,Long Identifier,The length of the field partitionOffsetsWithPartitionsAndKeys is 37.,157
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToPartition,Long Statement,The length of the statement "Response response=request("/topics/" + topicName + "/partitions/0"`queryParams).post(Entity.entity(payload`Versions.KAFKA_V2_JSON_AVRO));" is 137.,167
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToPartition,Long Statement,The length of the statement "TestUtils.assertTopicContains(plaintextBrokerList`topicName`payload.toProduceRequest().getRecords()`0`KafkaAvroDeserializer.class.getName()`KafkaAvroDeserializer.class.getName()`deserializerProps`false);" is 203.,167
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AvroProducerTest,testProduceToPartitionOnlyValues,Long Identifier,The length of the field producePartitionOffsetOnlyValues is 32.,197
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonParsingErrorTest,unparseableRequestReturnsBadRequest,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("foobar"`MediaType.APPLICATION_JSON));" is 159.,32
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonParsingErrorTest,invalidRequestReturnsBadRequest,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{}"`MediaType.APPLICATION_JSON));" is 155.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,exampleMapValue,Magic Number,The method contains a magic number: 53.4,36
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,exampleMapValue,Magic Number,The method contains a magic number: 45,36
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,exampleListValue,Magic Number,The method contains a magic number: 53.4,45
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,exampleListValue,Magic Number,The method contains a magic number: 45,45
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,setUp,Magic Number,The method contains a magic number: 3,75
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,testConsumeWithKeys,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_JSON`Versions.KAFKA_V2_JSON_JSON`jsonConsumerRecordType`null`JsonConsumerRecord::toConsumerRecord);" is 166.,84
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerJsonTest,testConsumeOnlyValues,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsOnlyValues`Versions.KAFKA_V2_JSON_JSON`Versions.KAFKA_V2_JSON_JSON`jsonConsumerRecordType`null`JsonConsumerRecord::toConsumerRecord);" is 168.,101
confluentinc_kafka-rest,io.confluent.kafkarest.integration,KafkaModuleOverridingTest,adminIsCreatedPerRequestAndDisposedAfterRequest,Long Statement,The length of the statement "Response response=kafkaRest.target().path("/v3/clusters").request().header("X-Teapot-Context"`"").accept(MediaType.APPLICATION_JSON).get();" is 139.,79
confluentinc_kafka-rest,io.confluent.kafkarest.integration,KafkaModuleOverridingTest,producerIsCreatedPerRequestAndDisposedAfterRequest,Long Statement,The length of the statement "Response response=kafkaRest.target().path("/v3/clusters/foo/topics/bar/records").request().header("X-Teapot-Context"`"").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{}"`MediaType.APPLICATION_JSON_TYPE));" is 214.,92
confluentinc_kafka-rest,io.confluent.kafkarest.integration,KafkaModuleOverridingTest,consumersResourceIsInitializedCorrectly,Long Statement,The length of the statement "Response response=kafkaRest.target().path("/consumers/bar").request().header("X-Teapot-Context"`"").accept(Versions.KAFKA_V2_JSON).post(Entity.entity(CreateConsumerInstanceRequest.PROTOTYPE`Versions.KAFKA_V2_JSON));" is 215.,107
confluentinc_kafka-rest,io.confluent.kafkarest.integration,KafkaRestStartUpIntegrationTest,KafkaRestStartUpIntegrationTest,Magic Number,The method contains a magic number: 3,28
confluentinc_kafka-rest,io.confluent.kafkarest.integration,MetadataApiTest,MetadataApiTest,Magic Number,The method contains a magic number: 2,87
confluentinc_kafka-rest,io.confluent.kafkarest.integration,MetadataApiTest,testTopicsList,Long Statement,The length of the statement "assertErrorResponse(Response.Status.NOT_FOUND`invalidResponse`KafkaExceptionMapper.KAFKA_UNKNOWN_TOPIC_PARTITION_CODE`null`Versions.KAFKA_V2_JSON);" is 147.,126
confluentinc_kafka-rest,io.confluent.kafkarest.integration,MetadataApiTest,testPartitionsList,Long Statement,The length of the statement "assertErrorResponse(Response.Status.NOT_FOUND`invalidResponse`Errors.PARTITION_NOT_FOUND_ERROR_CODE`Errors.PARTITION_NOT_FOUND_MESSAGE`Versions.KAFKA_V2_JSON);" is 159.,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration,MetadataApiTest,testPartitionsList,Magic Number,The method contains a magic number: 2,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration,MetadataApiTest,testPartitionsList,Magic Number,The method contains a magic number: 2,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration,MetadataApiTest,testPartitionsList,Magic Number,The method contains a magic number: 2,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTopicAutoCreationTest,testProduceToMissingTopic,Long Statement,The length of the statement "testProduceToTopic(topicName`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`partitionOffsets`false`request.toProduceRequest().getRecords());" is 177.,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,setUp,Magic Number,The method contains a magic number: 3,105
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToTopicWithKeys,Long Statement,The length of the statement "testProduceToTopic(topicName`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`produceOffsets`false`request.toProduceRequest().getRecords());" is 175.,114
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToTopicWithPartitions,Long Statement,The length of the statement "testProduceToTopic(topicName`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`producePartitionedOffsets`true`request.toProduceRequest().getRecords());" is 185.,127
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToTopicWithPartitionsAndKeys,Long Identifier,The length of the field topicRecordsWithPartitionsAndKeys is 33.,141
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToTopicWithPartitionsAndKeys,Long Statement,The length of the statement "testProduceToTopic(topicName`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`producePartitionedOffsets`true`request.toProduceRequest().getRecords());" is 185.,141
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToTopicWithNullValues,Long Statement,The length of the statement "testProduceToTopic(topicName`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`produceOffsets`false`request.toProduceRequest().getRecords());" is 175.,155
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToPartition,Long Statement,The length of the statement "testProduceToPartition(topicName`0`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`offsetResponse`request.toProduceRequest().getRecords());" is 175.,178
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testProduceToPartitionWithNullValues,Long Identifier,The length of the field partitionRecordsWithNullValues is 30.,201
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testNullPayload,Long Statement,The length of the statement "List<String> versions=Arrays.asList(Versions.KAFKA_V2_JSON_AVRO`Versions.KAFKA_V2_JSON_JSON`Versions.KAFKA_V2_JSON_BINARY);" is 123.,206
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testNullPayload,Magic Number,The method contains a magic number: 422,206
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerTest,testNullPayload,Magic Number,The method contains a magic number: 422,206
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerTimeoutTest,setUp,Magic Number,The method contains a magic number: 3,41
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerTimeoutTest,testConsumerTimeout,Long Statement,The length of the statement "String instanceUri=startConsumeMessages(groupName`topicName`EmbeddedFormat.BINARY`Versions.KAFKA_V2_JSON_BINARY`"earliest");" is 124.,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerTimeoutTest,testConsumerTimeout,Long Statement,The length of the statement "consumeForTimeout(instanceUri`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`new GenericType<List<BinaryConsumerRecord>>(){" is 136.,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerTimeoutTest,testConsumerTimeout,Long Statement,The length of the statement "consumeForTimeout(instanceUri`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`new GenericType<List<BinaryConsumerRecord>>(){" is 136.,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToTopic,Long Parameter List,The method has 7 parameters. ,36
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToTopic,Long Statement,The length of the statement "testProduceToTopic(topicName`request`keyDeserializerClassName`valueDeserializerClassName`offsetResponses`matchPartitions`Collections.emptyMap()`expected);" is 154.,36
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToTopic,Long Parameter List,The method has 8 parameters. ,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToTopic,Long Statement,The length of the statement "TestUtils.assertTopicContains(plaintextBrokerList`topicName`expected`null`keyDeserializerClassName`valueDeserializerClassName`true);" is 132.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToPartition,Long Parameter List,The method has 7 parameters. ,84
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToPartition,Long Statement,The length of the statement "testProduceToPartition(topicName`partition`request`keySerializerClassName`valueSerializerClassName`offsetResponse`Collections.emptyMap()`expected);" is 147.,84
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToPartition,Long Parameter List,The method has 8 parameters. ,103
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToPartition,Long Statement,The length of the statement "Response response=request("/topics/" + topicName + "/partitions/0"`queryParams).post(Entity.entity(request`getEmbeddedContentType()));" is 134.,103
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToPartition,Long Statement,The length of the statement "TestUtils.assertTopicContains(plaintextBrokerList`topicName`expected`partition`keySerializerClassName`valueSerializerClassName`true);" is 133.,103
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AbstractProducerTest,testProduceToTopicFails,Long Statement,The length of the statement "Response response=request("/topics/" + topicName`queryParams).post(Entity.entity(request`Versions.KAFKA_V2_JSON_BINARY));" is 121.,133
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SchemaRegistrySaslInheritTest,setUp,Magic Number,The method contains a magic number: 3,97
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SchemaRegistrySaslInheritTest,produceAvroWithRawSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 372.,102
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SchemaRegistrySaslInheritTest,produceAvroWithRawSchema,Long Statement,The length of the statement "Response response=kafkaRest.target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 209.,102
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SchemaRegistrySaslInheritTest,produceAvroWithRawSchema,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=kafkaCluster.getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`schemaRegistry.createAvroDeserializer()`schemaRegistry.createAvroDeserializer());" is 197.,102
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerLeakTest,setUp,Magic Number,The method contains a magic number: 3,72
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerLeakTest,producerDoesNotLeak,Long Statement,The length of the statement "Response response=kafkaRest.target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.json(new byte[1]));" is 184.,77
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerLeakTest,producerDoesNotLeak,Long Statement,The length of the statement "List<String> aliveClients=Thread.getAllStackTraces().keySet().stream().map(Thread::getName).filter(name -> name.contains("proxy")).collect(Collectors.toList());" is 160.,77
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ProducerLeakTest,producerDoesNotLeak,Long Statement,The length of the statement "assertEquals(0`aliveClients.size()`"Expected no live Kafka client threads` but some got left behind instead: " + aliveClients);" is 127.,77
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,setupMethod,Long Statement,The length of the statement "plaintextBrokerList=TestUtils.getBrokerListStrFromServers(JavaConverters.asScalaBuffer(servers)`SecurityProtocol.PLAINTEXT);" is 124.,184
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,setupMethod,Long Statement,The length of the statement "String broker=SecurityProtocol.PLAINTEXT.name + "://" + TestUtils.getBrokerListStrFromServers(JavaConverters.asScalaBuffer(servers)`SecurityProtocol.PLAINTEXT);" is 160.,184
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,startBrokersConcurrently,Long Statement,The length of the statement "configs=IntStream.range(0`numBrokers).mapToObj(brokerId -> KafkaConfig.fromProps(overrideBrokerProperties(brokerId`getBrokerProperties(brokerId)))).collect(toList());" is 166.,274
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,startBrokersConcurrently,Long Statement,The length of the statement "servers=CompletableFutures.allAsList(configs.stream().map(config -> CompletableFuture.supplyAsync(() -> TestUtils.createServer(config`new MockTime(System.currentTimeMillis()`System.nanoTime())))).collect(toList())).join();" is 222.,274
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,getBrokerProperties,Long Statement,The length of the statement "Properties props=TestUtils.createBrokerConfig(i`zkConnect`false`false`TestUtils.RandomPort()`noInterBrokerSecurityProtocol`noFile`Option.<Properties>empty()`true`false`TestUtils.RandomPort()`false`TestUtils.RandomPort()`false`TestUtils.RandomPort()`Option.<String>empty()`1`false`1`(short)1);" is 292.,311
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,request,Empty catch clause,The method has an empty catch block.,389
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,createTopic,Long Parameter List,The method has 5 parameters. ,487
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,createTopic,Long Statement,The length of the statement "else if (!topicNames.stream().filter(returnedTopicName -> topicName.equals(returnedTopicName)).findFirst().isPresent()) {" is 121.,487
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,createTopic,Long Statement,The length of the statement "if (!getTopicNames().stream().filter(returnedTopicName -> topicName.equals(returnedTopicName)).findFirst().isPresent()) {" is 121.,487
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,createTopic,Long Statement,The length of the statement "createTopic(topicName`Optional.empty()`Optional.empty()`Optional.of(replicasAssignments)`restConfig.getAdminProperties());" is 122.,548
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,createTopicCall,Long Parameter List,The method has 5 parameters. ,558
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,pause,Empty catch clause,The method has an empty catch block.,576
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ClusterTestHarness,setTopicConfig,Long Statement,The length of the statement "AlterConfigsResult result=adminClient.incrementalAlterConfigs(singletonMap(new ConfigResource(ConfigResource.Type.TOPIC`topicName)`singletonList(new AlterConfigOp(new ConfigEntry(configName`value)`AlterConfigOp.OpType.SET))));" is 226.,592
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,getBrokerProperties,Long Statement,The length of the statement "Properties brokerProps=kafka.utils.TestUtils.createBrokerConfig(0`""`false`false`kafka.utils.TestUtils.RandomPort()`securityProtocolOption`Option.empty()`saslProperties`true`true`kafka.utils.TestUtils.RandomPort()`false`kafka.utils.TestUtils.RandomPort()`false`kafka.utils.TestUtils.RandomPort()`Option.empty()`1`false`1`(short)1);" is 331.,80
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,getBrokerProperties,Long Statement,The length of the statement "brokerProps.setProperty("listener.name.sasl_plaintext.plain.sasl.jaas.config"`"org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"admin\" " + "password=\"admin-secret\" "+ "user_admin=\"admin-secret\" "+ "user_alice=\"alice-secret\"; ");" is 267.,80
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,createPlainLoginModule,Long Statement,The length of the statement "return "org.apache.kafka.common.security.plain.PlainLoginModule required " + " username=\"" + username + "\""+ " password=\""+ password+ "\";";" is 143.,132
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,testProducerAuthorization,Long Statement,The length of the statement "testProduceToTopic(TOPIC_NAME`request`ByteArrayDeserializer.class.getName()`ByteArrayDeserializer.class.getName()`produceOffsets`false`request.toProduceRequest().getRecords());" is 176.,151
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,verifySubscribeToTopic,Long Statement,The length of the statement "CreateConsumerInstanceResponse instanceResponse=TestUtils.tryReadEntityOrLog(createResponse`CreateConsumerInstanceResponse.class);" is 130.,168
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,verifySubscribeToTopic,Long Statement,The length of the statement "assertTrue(instanceResponse.getBaseUri().contains(instanceResponse.getInstanceId())`"Base URI should contain the consumer instance ID");" is 136.,168
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,verifySubscribeToTopic,Long Statement,The length of the statement "Response subscribe=request(instanceResponse.getBaseUri() + "/subscription").post(Entity.entity(topicJson`Versions.KAFKA_V2_JSON));" is 130.,168
confluentinc_kafka-rest,io.confluent.kafkarest.integration,AuthorizationErrorTest,verifySubscribeToTopic,Long Statement,The length of the statement "assertErrorResponse(Response.Status.FORBIDDEN`response`Errors.KAFKA_AUTHORIZATION_ERROR_CODE`"Not authorized to access topics"`Versions.KAFKA_V2_JSON_BINARY);" is 158.,168
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,setUp,Magic Number,The method contains a magic number: 3,57
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeOnlyValues,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsOnlyValues`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`binaryConsumerRecordType`null`BinaryConsumerRecord::toConsumerRecord);" is 176.,66
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeWithKeys,Long Statement,The length of the statement "String instanceUri=startConsumeMessages(groupName`topicName`EmbeddedFormat.BINARY`Versions.KAFKA_V2_JSON_BINARY`"earliest");" is 124.,85
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeWithKeys,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`binaryConsumerRecordType`null`BinaryConsumerRecord::toConsumerRecord);" is 174.,85
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeWithAcceptAllHeader,Long Statement,The length of the statement "String instanceUri=startConsumeMessages(groupName`topicName`EmbeddedFormat.BINARY`Versions.KAFKA_V2_JSON_BINARY`"earliest");" is 124.,102
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeWithAcceptAllHeader,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.ANYTHING`Versions.KAFKA_V2_JSON_BINARY`binaryConsumerRecordType`null`BinaryConsumerRecord::toConsumerRecord);" is 162.,102
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeTimeout,Long Statement,The length of the statement "String instanceUri=startConsumeMessages(groupName`topicName`EmbeddedFormat.BINARY`Versions.KAFKA_V2_JSON_BINARY`"earliest");" is 124.,120
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testConsumeTimeout,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`binaryConsumerRecordType`null`BinaryConsumerRecord::toConsumerRecord);" is 174.,120
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testDeleteConsumer,Long Statement,The length of the statement "consumeMessages(instanceUri`recordsWithKeys`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`binaryConsumerRecordType`null`BinaryConsumerRecord::toConsumerRecord);" is 174.,141
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testInvalidKafkaConsumerConfig,Long Statement,The length of the statement "CreateConsumerInstanceRequest config=new CreateConsumerInstanceRequest("id"`"name"`"binary"`"bad-config"`null`null`null);" is 121.,159
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testInvalidKafkaConsumerConfig,Long Statement,The length of the statement "assertErrorResponse(ConstraintViolationExceptionMapper.UNPROCESSABLE_ENTITY`response`Errors.INVALID_CONSUMER_CONFIG_ERROR_CODE`Errors.INVALID_CONSUMER_CONFIG_MESSAGE`Versions.KAFKA_V2_JSON);" is 190.,159
confluentinc_kafka-rest,io.confluent.kafkarest.integration,ConsumerBinaryTest,testDuplicateConsumerID,Long Statement,The length of the statement "assertErrorResponse(Response.Status.CONFLICT`createResponse`Errors.CONSUMER_ALREADY_EXISTS_ERROR_CODE`Errors.CONSUMER_ALREADY_EXISTS_MESSAGE`Versions.KAFKA_V2_JSON);" is 165.,180
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SecureTestUtils,setProduceAcls,Long Statement,The length of the statement "Collections.addAll(aclArgs`("--authorizer kafka.security.authorizer.AclAuthorizer " + "--authorizer-properties zookeeper.connect=" + zkConnect + " --topic "+ topic+ " --add --producer "+ " --allow-principal ").split("\\s+"));" is 225.,25
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SecureTestUtils,removeProduceAcls,Long Statement,The length of the statement "Collections.addAll(aclArgs`("--authorizer kafka.security.authorizer.AclAuthorizer " + "--authorizer-properties zookeeper.connect=" + zkConnect + " --topic "+ topic+ " --remove --producer "+ " --allow-principal ").split("\\s+"));" is 228.,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration,SecureTestUtils,setConsumerAcls,Long Statement,The length of the statement "Collections.addAll(aclArgs`("--authorizer kafka.security.authorizer.AclAuthorizer " + "--authorizer-properties zookeeper.connect=" + zkConnect + " --topic "+ topic+ " --add --consumer "+ " --allow-principal ").split("\\s+"));" is 225.,59
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,setUp,Magic Number,The method contains a magic number: 3,38
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,exampleMapValue,Magic Number,The method contains a magic number: 53.4,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,exampleMapValue,Magic Number,The method contains a magic number: 45,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,exampleListValue,Magic Number,The method contains a magic number: 53.4,61
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,exampleListValue,Magic Number,The method contains a magic number: 45,61
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,testProduceToTopicKeyAndValue,Long Statement,The length of the statement "testProduceToTopic(topicName`request`KafkaJsonDeserializer.class.getName()`KafkaJsonDeserializer.class.getName()`produceOffsets`true`request.toProduceRequest().getRecords());" is 174.,116
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,testProduceToTopicNoKey,Long Statement,The length of the statement "testProduceToTopic(topicName`request`KafkaJsonDeserializer.class.getName()`KafkaJsonDeserializer.class.getName()`produceOffsets`true`request.toProduceRequest().getRecords());" is 174.,129
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,testProduceToPartitionKeyAndValue,Long Statement,The length of the statement "testProduceToPartition(topicName`0`request`KafkaJsonDeserializer.class.getName()`KafkaJsonDeserializer.class.getName()`produceOffsets`request.toProduceRequest().getRecords());" is 175.,142
confluentinc_kafka-rest,io.confluent.kafkarest.integration,JsonProducerTest,testProduceToPartitionNoKey,Long Statement,The length of the statement "testProduceToPartition(topicName`0`request`KafkaJsonDeserializer.class.getName()`KafkaJsonDeserializer.class.getName()`produceOffsets`request.toProduceRequest().getRecords());" is 175.,156
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SeekToTimestampTest,testConsumeOnlyValues,Long Statement,The length of the statement "consumeMessages(consumerUri`RECORDS_AFTER_TIMESTAMP`Versions.KAFKA_V2_JSON_BINARY`Versions.KAFKA_V2_JSON_BINARY`BINARY_CONSUMER_RECORD_TYPE`null`BinaryConsumerRecord::toConsumerRecord);" is 185.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SeekToTimestampTest,testConsumeOnlyValues,Magic Number,The method contains a magic number: 1000,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Identifier,The length of the identifier createConsumerInstanceResponse is 30.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "Response createConsumerInstanceResponse=testEnv.kafkaRest().target().path(String.format("/consumers/%s"`CONSUMER_GROUP)).request().post(Entity.entity(new CreateConsumerInstanceRequest(null`null`getFormat() != null ? getFormat().name() : null`null`null`null`null)`Versions.KAFKA_V2_JSON));" is 288.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "CreateConsumerInstanceResponse createConsumerInstance=createConsumerInstanceResponse.readEntity(CreateConsumerInstanceResponse.class);" is 134.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "Response subscribeResponse=testEnv.kafkaRest().target().path(String.format("/consumers/%s/instances/%s/subscription"`CONSUMER_GROUP`createConsumerInstance.getInstanceId())).request().post(Entity.entity(new ConsumerSubscriptionRecord(singletonList(TOPIC)`null)`Versions.KAFKA_V2_JSON));" is 285.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "testEnv.kafkaRest().target().path(String.format("/consumers/%s/instances/%s/records"`CONSUMER_GROUP`createConsumerInstance.getInstanceId())).request().accept(getContentType()).get();" is 182.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "SchemaTopicProduceRequest produceRequest=new SchemaTopicProduceRequest(getProduceRecords()`getKeySchema().canonicalString()`null`getValueSchema().canonicalString()`null);" is 170.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "Response genericResponse=testEnv.kafkaRest().target().path(String.format("/topics/%s"`TOPIC)).request().post(Entity.entity(produceRequest`getContentType()));" is 157.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Long Statement,The length of the statement "Response readRecordsResponse=testEnv.kafkaRest().target().path(String.format("/consumers/%s/instances/%s/records"`CONSUMER_GROUP`createConsumerInstance.getInstanceId())).request().accept(getContentType()).get();" is 211.,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,produceThenConsume_returnsExactlyProduced,Magic Number,The method contains a magic number: 3,73
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v2,SchemaProduceConsumeTest,assertMapEquals,Complex Conditional,The conditional expression !extra.isEmpty() || !missing.isEmpty() || !different.isEmpty() is complex.,200
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 3,85
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinary,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(key.toByteArray())).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(value.toByteArray())).build()).setOriginalSize(0L).build();" is 330.,90
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinary,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,90
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinary,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,90
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithNullData,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(NullNode.getInstance()).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(NullNode.getInstance()).build()).setOriginalSize(0L).build();" is 298.,134
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithNullData,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,134
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithNullData,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,134
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithInvalidData_throwsBadRequest,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(IntNode.valueOf(1)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(TextNode.valueOf("fooba")).build()).setOriginalSize(0L).build();" is 297.,176
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithInvalidData_throwsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,176
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithInvalidData_throwsBadRequest,Magic Number,The method contains a magic number: 400,176
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJson,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSON).setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSON).setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 294.,208
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJson,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,208
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJson,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`deserializer`deserializer);" is 153.,208
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonWithNullData,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSON).setData(NullNode.getInstance()).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSON).setData(NullNode.getInstance()).build()).setOriginalSize(0L).build();" is 294.,254
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonWithNullData,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,254
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonWithNullData,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`deserializer`deserializer);" is 153.,254
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 372.,298
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchema,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,298
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchema,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,298
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndNullData_throwsBadRequest,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(NullNode.getInstance()).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(NullNode.getInstance()).build()).setOriginalSize(0L).build();" is 372.,344
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndNullData_throwsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,344
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndNullData_throwsBadRequest,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,344
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndInvalidData,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(IntNode.valueOf(1)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(IntNode.valueOf(2)).build()).setOriginalSize(0L).build();" is 364.,388
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndInvalidData,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,388
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndInvalidData,Magic Number,The method contains a magic number: 2,388
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndInvalidData,Magic Number,The method contains a magic number: 400,388
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaId,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema(DEFAULT_VALUE_SUBJECT`new AvroSchema("{\"type\": \"string\"}"));" is 124.,422
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaId,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSchemaId(keySchema.getSchemaId()).setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setSchemaId(valueSchema.getSchemaId()).setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 308.,422
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaId,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,422
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaId,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,422
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersion,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema(DEFAULT_VALUE_SUBJECT`new AvroSchema("{\"type\": \"string\"}"));" is 124.,474
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersion,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSchemaVersion(keySchema.getSchemaVersion()).setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setSchemaVersion(valueSchema.getSchemaVersion()).setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 328.,474
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersion,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,474
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersion,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,474
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 232.,526
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchema,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,526
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchema,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,526
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setSubject("my-key-subject").setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setSubject("my-value-subject").setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 432.,568
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,568
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,568
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubject,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema("my-value-subject"`new AvroSchema("{\"type\": \"string\"}"));" is 121.,616
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject("my-key-subject").setSchemaId(keySchema.getSchemaId()).setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setSubject("my-value-subject").setSchemaId(valueSchema.getSchemaId()).setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 368.,616
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,616
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,616
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubject,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema("my-value-subject"`new AvroSchema("{\"type\": \"string\"}"));" is 121.,670
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject("my-key-subject").setSchemaVersion(keySchema.getSchemaVersion()).setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setSubject("my-value-subject").setSchemaVersion(valueSchema.getSchemaVersion()).setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 388.,670
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,670
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,670
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject("my-key-subject").setData(TextNode.valueOf(key)).build()).setValue(ProduceRequestData.builder().setSubject("my-value-subject").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 292.,724
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,724
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,724
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "String keyRawSchema="{\"type\": \"record\"` \"name\": \"MyKey\"` \"fields\": [{\"name\": \"foo\"` \"type\": " + "\"string\"}]}";" is 128.,774
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "String valueRawSchema="{\"type\": \"record\"` \"name\": \"MyValue\"` \"fields\": [{\"name\": \"bar\"` \"type\": " + "\"string\"}]}";" is 132.,774
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setRawSchema(keyRawSchema).setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setRawSchema(valueRawSchema).setData(value).build()).setOriginalSize(0L).build();" is 434.,774
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,774
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,774
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "AvroSchema keySchema=new AvroSchema("{\"type\": \"record\"` \"name\": \"MyKey\"` \"fields\": [{\"name\": \"foo\"` " + "\"type\": \"string\"}]}");" is 145.,835
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "AvroSchema valueSchema=new AvroSchema("{\"type\": \"record\"` \"name\": \"MyValue\"` \"fields\": [{\"name\": \"bar\"` " + "\"type\": \"string\"}]}");" is 149.,835
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setSchemaId(keySchemaKey.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setSchemaId(valueSchemaKey.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 398.,835
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,835
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,835
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "AvroSchema keySchema=new AvroSchema("{\"type\": \"record\"` \"name\": \"MyKey\"` \"fields\": [{\"name\": \"foo\"` " + "\"type\": \"string\"}]}");" is 145.,901
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "AvroSchema valueSchema=new AvroSchema("{\"type\": \"record\"` \"name\": \"MyValue\"` \"fields\": [{\"name\": \"bar\"` " + "\"type\": \"string\"}]}");" is 149.,901
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setSchemaVersion(keySchemaKey.getSchemaVersion()).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setSchemaVersion(valueSchemaKey.getSchemaVersion()).setData(value).build()).setOriginalSize(0L).build();" is 416.,901
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,901
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,901
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "AvroSchema keySchema=new AvroSchema("{\"type\": \"record\"` \"name\": \"MyKey\"` \"fields\": [{\"name\": \"foo\"` " + "\"type\": \"string\"}]}");" is 145.,967
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "AvroSchema valueSchema=new AvroSchema("{\"type\": \"record\"` \"name\": \"MyValue\"` \"fields\": [{\"name\": \"bar\"` " + "\"type\": \"string\"}]}");" is 149.,967
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setData(value).build()).setOriginalSize(0L).build();" is 314.,967
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,967
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createAvroDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 227.,967
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setRawSchema("{\"type\": \"string\"}").setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setRawSchema("{\"type\": \"string\"}").setData(value).build()).setOriginalSize(0L).build();" is 348.,1031
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchema,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1031
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchema,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1031
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndNullData,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setRawSchema("{\"type\": \"string\"}").setData(NullNode.getInstance()).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setRawSchema("{\"type\": \"string\"}").setData(NullNode.getInstance()).build()).setOriginalSize(0L).build();" is 384.,1077
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndNullData,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1077
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndNullData,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1077
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndInvalidData_throwsBadRequest,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setRawSchema("{\"type\": \"string\"}").setData(IntNode.valueOf(1)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setRawSchema("{\"type\": \"string\"}").setData(IntNode.valueOf(2)).build()).setOriginalSize(0L).build();" is 376.,1121
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndInvalidData_throwsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1121
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndInvalidData_throwsBadRequest,Magic Number,The method contains a magic number: 2,1121
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndInvalidData_throwsBadRequest,Magic Number,The method contains a magic number: 400,1121
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaId,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema(DEFAULT_VALUE_SUBJECT`new JsonSchema("{\"type\": \"string\"}"));" is 124.,1155
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaId,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSchemaId(keySchema.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSchemaId(valueSchema.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 272.,1155
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaId,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1155
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaId,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1155
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersion,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema(DEFAULT_VALUE_SUBJECT`new JsonSchema("{\"type\": \"string\"}"));" is 124.,1207
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersion,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSchemaVersion(keySchema.getSchemaVersion()).setData(key).build()).setValue(ProduceRequestData.builder().setSchemaVersion(valueSchema.getSchemaVersion()).setData(value).build()).setOriginalSize(0L).build();" is 292.,1207
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersion,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1207
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersion,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1207
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setData(key).build()).setValue(ProduceRequestData.builder().setData(value).build()).setOriginalSize(0L).build();" is 196.,1259
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchema,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1259
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchema,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1259
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setSubject("my-key-subject").setRawSchema("{\"type\": \"string\"}").setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setSubject("my-value-subject").setRawSchema("{\"type\": \"string\"}").setData(value).build()).setOriginalSize(0L).build();" is 408.,1301
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1301
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1301
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubject,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema("my-value-subject"`new JsonSchema("{\"type\": \"string\"}"));" is 121.,1349
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject("my-key-subject").setSchemaId(keySchema.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSubject("my-value-subject").setSchemaId(valueSchema.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 332.,1349
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1349
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1349
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubject,Long Statement,The length of the statement "SchemaKey valueSchema=testEnv.schemaRegistry().createSchema("my-value-subject"`new JsonSchema("{\"type\": \"string\"}"));" is 121.,1403
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject("my-key-subject").setSchemaVersion(keySchema.getSchemaVersion()).setData(key).build()).setValue(ProduceRequestData.builder().setSubject("my-value-subject").setSchemaVersion(valueSchema.getSchemaVersion()).setData(value).build()).setOriginalSize(0L).build();" is 352.,1403
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1403
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1403
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject("my-key-subject").setData(key).build()).setValue(ProduceRequestData.builder().setSubject("my-value-subject").setData(value).build()).setOriginalSize(0L).build();" is 256.,1457
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1457
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubject,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1457
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "String keyRawSchema="{\"type\": \"object\"` \"title\": \"MyKey\"` \"properties\": {\"foo\": " + "{\"type\": \"string\"}}}";" is 123.,1500
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "String valueRawSchema="{\"type\": \"object\"` \"title\": \"MyValue\"` \"properties\": {\"bar\": " + "{\"type\": \"string\"}}}";" is 127.,1500
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setRawSchema(keyRawSchema).setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSONSCHEMA).setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setRawSchema(valueRawSchema).setData(value).build()).setOriginalSize(0L).build();" is 446.,1500
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1500
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1500
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "JsonSchema keySchema=new JsonSchema("{\"type\": \"object\"` \"title\": \"MyKey\"` \"properties\": {\"foo\": " + "{\"type\": \"string\"}}}");" is 140.,1556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "JsonSchema valueSchema=new JsonSchema("{\"type\": \"object\"` \"title\": \"MyValue\"` \"properties\": {\"bar\": " + "{\"type\": \"string\"}}}");" is 144.,1556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setSchemaId(keySchemaKey.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setSchemaId(valueSchemaKey.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 398.,1556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "JsonSchema keySchema=new JsonSchema("{\"type\": \"object\"` \"title\": \"MyKey\"` \"properties\": {\"foo\": " + "{\"type\": \"string\"}}}");" is 140.,1618
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "JsonSchema valueSchema=new JsonSchema("{\"type\": \"object\"` \"title\": \"MyValue\"` \"properties\": {\"bar\": " + "{\"type\": \"string\"}}}");" is 144.,1618
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setSchemaVersion(keySchemaKey.getSchemaVersion()).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setSchemaVersion(valueSchemaKey.getSchemaVersion()).setData(value).build()).setOriginalSize(0L).build();" is 416.,1618
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1618
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithSchemaVersionAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1618
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "JsonSchema keySchema=new JsonSchema("{\"type\": \"object\"` \"title\": \"MyKey\"` \"properties\": {\"foo\": " + "{\"type\": \"string\"}}}");" is 140.,1680
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "JsonSchema valueSchema=new JsonSchema("{\"type\": \"object\"` \"title\": \"MyValue\"` \"properties\": {\"bar\": " + "{\"type\": \"string\"}}}");" is 144.,1680
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.TOPIC_NAME).setData(value).build()).setOriginalSize(0L).build();" is 314.,1680
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1680
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonschemaWithLatestSchemaAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createJsonSchemaDeserializer()`testEnv.schemaRegistry().createJsonSchemaDeserializer());" is 239.,1680
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setRawSchema(keySchema.canonicalString()).setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setRawSchema(valueSchema.canonicalString()).setData(value).build()).setOriginalSize(0L).build();" is 352.,1740
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchema,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1740
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchema,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,1740
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndNullData,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setRawSchema(keySchema.canonicalString()).setData(NullNode.getInstance()).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setRawSchema(valueSchema.canonicalString()).setData(NullNode.getInstance()).build()).setOriginalSize(0L).build();" is 388.,1796
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndNullData,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1796
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndNullData,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,1796
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndInvalidData_throwsBadRequest,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setRawSchema(keySchema.canonicalString()).setData(IntNode.valueOf(1)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setRawSchema(valueSchema.canonicalString()).setData(IntNode.valueOf(2)).build()).setOriginalSize(0L).build();" is 380.,1844
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndInvalidData_throwsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1844
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndInvalidData_throwsBadRequest,Magic Number,The method contains a magic number: 2,1844
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndInvalidData_throwsBadRequest,Magic Number,The method contains a magic number: 400,1844
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaId,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSchemaId(keySchemaKey.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSchemaId(valueSchemaKey.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 278.,1882
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaId,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1882
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaId,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,1882
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaVersion,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSchemaVersion(keySchemaKey.getSchemaVersion()).setData(key).build()).setValue(ProduceRequestData.builder().setSchemaVersion(valueSchemaKey.getSchemaVersion()).setData(value).build()).setOriginalSize(0L).build();" is 298.,1939
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaVersion,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1939
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaVersion,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,1939
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithLatestSchema,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setData(key).build()).setValue(ProduceRequestData.builder().setData(value).build()).setOriginalSize(0L).build();" is 196.,1996
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithLatestSchema,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,1996
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithLatestSchema,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,1996
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setSubject("my-key-subject").setRawSchema(keySchema.canonicalString()).setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setSubject("my-value-subject").setRawSchema(valueSchema.canonicalString()).setData(value).build()).setOriginalSize(0L).build();" is 412.,2044
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2044
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndSubject,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,2044
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaIdAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject(keySubject).setSchemaId(keySchemaKey.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSubject(valueSubject).setSchemaId(valueSchemaKey.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 326.,2102
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaIdAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2102
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaIdAndSubject,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,2102
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaVersionAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject(keySubject).setSchemaVersion(keySchemaKey.getSchemaVersion()).setData(key).build()).setValue(ProduceRequestData.builder().setSubject(valueSubject).setSchemaVersion(valueSchemaKey.getSchemaVersion()).setData(value).build()).setOriginalSize(0L).build();" is 346.,2162
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaVersionAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2162
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaVersionAndSubject,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,2162
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithLatestSchemaAndSubject,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubject(keySubject).setData(key).build()).setValue(ProduceRequestData.builder().setSubject(valueSubject).setData(value).build()).setOriginalSize(0L).build();" is 244.,2222
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithLatestSchemaAndSubject,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2222
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithLatestSchemaAndSubject,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,2222
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setRawSchema(keySchema.canonicalString()).setData(key).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.PROTOBUF).setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setRawSchema(valueSchema.canonicalString()).setData(value).build()).setOriginalSize(0L).build();" is 472.,2272
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2272
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithRawSchemaAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,2272
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setSchemaId(keySchemaKey.getSchemaId()).setData(key).build()).setValue(ProduceRequestData.builder().setSubjectNameStrategy(EnumSubjectNameStrategy.RECORD_NAME).setSchemaId(valueSchemaKey.getSchemaId()).setData(value).build()).setOriginalSize(0L).build();" is 398.,2330
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2330
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceProtobufWithSchemaIdAndSubjectStrategy,Long Statement,The length of the statement "ConsumerRecord<Message`Message> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`testEnv.schemaRegistry().createProtobufDeserializer()`testEnv.schemaRegistry().createProtobufDeserializer());" is 237.,2330
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithPartitionId,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setPartitionId(partitionId).setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(key.toByteArray())).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(value.toByteArray())).build()).setOriginalSize(0L).build();" is 358.,2392
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithPartitionId,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2392
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithPartitionId,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`partitionId`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 171.,2392
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithTimestamp,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(key.toByteArray())).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(value.toByteArray())).build()).setTimestamp(timestamp).setOriginalSize(0L).build();" is 354.,2438
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithTimestamp,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2438
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithTimestamp,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,2438
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithTimestamp,Magic Number,The method contains a magic number: 1000,2438
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithHeaders,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setHeaders(Arrays.asList(ProduceRequestHeader.create("header-1"`ByteString.copyFromUtf8("value-1"))`ProduceRequestHeader.create("header-1"`ByteString.copyFromUtf8("value-2"))`ProduceRequestHeader.create("header-2"`ByteString.copyFromUtf8("value-3")))).setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(key.toByteArray())).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(value.toByteArray())).build()).setOriginalSize(0L).build();" is 582.,2485
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithHeaders,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2485
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithHeaders,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,2485
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithHeaders,Long Statement,The length of the statement "assertEquals(Arrays.asList(new RecordHeader("header-1"`ByteString.copyFromUtf8("value-1").toByteArray())`new RecordHeader("header-1"`ByteString.copyFromUtf8("value-2").toByteArray()))`ImmutableList.copyOf(produced.headers().headers("header-1")));" is 246.,2485
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithHeaders,Long Statement,The length of the statement "assertEquals(singletonList(new RecordHeader("header-2"`ByteString.copyFromUtf8("value-3").toByteArray()))`ImmutableList.copyOf(produced.headers().headers("header-2")));" is 168.,2485
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryAndAvro,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(key.toByteArray())).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.AVRO).setRawSchema("{\"type\": \"string\"}").setData(TextNode.valueOf(value)).build()).setOriginalSize(0L).build();" is 351.,2543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryAndAvro,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryAndAvro,Long Statement,The length of the statement "ConsumerRecord<byte[]`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`testEnv.schemaRegistry().createAvroDeserializer());" is 205.,2543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryKeyOnly,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(key.toByteArray())).build()).setOriginalSize(0L).build();" is 201.,2588
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryKeyOnly,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2588
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryKeyOnly,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,2588
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryValueOnly,Long Statement,The length of the statement "ProduceRequest request=ProduceRequest.builder().setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(BinaryNode.valueOf(value.toByteArray())).build()).setOriginalSize(0L).build();" is 205.,2626
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryValueOnly,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2626
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryValueOnly,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,2626
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceNothing,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2664
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceNothing,Long Statement,The length of the statement "ConsumerRecord<byte[]`byte[]> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.getPartitionId()`actual.getOffset()`new ByteArrayDeserializer()`new ByteArrayDeserializer());" is 183.,2664
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Long Statement,The length of the statement "requests.add(ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSON).setData(TextNode.valueOf("key-" + i)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.JSON).setData(TextNode.valueOf("value-" + i)).build()).setOriginalSize(0L).build());" is 299.,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(batch.toString()`MediaType.APPLICATION_JSON));" is 228.,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Long Statement,The length of the statement "ConsumerRecord<Object`Object> produced=testEnv.kafkaCluster().getRecord(TOPIC_NAME`actual.get(i).getPartitionId()`actual.get(i).getOffset()`deserializer`deserializer);" is 167.,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Long Statement,The length of the statement "assertEquals(requests.get(i).getKey().map(ProduceRequestData::getData).map(JsonNode::asText).orElse(null)`produced.key());" is 122.,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Long Statement,The length of the statement "assertEquals(requests.get(i).getValue().map(ProduceRequestData::getData).map(JsonNode::asText).orElse(null)`produced.value());" is 126.,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Magic Number,The method contains a magic number: 1000,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceJsonBatch,Magic Number,The method contains a magic number: 1000,2693
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Long Statement,The length of the statement "requests.add(ProduceRequest.builder().setKey(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(IntNode.valueOf(2 * i)).build()).setValue(ProduceRequestData.builder().setFormat(EmbeddedFormat.BINARY).setData(IntNode.valueOf(2 * i + 1)).build()).setOriginalSize(0L).build());" is 293.,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(batch.toString()`MediaType.APPLICATION_JSON));" is 228.,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Magic Number,The method contains a magic number: 1000,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Magic Number,The method contains a magic number: 2,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Magic Number,The method contains a magic number: 2,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Magic Number,The method contains a magic number: 1000,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryBatchWithInvalidData_throwsMultipleBadRequests,Magic Number,The method contains a magic number: 400,2763
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaSubject_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2806
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaSubject_returnsBadRequest,Magic Number,The method contains a magic number: 400,2806
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaSubjectStrategy_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2825
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaSubjectStrategy_returnsBadRequest,Magic Number,The method contains a magic number: 400,2825
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithRawSchema_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2844
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithRawSchema_returnsBadRequest,Magic Number,The method contains a magic number: 400,2844
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaId_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2864
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaId_returnsBadRequest,Magic Number,The method contains a magic number: 400,2864
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaVersion_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2883
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceBinaryWithSchemaVersion_returnsBadRequest,Magic Number,The method contains a magic number: 400,2883
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithTypeAndSchemaVersion_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2902
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithTypeAndSchemaVersion_returnsBadRequest,Magic Number,The method contains a magic number: 400,2902
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithTypeAndSchemaId_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2921
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithTypeAndSchemaId_returnsBadRequest,Magic Number,The method contains a magic number: 400,2921
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithTypeAndLatestSchema_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2940
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithTypeAndLatestSchema_returnsBadRequest,Magic Number,The method contains a magic number: 400,2940
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaSubjectAndSchemaSubjectStrategy_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2959
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaSubjectAndSchemaSubjectStrategy_returnsBadRequest,Magic Number,The method contains a magic number: 400,2959
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSchemaVersion_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2980
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithSchemaIdAndSchemaVersion_returnsBadRequest,Magic Number,The method contains a magic number: 400,2980
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSchemaId_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,2999
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSchemaId_returnsBadRequest,Magic Number,The method contains a magic number: 400,2999
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSchemaVersion_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,3019
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRawSchemaAndSchemaVersion_returnsBadRequest,Magic Number,The method contains a magic number: 400,3019
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRecordSchemaSubjectStrategyAndSchemaVersion_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,3039
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRecordSchemaSubjectStrategyAndSchemaVersion_returnsBadRequest,Magic Number,The method contains a magic number: 400,3039
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRecordSchemaSubjectStrategyAndLatestVersion_returnsBadRequest,Long Statement,The length of the statement "Response response=testEnv.kafkaRest().target().path("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/records").request().accept(MediaType.APPLICATION_JSON).post(Entity.entity(request`MediaType.APPLICATION_JSON));" is 219.,3060
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ProduceActionIntegrationTest,produceAvroWithRecordSchemaSubjectStrategyAndLatestVersion_returnsBadRequest,Magic Number,The method contains a magic number: 400,3060
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReplicasByBrokerActionIntegrationTest,SearchReplicasByBrokerActionIntegrationTest,Magic Number,The method contains a magic number: 2,40
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReplicasByBrokerActionIntegrationTest,searchReplicasByBroker_existingBroker_returnsReplicas,Long Statement,The length of the statement "SearchReplicasByBrokerResponse expected=SearchReplicasByBrokerResponse.create(ReplicaDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ BROKER_ID+ "/partition-replicas").build()).setData(Arrays.asList(ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/"+ BROKER_ID).setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_NAME+ "/partition=0/replica="+ BROKER_ID).build()).setClusterId(clusterId).setTopicName(TOPIC_NAME).setPartitionId(0).setBrokerId(BROKER_ID).setLeader(true).setInSync(true).setBroker(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ BROKER_ID)).build()`ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/1/replicas/"+ BROKER_ID).setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_NAME+ "/partition=1/replica="+ BROKER_ID).build()).setClusterId(clusterId).setTopicName(TOPIC_NAME).setPartitionId(1).setBrokerId(BROKER_ID).setLeader(false).setInSync(true).setBroker(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ BROKER_ID)).build())).build());" is 1327.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReplicasByBrokerActionIntegrationTest,searchReplicasByBroker_existingBroker_returnsReplicas,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ BROKER_ID+ "/partition-replicas").accept(MediaType.APPLICATION_JSON).get();" is 144.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReplicasByBrokerActionIntegrationTest,searchReplicasByBroker_nonExistingBroker_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/100/partition-replicas").accept(MediaType.APPLICATION_JSON).get();" is 132.,155
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_returnsConsumerGroups,Long Statement,The length of the statement "ListConsumerGroupsResponse expectedPreparingRebalance=getExpectedListResponse(baseUrl`clusterId`""`State.PREPARING_REBALANCE);" is 126.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_returnsConsumerGroups,Long Statement,The length of the statement "assertThat(response.readEntity(ListConsumerGroupsResponse.class)`anyOf(is(expectedPreparingRebalance)`is(expectedStable)));" is 123.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_returnsConsumerGroups,Magic Number,The method contains a magic number: 3,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_returnsConsumerGroups,Magic Number,The method contains a magic number: 3,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_returnsConsumerGroups,Magic Number,The method contains a magic number: 3,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,84
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,84
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,listConsumerGroups_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,84
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_returnsConsumerGroup,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1").accept(MediaType.APPLICATION_JSON).get();" is 134.,104
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_returnsConsumerGroup,Magic Number,The method contains a magic number: 3,104
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_returnsConsumerGroup,Magic Number,The method contains a magic number: 3,104
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_returnsConsumerGroup,Magic Number,The method contains a magic number: 3,104
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/consumer-groups/consumer-group-1").accept(MediaType.APPLICATION_JSON).get();" is 123.,138
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,138
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,138
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,138
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingConsumerGroup_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/foobar").accept(MediaType.APPLICATION_JSON).get();" is 124.,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getConsumerGroup_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,160
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getExpectedListResponse,Long Statement,The length of the statement "return ListConsumerGroupsResponse.create(ConsumerGroupDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups").build()).setData(singletonList(ConsumerGroupData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1").setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1").build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setSimple(false).setPartitionAssignor(partitionAssignor).setState(state).setCoordinator(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/0")).setConsumers(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers")).setLagSummary(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/lag-summary")).build())).build());" is 951.,191
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupsResourceIntegrationTest,getExpectedGroupResponse,Long Statement,The length of the statement "return GetConsumerGroupResponse.create(ConsumerGroupData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1").setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1").build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setSimple(false).setPartitionAssignor(partitionAssignor).setState(state).setCoordinator(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/0")).setConsumers(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers")).setLagSummary(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/lag-summary")).build());" is 759.,238
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,listConsumerAssignments_returnsConsumerAssignments,Long Statement,The length of the statement "ListConsumerAssignmentsResponse expected=ListConsumerAssignmentsResponse.create(ConsumerAssignmentDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups"+ "/consumer-group-1/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments").build()).setData(Arrays.asList(ConsumerAssignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/topic-1/partitions/0").setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer.groupMetadata().memberId()+ "/assignment=topic-1/partition=0").build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer.groupMetadata().memberId()).setTopicName("topic-1").setPartitionId(0).setPartition(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/topic-1"+ "/partitions/0")).setLag(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1"+ "/lags/topic-1"+ "/partitions/0")).build()`ConsumerAssignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/topic-1/partitions/1").setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer.groupMetadata().memberId()+ "/assignment=topic-1/partition=1").build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer.groupMetadata().memberId()).setTopicName("topic-1").setPartitionId(1).setPartition(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/topic-1"+ "/partitions/1")).setLag(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1"+ "/lags/topic-1"+ "/partitions/1")).build()`ConsumerAssignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/topic-1/partitions/2").setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer.groupMetadata().memberId()+ "/assignment=topic-1/partition=2").build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer.groupMetadata().memberId()).setTopicName("topic-1").setPartitionId(2).setPartition(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/topic-1"+ "/partitions/2")).setLag(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1"+ "/lags/topic-1"+ "/partitions/2")).build())).build());" is 2851.,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,listConsumerAssignments_returnsConsumerAssignments,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments").accept(MediaType.APPLICATION_JSON).get();" is 198.,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,listConsumerAssignments_returnsConsumerAssignments,Magic Number,The method contains a magic number: 3,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,listConsumerAssignments_returnsConsumerAssignments,Magic Number,The method contains a magic number: 2,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,listConsumerAssignments_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/consumer-groups/consumer-group-1/consumers/" + consumer.groupMetadata().memberId() + "/assignments").accept(MediaType.APPLICATION_JSON).get();" is 189.,204
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,listConsumerAssignments_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,204
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_returnsConsumerAssignment,Long Statement,The length of the statement "GetConsumerAssignmentResponse expected=GetConsumerAssignmentResponse.create(ConsumerAssignmentData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/topic-1/partitions/0").setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer.groupMetadata().memberId()+ "/assignment=topic-1/partition=0").build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer.groupMetadata().memberId()).setTopicName("topic-1").setPartitionId(0).setPartition(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/topic-1"+ "/partitions/0")).setLag(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1"+ "/lags/topic-1"+ "/partitions/0")).build());" is 907.,221
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_returnsConsumerAssignment,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1"+ "/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/topic-1/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 223.,221
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_returnsConsumerAssignment,Magic Number,The method contains a magic number: 3,221
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/consumer-groups/consumer-group-1" + "/consumers/" + consumer.groupMetadata().memberId() + "/assignments/topic-1/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 215.,287
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,287
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingConsumerGroup_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/foobar"+ "/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/topic-1/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 213.,305
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,305
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingConsumer_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1"+ "/consumers/foobar"+ "/assignments/topic-1/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 192.,326
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingConsumer_returnsNotFound,Magic Number,The method contains a magic number: 3,326
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingConsumerAssignment_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1"+ "/consumers/"+ consumer.groupMetadata().memberId()+ "/assignments/foobar/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 222.,346
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerAssignmentsResourceIntegrationTest,getConsumerAssignment_nonExistingConsumerAssignment_returnsNotFound,Magic Number,The method contains a magic number: 3,346
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "ListConsumersResponse expected=ListConsumersResponse.create(ConsumerDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups"+ "/consumer-group-1/consumers").build()).setData(Arrays.asList(ConsumerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer1.groupMetadata().memberId()).setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer1.groupMetadata().memberId()).build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer1.groupMetadata().memberId()).setClientId("client-1").setAssignments(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups"+ "/consumer-group-1/consumers/"+ consumer1.groupMetadata().memberId()+ "/assignments")).build()`ConsumerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer2.groupMetadata().memberId()).setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer2.groupMetadata().memberId()).build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer2.groupMetadata().memberId()).setClientId("client-2").setAssignments(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups"+ "/consumer-group-1/consumers/"+ consumer2.groupMetadata().memberId()+ "/assignments")).build()`ConsumerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer3.groupMetadata().memberId()).setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer3.groupMetadata().memberId()).build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer3.groupMetadata().memberId()).setClientId("client-3").setAssignments(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups"+ "/consumer-group-1/consumers/"+ consumer3.groupMetadata().memberId()+ "/assignments")).build())).build());" is 2278.,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,listConsumers_returnsConsumers,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1/consumers").accept(MediaType.APPLICATION_JSON).get();" is 144.,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,listConsumers_returnsConsumers,Magic Number,The method contains a magic number: 3,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,listConsumers_returnsConsumers,Magic Number,The method contains a magic number: 3,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,listConsumers_returnsConsumers,Magic Number,The method contains a magic number: 3,46
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,listConsumers_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/consumer-groups/consumer-group-1").accept(MediaType.APPLICATION_JSON).get();" is 123.,183
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "GetConsumerResponse expected=GetConsumerResponse.create(ConsumerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/consumer-group-1/consumers/"+ consumer1.groupMetadata().memberId()).setResourceName("crn:///kafka=" + clusterId + "/consumer-group=consumer-group-1"+ "/consumer="+ consumer1.groupMetadata().memberId()).build()).setClusterId(clusterId).setConsumerGroupId("consumer-group-1").setConsumerId(consumer1.groupMetadata().memberId()).setClientId("client-1").setAssignments(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups"+ "/consumer-group-1/consumers/"+ consumer1.groupMetadata().memberId()+ "/assignments")).build());" is 724.,192
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_returnsConsumer,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1"+ "/consumers/"+ consumer1.groupMetadata().memberId()).accept(MediaType.APPLICATION_JSON).get();" is 187.,192
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_returnsConsumer,Magic Number,The method contains a magic number: 3,192
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_returnsConsumer,Magic Number,The method contains a magic number: 3,192
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_returnsConsumer,Magic Number,The method contains a magic number: 3,192
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/consumer-groups/consumer-group-1/consumers/" + consumer1.groupMetadata().memberId()).accept(MediaType.APPLICATION_JSON).get();" is 173.,261
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,261
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,261
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingCluster_returnsNotFound,Magic Number,The method contains a magic number: 3,261
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumerGroup_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/foobar/consumers/"+ consumer1.groupMetadata().memberId()).accept(MediaType.APPLICATION_JSON).get();" is 173.,290
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,290
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,290
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumerGroup_returnsNotFound,Magic Number,The method contains a magic number: 3,290
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumer_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/consumer-group-1/consumers/foobar").accept(MediaType.APPLICATION_JSON).get();" is 151.,322
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumer_returnsNotFound,Magic Number,The method contains a magic number: 3,322
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumer_returnsNotFound,Magic Number,The method contains a magic number: 3,322
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumersResourceIntegrationTest,getConsumer_nonExistingConsumer_returnsNotFound,Magic Number,The method contains a magic number: 3,322
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,SearchReassignmentsByTopicActionIntegrationTest,Magic Number,The method contains a magic number: 6,40
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 2,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 100,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Long Statement,The length of the statement "Map<TopicPartition`Optional<NewPartitionReassignment>> reassignmentMap=createReassignment(Arrays.asList(3`4`5)`TOPIC_NAME`100);" is 127.,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/-/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 151.,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Long Statement,The length of the statement "assertEquals(data.getAddingReplicas()`reassignmentMap.get(new TopicPartition(TOPIC_NAME`data.getPartitionId())).get().targetReplicas());" is 136.,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Magic Number,The method contains a magic number: 3,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Magic Number,The method contains a magic number: 4,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Magic Number,The method contains a magic number: 5,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_returnsReassignments,Magic Number,The method contains a magic number: 100,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/topic-1/partitions/-/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 131.,83
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,SearchReassignmentsByTopicActionIntegrationTest,searchReassignmentsByTopic_nonExistingTopic_returnsEmpty,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/partitions/-/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 141.,94
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,listReplicas_existingPartition_returnsReplicas,Long Statement,The length of the statement "ListReplicasResponse expected=ListReplicasResponse.create(ReplicaDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas").build()).setData(singletonList(ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/0").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_NAME+ "/partition=0/replica=0").build()).setClusterId(clusterId).setTopicName(TOPIC_NAME).setPartitionId(0).setBrokerId(0).setLeader(true).setInSync(true).setBroker(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/0")).build())).build());" is 753.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,listReplicas_existingPartition_returnsReplicas,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas").accept(MediaType.APPLICATION_JSON).get();" is 147.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,listReplicas_nonExistingPartition_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/100/replicas").accept(MediaType.APPLICATION_JSON).get();" is 149.,109
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,listReplicas_nonExistingTopic_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/partitions/0/replicas").accept(MediaType.APPLICATION_JSON).get();" is 137.,120
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,listReplicas_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_NAME + "/partitions/0/replicas").accept(MediaType.APPLICATION_JSON).get();" is 138.,131
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,getReplica_existingReplica_returnsReplica,Long Statement,The length of the statement "GetReplicaResponse expected=GetReplicaResponse.create(ReplicaData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/0").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_NAME+ "/partition=0/replica=0").build()).setClusterId(clusterId).setTopicName(TOPIC_NAME).setPartitionId(0).setBrokerId(0).setLeader(true).setInSync(true).setBroker(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/0")).build());" is 535.,140
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,getReplica_existingReplica_returnsReplica,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/0").accept(MediaType.APPLICATION_JSON).get();" is 149.,140
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,getReplica_nonExistingReplica_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/100").accept(MediaType.APPLICATION_JSON).get();" is 151.,185
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,getReplica_nonExistingPartition_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/100/replicas/0").accept(MediaType.APPLICATION_JSON).get();" is 151.,201
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,getReplica_nonExistingTopic_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/partitions/0/replicas/0").accept(MediaType.APPLICATION_JSON).get();" is 139.,217
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ReplicasResourceIntegrationTest,getReplica_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_NAME + "/partitions/0/replicas/0").accept(MediaType.APPLICATION_JSON).get();" is 140.,228
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,listPartitions_existingTopic_returnPartitions,Long Statement,The length of the statement "ListPartitionsResponse expected=ListPartitionsResponse.create(PartitionDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions").build()).setData(singletonList(PartitionData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0").setResourceName("crn://" + "/kafka=" + clusterId + "/topic="+ TOPIC_NAME+ "/partition=0").build()).setClusterId(clusterId).setTopicName(TOPIC_NAME).setPartitionId(0).setLeader(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/0")).setReplicas(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas")).setReassignment(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/reassignment")).build())).build());" is 995.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,listPartitions_existingTopic_returnPartitions,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions").accept(MediaType.APPLICATION_JSON).get();" is 136.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,listPartitions_nonExistingTopic_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/partitions").accept(MediaType.APPLICATION_JSON).get();" is 126.,128
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,listPartitions_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_NAME + "/partitions").accept(MediaType.APPLICATION_JSON).get();" is 127.,139
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,getPartition_existingPartition_returnPartition,Long Statement,The length of the statement "GetPartitionResponse expected=GetPartitionResponse.create(PartitionData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_NAME+ "/partition=0").build()).setClusterId(clusterId).setTopicName(TOPIC_NAME).setPartitionId(0).setLeader(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas/0")).setReplicas(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/replicas")).setReassignment(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_NAME+ "/partitions/0/reassignment")).build());" is 781.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,getPartition_existingPartition_returnPartition,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 138.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,getPartition_nonExistingPartition_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/100").accept(MediaType.APPLICATION_JSON).get();" is 140.,207
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,getPartition_nonExistingTopic_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 128.,218
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,PartitionsResourceIntegrationTest,getPartition_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_NAME + "/partitions/0").accept(MediaType.APPLICATION_JSON).get();" is 129.,229
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClustersResourceIntegrationTest,ClustersResourceIntegrationTest,Magic Number,The method contains a magic number: 3,35
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClustersResourceIntegrationTest,listClusters_returnsArrayWithOwnCluster,Long Statement,The length of the statement "ListClustersResponse expected=ListClustersResponse.create(ClusterDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters").build()).setData(singletonList(ClusterData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId).setResourceName("crn:///kafka=" + clusterId).build()).setClusterId(clusterId).setController(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ controllerId)).setAcls(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/acls")).setBrokers(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers")).setBrokerConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/broker-configs")).setConsumerGroups(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups")).setTopics(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/-/partitions/-/reassignment")).build())).build());" is 1129.,39
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClustersResourceIntegrationTest,getCluster_ownCluster_returnsOwnCluster,Long Statement,The length of the statement "GetClusterResponse expected=GetClusterResponse.create(ClusterData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId).setResourceName("crn:///kafka=" + clusterId).build()).setClusterId(clusterId).setController(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ controllerId)).setAcls(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/acls")).setBrokers(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers")).setBrokerConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/broker-configs")).setConsumerGroups(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups")).setTopics(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/-/partitions/-/reassignment")).build());" is 974.,97
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "ResourceCollection.Metadata expectedMetadata=ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/-/configs").build();" is 159.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedTopic1Config1=createTopicConfigData(baseUrl`clusterId`TOPIC_1`"cleanup.policy"`"delete"`true`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 285.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedTopic1Config2=createTopicConfigData(baseUrl`clusterId`TOPIC_1`"compression.type"`"producer"`true`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 289.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedTopic1Config3=createTopicConfigData(baseUrl`clusterId`TOPIC_1`"delete.retention.ms"`"86400000"`true`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("log.cleaner.delete.retention.ms").setValue("86400000").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 307.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedTopic2Config1=createTopicConfigData(baseUrl`clusterId`TOPIC_2`"cleanup.policy"`"delete"`true`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 285.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedTopic2Config2=createTopicConfigData(baseUrl`clusterId`TOPIC_2`"compression.type"`"producer"`true`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 289.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedTopic2Config3=createTopicConfigData(baseUrl`clusterId`TOPIC_2`"delete.retention.ms"`"100000"`false`ConfigSource.DYNAMIC_TOPIC_CONFIG`Arrays.asList(ConfigSynonymData.builder().setName("delete.retention.ms").setValue("100000").setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).build()`ConfigSynonymData.builder().setName("log.cleaner.delete.retention.ms").setValue("86400000").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 443.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedTopic1Config1)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedTopic1Config1));" is 164.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedTopic1Config2)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedTopic1Config2));" is 164.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedTopic1Config3)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedTopic1Config3));" is 164.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedTopic2Config1)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedTopic2Config1));" is 164.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedTopic2Config2)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedTopic2Config2));" is 164.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,listTopicConfigs_existingTopics_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedTopic2Config3)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedTopic2Config3));" is 164.,56
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,createTopicConfigData,Long Parameter List,The method has 8 parameters. ,197
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllTopicsConfigsActionIntegrationTest,createTopicConfigData,Long Statement,The length of the statement "return TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topic1+ "/configs/"+ configName).setResourceName("crn:///kafka=" + clusterId + "/topic="+ topic1+ "/config="+ configName).build()).setClusterId(clusterId).setTopicName(topic1).setName(configName).setValue(configValue).setDefault(isDefault).setReadOnly(false).setSensitive(false).setSource(source).setSynonyms(synonyms).build();" is 459.,197
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,setUp,Magic Number,The method contains a magic number: 3,58
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + getClusterId() + "/consumer-groups/"+ group1+ "/lag-summary").accept(MediaType.APPLICATION_JSON).get();" is 147.,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "ConsumerGroupLagSummaryData consumerGroupLagSummaryData=response.readEntity(GetConsumerGroupLagSummaryResponse.class).getValue();" is 129.,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "GetConsumerGroupLagSummaryResponse expectedResponse=GetConsumerGroupLagSummaryResponse.create(ConsumerGroupLagSummaryData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/"+ group1+ "/lag-summary").setResourceName("crn:///kafka=" + clusterId + "/consumer-group="+ group1+ "/lag-summary").build()).setClusterId(clusterId).setConsumerGroupId(group1).setMaxLagConsumerId(consumer2.groupMetadata().memberId()).setMaxLagClientId("client-2").setMaxLagTopicName(topic2).setMaxLagPartitionId(1).setMaxLag(6L).setTotalLag(9L).setMaxLagConsumer(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/"+ group1+ "/consumers/"+ consumer2.groupMetadata().memberId())).setMaxLagPartition(Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topic2+ "/partitions/"+ 1)).build());" is 870.,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Long Statement,The length of the statement "Response response2=request("/v3/clusters/" + getClusterId() + "/consumer-groups/"+ group1+ "/lag-summary").accept(MediaType.APPLICATION_JSON).get();" is 148.,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Magic Number,The method contains a magic number: 5,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Magic Number,The method contains a magic number: 5,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Magic Number,The method contains a magic number: 5,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Magic Number,The method contains a magic number: 5,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Magic Number,The method contains a magic number: 6L,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_returnsConsumerGroupLagSummary,Magic Number,The method contains a magic number: 9L,70
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_nonExistingOffsets_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + getClusterId() + "/consumer-groups/"+ group1+ "/lag-summary").accept(MediaType.APPLICATION_JSON).get();" is 147.,176
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_nonExistingConsumerGroup_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + getClusterId() + "/consumer-groups/foo/lag-summary").accept(MediaType.APPLICATION_JSON).get();" is 138.,193
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,getConsumerGroupLagSummary_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foo/consumer-groups/" + group1 + "/lag-summary").accept(MediaType.APPLICATION_JSON).get();" is 130.,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerGroupLagSummariesResourceIntegrationTest,produce,Long Statement,The length of the statement "request("topics/" + topicName + "/partitions/"+ partitionId`Collections.emptyMap()).post(Entity.entity(request`Versions.KAFKA_V2_JSON_BINARY));" is 143.,233
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,ListAllBrokersConfigsActionIntegrationTest,Magic Number,The method contains a magic number: 2,39
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "ResourceCollection.Metadata expectedMetadata=ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/-/configs").build();" is 160.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedBroker1Config1=createBrokerConfigData(baseUrl`clusterId`0`"log.cleaner.min.compaction.lag.ms"`"0"`true`false`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("log.cleaner.min.compaction.lag.ms").setValue("0").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 312.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedBroker1Config2=createBrokerConfigData(baseUrl`clusterId`0`"offsets.topic.num.partitions"`"5"`false`true`ConfigSource.STATIC_BROKER_CONFIG`ImmutableList.of(ConfigSynonymData.builder().setName("offsets.topic.num.partitions").setValue("5").setSource(ConfigSource.STATIC_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("offsets.topic.num.partitions").setValue("50").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 447.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedBroker2Config1=createBrokerConfigData(baseUrl`clusterId`1`"num.network.threads"`"3"`true`false`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("num.network.threads").setValue("3").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 284.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedBroker2Config2=createBrokerConfigData(baseUrl`clusterId`1`"default.replication.factor"`"1"`false`true`ConfigSource.STATIC_BROKER_CONFIG`ImmutableList.of(ConfigSynonymData.builder().setName("default.replication.factor").setValue("1").setSource(ConfigSource.STATIC_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("default.replication.factor").setValue("1").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 440.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedBroker2Config3=createBrokerConfigData(baseUrl`clusterId`1`"queued.max.request.bytes"`"-1"`true`true`ConfigSource.DEFAULT_CONFIG`singletonList(ConfigSynonymData.builder().setName("queued.max.request.bytes").setValue("-1").setSource(ConfigSource.DEFAULT_CONFIG).build()));" is 295.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "assertEquals(2`responseBody.getValue().getData().stream().collect(Collectors.toMap(BrokerConfigData::getBrokerId`config -> config`(o`n) -> n)).size()`"Unexpected number of brokers in response");" is 194.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedBroker1Config1)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedBroker1Config1));" is 166.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedBroker1Config2)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedBroker1Config2));" is 166.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedBroker2Config1)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedBroker2Config1));" is 166.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedBroker2Config2)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedBroker2Config2));" is 166.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedBroker2Config3)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedBroker2Config3));" is 166.,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,listBrokersConfigs_existingBrokers_returnsConfigs,Magic Number,The method contains a magic number: 2,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,createBrokerConfigData,Long Parameter List,The method has 9 parameters. ,182
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllBrokersConfigsActionIntegrationTest,createBrokerConfigData,Long Statement,The length of the statement "return BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/"+ configName).setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config="+ configName).build()).setClusterId(clusterId).setBrokerId(brokerId).setName(configName).setValue(configValue).setDefault(isDefault).setReadOnly(isReadonly).setSensitive(false).setSource(source).setSynonyms(synonyms).build();" is 472.,182
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,ListAllReassignmentsActionIntegrationTest,Magic Number,The method contains a magic number: 6,39
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 2,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 100,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Long Statement,The length of the statement "Map<TopicPartition`Optional<NewPartitionReassignment>> reassignmentMap=createReassignment(Arrays.asList(3`4`5)`TOPIC_NAME`100);" is 127.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/-/partitions/-/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 136.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Long Statement,The length of the statement "assertEquals(data.getAddingReplicas()`reassignmentMap.get(new TopicPartition(TOPIC_NAME`data.getPartitionId())).get().targetReplicas());" is 136.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Magic Number,The method contains a magic number: 3,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Magic Number,The method contains a magic number: 4,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Magic Number,The method contains a magic number: 5,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_returnsReassignments,Magic Number,The method contains a magic number: 100,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ListAllReassignmentsActionIntegrationTest,listAllReassignments_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/-/partitions/-/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 125.,77
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,BrokersResourceIntegrationTest,Magic Number,The method contains a magic number: 3,38
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Long Statement,The length of the statement "ListBrokersResponse expected=ListBrokersResponse.create(BrokerDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers").build()).setData(Arrays.asList(BrokerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(0).id()).setResourceName("crn://" + "/kafka=" + clusterId + "/broker="+ nodes.get(0).id()).build()).setClusterId(clusterId).setBrokerId(nodes.get(0).id()).setHost(nodes.get(0).host()).setPort(nodes.get(0).port()).setRack(nodes.get(0).rack()).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(0).id()+ "/configs")).setPartitionReplicas(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(0).id()+ "/partition-replicas")).build()`BrokerData.builder().setMetadata(Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(1).id()).setResourceName("crn://" + "/kafka=" + clusterId + "/broker="+ nodes.get(1).id()).build()).setClusterId(clusterId).setBrokerId(nodes.get(1).id()).setHost(nodes.get(1).host()).setPort(nodes.get(1).port()).setRack(nodes.get(1).rack()).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(1).id()+ "/configs")).setPartitionReplicas(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(1).id()+ "/partition-replicas")).build()`BrokerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(2).id()).setResourceName("crn://" + "/kafka=" + clusterId + "/broker="+ nodes.get(2).id()).build()).setClusterId(clusterId).setBrokerId(nodes.get(2).id()).setHost(nodes.get(2).host()).setPort(nodes.get(2).port()).setRack(nodes.get(2).rack()).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(2).id()+ "/configs")).setPartitionReplicas(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(2).id()+ "/partition-replicas")).build())).build());" is 2173.,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,listBrokers_existingCluster_returnsBrokers,Magic Number,The method contains a magic number: 2,42
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,getBroker_existingClusterExistingBroker_returnsBroker,Long Statement,The length of the statement "GetBrokerResponse expected=GetBrokerResponse.create(BrokerData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(0).id()).setResourceName("crn://" + "/kafka=" + clusterId + "/broker="+ nodes.get(0).id()).build()).setClusterId(clusterId).setBrokerId(nodes.get(0).id()).setHost(nodes.get(0).host()).setPort(nodes.get(0).port()).setRack(nodes.get(0).rack()).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(0).id()+ "/configs")).setPartitionReplicas(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ nodes.get(0).id()+ "/partition-replicas")).build());" is 703.,188
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokersResourceIntegrationTest,getBroker_existingClusterExistingBroker_returnsBroker,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ nodes.get(0).id()).accept(MediaType.APPLICATION_JSON).get();" is 129.,188
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ group1+ "/lags").accept(MediaType.APPLICATION_JSON).get();" is 135.,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "ConsumerLagData consumerLagData=consumerLagDataList.getData().stream().filter(lagData -> lagData.getTopicName().equals(topics[finalT])).filter(lagData -> lagData.getPartitionId() == finalP).findAny().get();" is 206.,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "Response response2=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ group1+ "/lags").accept(MediaType.APPLICATION_JSON).get();" is 136.,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Long Statement,The length of the statement "ListConsumerLagsResponse expected=ListConsumerLagsResponse.create(ConsumerLagDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/"+ group1+ "/lags").build()).setData(Arrays.asList(expectedConsumerLagData(topic2`1`consumer2.groupMetadata().memberId()`"client-2"`3`6)`expectedConsumerLagData(topic1`0`consumer1.groupMetadata().memberId()`"client-1"`3`3)`expectedConsumerLagData(topic1`1`consumer1.groupMetadata().memberId()`"client-1"`0`0)`expectedConsumerLagData(topic2`0`consumer2.groupMetadata().memberId()`"client-2"`0`0))).build());" is 617.,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 3,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 3,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 5,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 5,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 5,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 5,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 3,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 6,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 3,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_returnsConsumerLags,Magic Number,The method contains a magic number: 3,74
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,listConsumerLags_nonExistingConsumerGroup_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ "foo"+ "/lags").accept(MediaType.APPLICATION_JSON).get();" is 134.,192
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ group1+ "/lags/"+ topics[finalT]+ "/partitions/"+ finalP).accept(MediaType.APPLICATION_JSON).get();" is 176.,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "Response response2=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ group1+ "/lags/"+ topic2+ "/partitions/"+ 1).accept(MediaType.APPLICATION_JSON).get();" is 164.,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Long Statement,The length of the statement "GetConsumerLagResponse expectedConsumerLagResponse=GetConsumerLagResponse.create(ConsumerLagData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/"+ group1+ "/lags/"+ topic2+ "/partitions/"+ 1).setResourceName("crn:///kafka=" + clusterId + "/consumer-group="+ group1+ "/lag="+ topic2+ "/partition="+ 1).build()).setClusterId(clusterId).setConsumerGroupId(group1).setTopicName(topic2).setPartitionId(1).setConsumerId(consumer.groupMetadata().memberId()).setClientId("client-1").setCurrentOffset(3L).setLogEndOffset(6L).setLag(3L).build());" is 604.,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 3,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 3,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 5,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 5,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 3L,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 6L,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_returnsConsumerLag,Magic Number,The method contains a magic number: 3L,209
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_nonExistingOffsets_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ group1+ "/lags/"+ topic1+ "/partitions/"+ 0).accept(MediaType.APPLICATION_JSON).get();" is 163.,319
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_nonExistingConsumerGroup_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/consumer-groups/"+ "foo"+ "/lags/"+ topic1+ "/partitions/"+ 0).accept(MediaType.APPLICATION_JSON).get();" is 162.,344
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,getConsumerLag_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + "foo" + "/consumer-groups/" + group1 + "/lags/"+ topic1+ "/partitions/"+ 0).accept(MediaType.APPLICATION_JSON).get();" is 161.,369
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,produce,Long Statement,The length of the statement "request("topics/" + topicName + "/partitions/"+ partitionId`Collections.emptyMap()).post(Entity.entity(request`Versions.KAFKA_V2_JSON_BINARY));" is 143.,403
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,expectedConsumerLagData,Long Parameter List,The method has 6 parameters. ,408
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ConsumerLagsResourceIntegrationTest,expectedConsumerLagData,Long Statement,The length of the statement "return ConsumerLagData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/consumer-groups/"+ group1+ "/lags/"+ topicName+ "/partitions/"+ partitionId).setResourceName("crn:///kafka=" + clusterId + "/consumer-group="+ group1+ "/lag="+ topicName+ "/partition="+ partitionId).build()).setClusterId(clusterId).setConsumerGroupId(group1).setTopicName(topicName).setPartitionId(partitionId).setConsumerId(consumerId).setClientId(clientId).setCurrentOffset(currentOffset).setLogEndOffset(logEndOffset).setLag(logEndOffset - currentOffset).build();" is 588.,408
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,GetReassignmentActionIntegrationTest,Magic Number,The method contains a magic number: 6,39
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 2,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,setUp,Magic Number,The method contains a magic number: 100,43
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Long Statement,The length of the statement "Map<TopicPartition`Optional<NewPartitionReassignment>> reassignmentMap=createReassignment(Arrays.asList(3`4`5)`TOPIC_NAME`100);" is 127.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/"+ PARTITION_ID+ "/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 168.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Long Statement,The length of the statement "assertEquals(actualReassignment.getValue().getAddingReplicas()`reassignmentMap.get(new TopicPartition(TOPIC_NAME`actualReassignment.getValue().getPartitionId())).get().targetReplicas());" is 186.,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Magic Number,The method contains a magic number: 3,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Magic Number,The method contains a magic number: 4,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Magic Number,The method contains a magic number: 5,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignment_returnsReassignment,Magic Number,The method contains a magic number: 100,50
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignments_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_NAME + "/partitions/"+ PARTITION_ID+ "/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 159.,82
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignments_nonExistingTopic_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/partitions/"+ PARTITION_ID+ "/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 158.,97
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,GetReassignmentActionIntegrationTest,getReassignments_nonExistingPartition_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_NAME+ "/partitions/10/reassignment").accept(MediaType.APPLICATION_JSON).get();" is 152.,113
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,TopicsResourceIntegrationTest,Magic Number,The method contains a magic number: 3,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,overrideBrokerProperties,Magic Number,The method contains a magic number: 2,65
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,listTopics_existingCluster_returnsTopics,Long Statement,The length of the statement "ListTopicsResponse expected=ListTopicsResponse.create(TopicDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics").build()).setData(Arrays.asList(TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1).setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1).build()).setClusterId(clusterId).setTopicName(TOPIC_1).setInternal(false).setReplicationFactor(1).setPartitionsCount(1).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build()`TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_2).setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_2).build()).setClusterId(clusterId).setTopicName(TOPIC_2).setInternal(false).setReplicationFactor(1).setPartitionsCount(1).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_2+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_2+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_2+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build()`TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_3).setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_3).build()).setClusterId(clusterId).setTopicName(TOPIC_3).setInternal(false).setReplicationFactor(1).setPartitionsCount(1).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_3+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_3+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_3+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build())).build());" is 2436.,72
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,getTopic_existingClusterExistingTopic_returnsTopic,Long Statement,The length of the statement "GetTopicResponse expected=GetTopicResponse.create(TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1).setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1).build()).setClusterId(clusterId).setTopicName(TOPIC_1).setInternal(false).setReplicationFactor(1).setPartitionsCount(1).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build());" is 787.,238
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_returnsCreatedTopic,Long Statement,The length of the statement "CreateTopicResponse expected=CreateTopicResponse.create(TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName).setResourceName("crn:///kafka=" + clusterId + "/topic="+ topicName).build()).setClusterId(clusterId).setTopicName(topicName).setInternal(false).setReplicationFactor(1).setPartitionsCount(0).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build());" is 805.,308
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_returnsCreatedTopic,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"topic_name\":\"" + topicName + "\"`\"partitions_count\":1`"+ "\"replication_factor\":1}"`MediaType.APPLICATION_JSON));" is 243.,308
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_returnsCreatedTopic,Long Statement,The length of the statement "testWithRetry(() -> assertTrue(getTopicNames().contains(topicName)`String.format("Topic names should contain %s after its creation"`topicName)));" is 145.,308
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_customReplicasAssignments_returnsCreatedTopic,Long Statement,The length of the statement "CreateTopicResponse expected=CreateTopicResponse.create(TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName).setResourceName("crn:///kafka=" + clusterId + "/topic="+ topicName).build()).setClusterId(clusterId).setTopicName(topicName).setInternal(false).setReplicationFactor(2).setPartitionsCount(0).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build());" is 805.,376
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_customReplicasAssignments_returnsCreatedTopic,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"topic_name\":\"" + topicName + "\"`\"replicas_assignments\":{\"0\":[1`2]` \"1\":[2`3]` \"2\":[3`1]}}"`MediaType.APPLICATION_JSON));" is 256.,376
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_customReplicasAssignments_returnsCreatedTopic,Long Statement,The length of the statement "testWithRetry(() -> assertTrue(getTopicNames().contains(topicName)`String.format("Topic names should contain %s after its creation"`topicName)));" is 145.,376
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingTopic_customReplicasAssignments_returnsCreatedTopic,Magic Number,The method contains a magic number: 2,376
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_existingTopic_returnsBadRequest,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"topic_name\":\"" + TOPIC_1 + "\"`\"partitions_count\":1`\\"+ "replication_factor\":1}"`MediaType.APPLICATION_JSON));" is 241.,443
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createTopic_nonExistingCluster_returnsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"topic_name\":\"topic-4\"`\"partitions_count\":1`\"replication_factor\":1}"`MediaType.APPLICATION_JSON));" is 218.,460
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,deleteTopic_existingTopic_deletesTopic,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1).accept(MediaType.APPLICATION_JSON).delete();" is 121.,472
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,deleteTopic_existingTopic_deletesTopic,Long Statement,The length of the statement "testWithRetry(() -> assertFalse(getTopicNames().contains(TOPIC_1)`String.format("Topic names should not contain %s after its deletion"`TOPIC_1)));" is 146.,472
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Identifier,The length of the identifier expectedExistingGetTopicResponse is 32.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Identifier,The length of the identifier actualExistingGetTopicResponse is 30.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Identifier,The length of the identifier expectedExistingGetTopicConfigResponse is 38.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Identifier,The length of the identifier existingGetTopicConfigResponse is 30.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "Response nonExistingGetTopicResponse=request("/v3/clusters/" + clusterId + "/topics/"+ topicName).accept(MediaType.APPLICATION_JSON).get();" is 139.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "CreateTopicResponse expectedCreateTopicResponse=CreateTopicResponse.create(TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName).setResourceName("crn:///kafka=" + clusterId + "/topic="+ topicName).build()).setClusterId(clusterId).setTopicName(topicName).setInternal(false).setReplicationFactor(0).setPartitionsCount(0).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build());" is 824.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "Response createTopicResponse=request("/v3/clusters/" + clusterId + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"topic_name\":\"" + topicName + "\"`\"partitions_count\":1`"+ "\"configs\":[{\"name\":\"cleanup.policy\"`\"value\":\"compact\"}]}"`MediaType.APPLICATION_JSON));" is 295.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "testWithRetry(() -> assertTrue(getTopicNames().contains(topicName)`String.format("Topic names should contain %s after its creation"`topicName)));" is 145.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "GetTopicResponse expectedExistingGetTopicResponse=GetTopicResponse.create(TopicData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName).setResourceName("crn:///kafka=" + clusterId + "/topic="+ topicName).build()).setClusterId(clusterId).setTopicName(topicName).setInternal(false).setReplicationFactor(2).setPartitionsCount(1).setPartitions(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions")).setConfigs(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/configs")).setPartitionReassignments(Resource.Relationship.create(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/partitions/-/reassignment")).setAuthorizedOperations(emptySet()).build());" is 823.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "Response existingTopicResponse=request("/v3/clusters/" + clusterId + "/topics/"+ topicName).accept(MediaType.APPLICATION_JSON).get();" is 133.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "GetTopicConfigResponse expectedExistingGetTopicConfigResponse=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ topicName+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ topicName+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(topicName).setName("cleanup.policy").setValue("compact").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("cleanup.policy").setValue("compact").setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).build()`ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 842.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "Response existingGetTopicConfigResponse=request("/v3/clusters/" + clusterId + "/topics/"+ topicName+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 169.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "GetTopicConfigResponse actualGetTopicConfigResponse=existingGetTopicConfigResponse.readEntity(GetTopicConfigResponse.class);" is 124.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "Response deleteTopicResponse=request("/v3/clusters/" + clusterId + "/topics/"+ topicName).accept(MediaType.APPLICATION_JSON).delete();" is 134.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "testWithRetry(() -> assertFalse(getTopicNames().contains(topicName)`String.format("Topic names should not contain %s after its deletion"`topicName)));" is 150.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Long Statement,The length of the statement "Response deletedGetTopicResponse=request("/v3/clusters/" + clusterId + "/topics/"+ topicName).accept(MediaType.APPLICATION_JSON).get();" is 135.,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicsResourceIntegrationTest,createAndDelete_nonExisting_returnsNotFoundCreatedAndNotFound,Magic Number,The method contains a magic number: 2,515
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,BrokerConfigsResourceIntegrationTest,Magic Number,The method contains a magic number: 3,40
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "ResourceCollection.Metadata expectedMetadata=ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs").build();" is 173.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedConfig1=BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/max.connections").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=max.connections").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("max.connections").setValue("2147483647").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("max.connections").setValue("2147483647").setSource(ConfigSource.DEFAULT_CONFIG).build())).build();" is 654.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedConfig2=BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("producer").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build();" is 654.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "BrokerConfigData expectedConfig3=BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/log.cleaner.threads").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=log.cleaner.threads").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("log.cleaner.threads").setValue("1").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("log.cleaner.threads").setValue("1").setSource(ConfigSource.DEFAULT_CONFIG).build())).build();" is 652.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs").accept(MediaType.APPLICATION_JSON).get();" is 132.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "assertTrue(actual.getValue().getData().contains(expectedConfig1)`String.format("Not true that `%s' contains `%s'."`actual.getValue().getData()`expectedConfig1));" is 161.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "assertTrue(actual.getValue().getData().contains(expectedConfig2)`String.format("Not true that `%s' contains `%s'."`actual.getValue().getData()`expectedConfig2));" is 161.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_existingBroker_returnsConfigs,Long Statement,The length of the statement "assertTrue(actual.getValue().getData().contains(expectedConfig3)`String.format("Not true that `%s' contains `%s'."`actual.getValue().getData()`expectedConfig3));" is 161.,44
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/foobar/configs").accept(MediaType.APPLICATION_JSON).get();" is 124.,183
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,listBrokerConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/brokers/" + brokerId + "/configs").accept(MediaType.APPLICATION_JSON).get();" is 123.,193
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,getBrokerConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "GetBrokerConfigResponse expected=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/max.connections").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=max.connections").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("max.connections").setValue("2147483647").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("max.connections").setValue("2147483647").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 686.,204
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,getBrokerConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/max.connections").accept(MediaType.APPLICATION_JSON).get();" is 148.,204
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,getBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/foobar").accept(MediaType.APPLICATION_JSON).get();" is 139.,256
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,getBrokerConfig_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/foobar/configs/max.connections").accept(MediaType.APPLICATION_JSON).get();" is 140.,268
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,getBrokerConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/brokers/" + brokerId + "/configs/max.connections").accept(MediaType.APPLICATION_JSON).get();" is 139.,279
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetBrokerConfigResponse expectedBeforeUpdate=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("producer").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 698.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseBeforeUpdate=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 161.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response updateResponse=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"gzip\"}"`MediaType.APPLICATION_JSON));" is 219.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetBrokerConfigResponse expectedAfterUpdate=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("gzip").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_BROKER_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("compression.type").setValue("gzip").setSource(ConfigSource.DYNAMIC_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 828.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseAfterUpdate=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 160.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response resetResponse=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).delete();" is 157.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetBrokerConfigResponse expectedAfterReset=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("producer").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 696.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseAfterReset=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 159.,289
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/foobar").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"producer\"}"`MediaType.APPLICATION_JSON));" is 207.,467
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateBrokerConfig_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/foobar/configs/compression.type").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"data\":{\"attributes\":{\"value\":\"producer\"}}}"`MediaType.APPLICATION_JSON));" is 237.,479
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateBrokerConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/brokers/" + brokerId + "/configs/compression.type").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"producer\"}"`MediaType.APPLICATION_JSON));" is 208.,493
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,updateBrokerConfig_nonExistingCluster_noContentType_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/brokers/" + brokerId + "/configs/compression.type").put(Entity.entity("{\"value\":\"producer\"}"`MediaType.APPLICATION_JSON));" is 173.,504
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,resetBrokerConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/foobar").accept(MediaType.APPLICATION_JSON).delete();" is 142.,514
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,resetBrokerConfig_nonExistingBroker_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/brokers/foobar/configs/compression.type").accept(MediaType.APPLICATION_JSON).delete();" is 144.,525
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,resetBrokerConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/brokers/" + brokerId + "/configs/compression.type").accept(MediaType.APPLICATION_JSON).delete();" is 143.,536
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response updateResponse=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs:alter").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"data\":[" + "{\"name\": \"max.connections\"`\"value\":\"1000\"}`" + "{\"name\": \"compression.type\"`\"value\":\"gzip\"}]}"`MediaType.APPLICATION_JSON));" is 314.,556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "GetBrokerConfigResponse expectedAfterUpdate1=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/max.connections").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=max.connections").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("max.connections").setValue("1000").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_BROKER_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("max.connections").setValue("1000").setSource(ConfigSource.DYNAMIC_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("max.connections").setValue("2147483647").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 826.,556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "GetBrokerConfigResponse expectedAfterUpdate2=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("gzip").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_BROKER_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("compression.type").setValue("gzip").setSource(ConfigSource.DYNAMIC_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 829.,556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate1=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/max.connections").accept(MediaType.APPLICATION_JSON).get();" is 160.,556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,BrokerConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate2=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 161.,556
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,ClusterConfigsResourceIntegrationTest,Magic Number,The method contains a magic number: 3,40
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,getClusterConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/broker-configs/foobar").accept(MediaType.APPLICATION_JSON).get();" is 123.,51
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,getClusterConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/broker-configs/max.connections").accept(MediaType.APPLICATION_JSON).get();" is 121.,62
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseBeforeUpdate=request("/v3/clusters/" + clusterId + "/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 145.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetBrokerConfigResponse expectedBrokerBeforeUpdate=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("producer").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 704.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response brokerResponseBeforeUpdate=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 167.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response updateResponse=request("/v3/clusters/" + clusterId + "/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"gzip\"}"`MediaType.APPLICATION_JSON));" is 203.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetClusterConfigResponse expectedAfterUpdate=GetClusterConfigResponse.create(ClusterConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/broker-configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker-config=compression.type").build()).setClusterId(clusterId).setConfigType(ClusterConfig.Type.BROKER).setName("compression.type").setValue("gzip").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("gzip").setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).build())).build());" is 711.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseAfterUpdate=request("/v3/clusters/" + clusterId + "/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 144.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetBrokerConfigResponse expectedBrokerAfterUpdate=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("gzip").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("compression.type").setValue("gzip").setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 850.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseBrokerAfterUpdate=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 166.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response resetResponse=request("/v3/clusters/" + clusterId + "/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).delete();" is 141.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response responseAfterReset=request("/v3/clusters/" + clusterId + "/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 143.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "GetBrokerConfigResponse expectedBrokerAfterReset=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("producer").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 702.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateAndReset_existingConfig_returnsDefaultUpdatedAndDefaultAgain,Long Statement,The length of the statement "Response brokerResponseAfterReset=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 165.,71
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,updateClusterConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"producer\"}"`MediaType.APPLICATION_JSON));" is 190.,299
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,resetClusterConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/broker-configs/compression.type").accept(MediaType.APPLICATION_JSON).delete();" is 125.,308
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response updateResponse=request("/v3/clusters/" + clusterId + "/broker-configs:alter").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"data\":[" + "{\"name\": \"max.connections\"`\"value\":\"1000\"}`" + "{\"name\": \"compression.type\"`\"value\":\"gzip\"}]}"`MediaType.APPLICATION_JSON));" is 298.,317
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "GetBrokerConfigResponse expectedAfterUpdate1=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/max.connections").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=max.connections").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("max.connections").setValue("1000").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("max.connections").setValue("1000").setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("max.connections").setValue("2147483647").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 842.,317
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "GetBrokerConfigResponse expectedAfterUpdate2=GetBrokerConfigResponse.create(BrokerConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/brokers/"+ brokerId+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/broker="+ brokerId+ "/config=compression.type").build()).setClusterId(clusterId).setBrokerId(brokerId).setName("compression.type").setValue("gzip").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("compression.type").setValue("gzip").setSource(ConfigSource.DYNAMIC_DEFAULT_BROKER_CONFIG).build()`ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 845.,317
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate1=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/max.connections").accept(MediaType.APPLICATION_JSON).get();" is 160.,317
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,ClusterConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate2=request("/v3/clusters/" + clusterId + "/brokers/"+ brokerId+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 161.,317
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "ResourceCollection.Metadata expectedMetadata=ResourceCollection.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs").build();" is 171.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedConfig1=TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("cleanup.policy").setValue("delete").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build();" is 640.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedConfig2=TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=compression.type").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("compression.type").setValue("producer").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build();" is 648.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "TopicConfigData expectedConfig3=TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/delete.retention.ms").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=delete.retention.ms").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("delete.retention.ms").setValue("86400000").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("log.cleaner.delete.retention.ms").setValue("86400000").setSource(ConfigSource.DEFAULT_CONFIG).build())).build();" is 672.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs").accept(MediaType.APPLICATION_JSON).get();" is 130.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedConfig1)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedConfig1));" is 152.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedConfig2)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedConfig2));" is 152.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_existingTopic_returnsConfigs,Long Statement,The length of the statement "assertTrue(responseBody.getValue().getData().contains(expectedConfig3)`String.format("Not true that `%s' contains `%s'."`responseBody`expectedConfig3));" is 152.,55
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_nonExistingTopic_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/configs").accept(MediaType.APPLICATION_JSON).get();" is 123.,186
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,listTopicConfigs_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_1 + "/configs").accept(MediaType.APPLICATION_JSON).get();" is 121.,197
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getTopicConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "GetTopicConfigResponse expected=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("cleanup.policy").setValue("delete").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 671.,206
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getTopicConfig_existingConfig_returnsConfig,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 145.,206
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/foobar").accept(MediaType.APPLICATION_JSON).get();" is 137.,257
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getTopicConfig_nonExistingTopic_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 138.,268
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getTopicConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_1 + "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 136.,279
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "GetTopicConfigResponse expectedBeforeUpdate=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("cleanup.policy").setValue("delete").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 683.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "Response responseBeforeUpdate=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 157.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "Response updateResponse=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"compact\"}"`MediaType.APPLICATION_JSON));" is 218.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "GetTopicConfigResponse expectedAfterUpdate=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("cleanup.policy").setValue("compact").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("cleanup.policy").setValue("compact").setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).build()`ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 817.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 156.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "Response resetResponse=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).delete();" is 153.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "GetTopicConfigResponse expectedAfterReset=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("cleanup.policy").setValue("delete").setDefault(true).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DEFAULT_CONFIG).setSynonyms(singletonList(ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 681.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,getUpdateReset_withExistingConfig,Long Statement,The length of the statement "Response responseAfterReset=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 155.,288
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,updateTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/foobar").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"compact\"}"`MediaType.APPLICATION_JSON));" is 204.,466
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,updateTopicConfig_nonExistingTopic_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"compact\"}"`MediaType.APPLICATION_JSON));" is 205.,477
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,updateTopicConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_1 + "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).put(Entity.entity("{\"value\":\"compact\"}"`MediaType.APPLICATION_JSON));" is 203.,488
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,updateTopicConfig_nonExistingCluster_noContentType_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_1 + "/configs/cleanup.policy").put(Entity.entity("{\"value\":\"compact\"}"`MediaType.APPLICATION_JSON));" is 168.,497
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,resetTopicConfig_nonExistingConfig_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/foobar").accept(MediaType.APPLICATION_JSON).delete();" is 140.,505
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,resetTopicConfig_nonExistingTopic_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/" + clusterId + "/topics/foobar/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).delete();" is 141.,516
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,resetTopicConfig_nonExistingCluster_throwsNotFound,Long Statement,The length of the statement "Response response=request("/v3/clusters/foobar/topics/" + TOPIC_1 + "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).delete();" is 139.,527
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response updateResponse=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs:alter").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"data\":[" + "{\"name\": \"cleanup.policy\"`\"value\":\"compact\"}`" + "{\"name\": \"compression.type\"`\"value\":\"gzip\"}]}"`MediaType.APPLICATION_JSON));" is 314.,543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "GetTopicConfigResponse expectedAfterUpdate1=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=cleanup.policy").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("cleanup.policy").setValue("compact").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("cleanup.policy").setValue("compact").setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).build()`ConfigSynonymData.builder().setName("log.cleanup.policy").setValue("delete").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 818.,543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "GetTopicConfigResponse expectedAfterUpdate2=GetTopicConfigResponse.create(TopicConfigData.builder().setMetadata(Resource.Metadata.builder().setSelf(baseUrl + "/v3/clusters/" + clusterId+ "/topics/"+ TOPIC_1+ "/configs/compression.type").setResourceName("crn:///kafka=" + clusterId + "/topic="+ TOPIC_1+ "/config=compression.type").build()).setClusterId(clusterId).setTopicName(TOPIC_1).setName("compression.type").setValue("gzip").setDefault(false).setReadOnly(false).setSensitive(false).setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).setSynonyms(Arrays.asList(ConfigSynonymData.builder().setName("compression.type").setValue("gzip").setSource(ConfigSource.DYNAMIC_TOPIC_CONFIG).build()`ConfigSynonymData.builder().setName("compression.type").setValue("producer").setSource(ConfigSource.DEFAULT_CONFIG).build())).build());" is 820.,543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate1=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/cleanup.policy").accept(MediaType.APPLICATION_JSON).get();" is 157.,543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,TopicConfigsResourceIntegrationTest,alterConfigBatch_withExistingConfig,Long Statement,The length of the statement "Response responseAfterUpdate2=request("/v3/clusters/" + clusterId + "/topics/"+ TOPIC_1+ "/configs/compression.type").accept(MediaType.APPLICATION_JSON).get();" is 159.,543
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,AclsResourceIntegrationTest,Magic Number,The method contains a magic number: 3,72
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,overrideBrokerProperties,Long Statement,The length of the statement "props.put("listener.name.sasl_plaintext.plain.sasl.jaas.config"`"org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"kafka\" " + "password=\"kafka\" "+ "user_kafka=\"kafka\" "+ "user_kafkarest=\"kafkarest\" "+ "user_alice=\"alice\" "+ "user_bob=\"bob\";");" is 285.,81
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,overrideKafkaRestConfigs,Long Statement,The length of the statement "props.put("client.sasl.jaas.config"`"org.apache.kafka.common.security.plain.PlainLoginModule required " + "username=\"kafkarest\" " + "password=\"kafkarest\";");" is 161.,99
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,setUp,Long Statement,The length of the statement "expectedAliceUrl=restConnect + baseAclUrl + "?resource_type=TOPIC"+ "&resource_name=*"+ "&pattern_type=LITERAL"+ "&principal=User%3Aalice"+ "&host=*"+ "&operation=READ"+ "&permission=ALLOW";" is 190.,110
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,setUp,Long Statement,The length of the statement "expectedBobUrl=restConnect + baseAclUrl + "?resource_type=TOPIC"+ "&resource_name=topic-"+ "&pattern_type=PREFIXED"+ "&principal=User%3Abob"+ "&host=1.2.3.4"+ "&operation=WRITE"+ "&permission=ALLOW";" is 199.,110
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,setUp,Long Statement,The length of the statement "expectedSearchUrl=restConnect + baseAclUrl + "?resource_type=TOPIC"+ "&resource_name=topic-1"+ "&pattern_type=MATCH"+ "&principal="+ "&host="+ "&operation=ANY"+ "&permission=ANY";" is 179.,110
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Identifier,The length of the identifier expectedPreCreateSearchResponse is 31.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Identifier,The length of the identifier expectedPostCreateSearchResponse is 32.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Identifier,The length of the identifier actualPostCreateSearchResponse is 30.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Statement,The length of the statement "SearchAclsResponse expectedPreCreateSearchResponse=SearchAclsResponse.create(AclDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(expectedSearchUrl).build()).setData(emptyList()).build());" is 215.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Statement,The length of the statement "Response actualPreCreateSearchResponse=request(baseAclUrl`ImmutableMap.of("resource_type"`"topic"`"resource_name"`"topic-1"`"pattern_type"`"match")).accept(MediaType.APPLICATION_JSON).get();" is 190.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Statement,The length of the statement "Response actualCreateAliceResponse=request(baseAclUrl).post(Entity.entity(CreateAclRequest.builder().setResourceType(Acl.ResourceType.TOPIC).setResourceName("*").setPatternType(Acl.PatternType.LITERAL).setPrincipal("User:alice").setHost("*").setOperation(Acl.Operation.READ).setPermission(Acl.Permission.ALLOW).build()`MediaType.APPLICATION_JSON));" is 348.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Statement,The length of the statement "Response actualCreateBobResponse=request(baseAclUrl).post(Entity.entity(CreateAclRequest.builder().setResourceType(Acl.ResourceType.TOPIC).setResourceName("topic-").setPatternType(Acl.PatternType.PREFIXED).setPrincipal("User:bob").setHost("1.2.3.4").setOperation(Acl.Operation.WRITE).setPermission(Acl.Permission.ALLOW).build()`MediaType.APPLICATION_JSON));" is 357.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Statement,The length of the statement "SearchAclsResponse expectedPostCreateSearchResponse=SearchAclsResponse.create(AclDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(expectedSearchUrl).build()).setData(Arrays.asList(ALICE_ACL_DATA.setMetadata(Resource.Metadata.builder().setSelf(expectedAliceUrl).build()).setClusterId(clusterId).build()`BOB_ACL_DATA.setMetadata(Resource.Metadata.builder().setSelf(expectedBobUrl).build()).setClusterId(clusterId).build())).build());" is 459.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,createAliceAndBobAcls,Long Statement,The length of the statement "Response actualPostCreateSearchResponse=request(baseAclUrl`ImmutableMap.of("resource_type"`"topic"`"resource_name"`"topic-1"`"pattern_type"`"match")).accept(MediaType.APPLICATION_JSON).get();" is 191.,148
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Identifier,The length of the identifier expectedPostDeleteSearchResponse is 32.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Identifier,The length of the identifier actualPostDeleteSearchResponse is 30.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Statement,The length of the statement "DeleteAclsResponse expectedDeleteAliceResponse=DeleteAclsResponse.create(singletonList(ALICE_ACL_DATA.setMetadata(Resource.Metadata.builder().setSelf(expectedAliceUrl).build()).setClusterId(clusterId).build()));" is 211.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Statement,The length of the statement "Response actualDeleteAliceResponse=webClient.target(expectedAliceUrl).request().accept(MediaType.APPLICATION_JSON).delete();" is 124.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Statement,The length of the statement "DeleteAclsResponse expectedDeleteBobResponse=DeleteAclsResponse.create(singletonList(BOB_ACL_DATA.setMetadata(Resource.Metadata.builder().setSelf(expectedBobUrl).build()).setClusterId(clusterId).build()));" is 205.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Statement,The length of the statement "SearchAclsResponse expectedPostDeleteSearchResponse=SearchAclsResponse.create(AclDataList.builder().setMetadata(ResourceCollection.Metadata.builder().setSelf(expectedSearchUrl).build()).setData(emptyList()).build());" is 216.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndSeparateDelete,Long Statement,The length of the statement "Response actualPostDeleteSearchResponse=request(baseAclUrl`ImmutableMap.of("resource_type"`"topic"`"resource_name"`"topic-1"`"pattern_type"`"match")).accept(MediaType.APPLICATION_JSON).get();" is 191.,239
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndMultiDelete,Long Statement,The length of the statement "Response multiDeleteNoParamsResponse=webClient.target(restConnect + baseAclUrl).request().accept(MediaType.APPLICATION_JSON).delete();" is 134.,297
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndMultiDelete,Long Statement,The length of the statement "DeleteAclsResponse expectedMultiDeleteResponse=DeleteAclsResponse.create(ImmutableList.of(ALICE_ACL_DATA.setMetadata(Resource.Metadata.builder().setSelf(expectedAliceUrl).build()).setClusterId(clusterId).build()`BOB_ACL_DATA.setMetadata(Resource.Metadata.builder().setSelf(expectedBobUrl).build()).setClusterId(clusterId).build()));" is 332.,297
confluentinc_kafka-rest,io.confluent.kafkarest.integration.v3,AclsResourceIntegrationTest,testCreateSearchAndMultiDelete,Long Statement,The length of the statement "Response multiDeleteResourceTypeAll=webClient.target(expectedSearchUrl).request().accept(MediaType.APPLICATION_JSON).delete();" is 126.,297
confluentinc_kafka-rest,io.confluent.kafkarest.integration.accesslist,ResourceAccesslistTestBase,ResourceAccesslistTestBase,Magic Number,The method contains a magic number: 3,28
confluentinc_kafka-rest,io.confluent.kafkarest.integration.accesslist,ResourceAccesslistTestBase,createTopic,Long Statement,The length of the statement "return request("/v3/clusters/" + getClusterId() + "/topics").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"topic_name\":\"" + TOPIC_1 + "\"`\"partitions_count\":3`\"replication_factor\":3}"`MediaType.APPLICATION_JSON));" is 231.,52
confluentinc_kafka-rest,io.confluent.kafkarest.integration.accesslist,ResourceAccesslistTestBase,updateClusterConfig,Long Statement,The length of the statement "return request("/v3/clusters/" + getClusterId() + "/broker-configs:alter").accept(MediaType.APPLICATION_JSON).post(Entity.entity("{\"data\":[" + "{\"name\": \"max.connections\"`\"value\":\"1000\"}`" + "{\"name\": \"compression.type\"`\"value\":\"gzip\"}]}"`MediaType.APPLICATION_JSON));" is 286.,95
confluentinc_kafka-rest,io.confluent.kafkarest.integration.accesslist,ResourceDiscoverabilityTest,overrideKafkaRestConfigs,Long Statement,The length of the statement "restProperties.put(KafkaRestConfig.KAFKA_REST_RESOURCE_EXTENSION_CONFIG`Collections.singletonList(NoAuthExtension.class));" is 122.,55
confluentinc_kafka-rest,io.confluent.kafkarest.unit,JsonSchemaConverterTest,testPrimitiveTypesToJson,Magic Number,The method contains a magic number: 0.1f,29
confluentinc_kafka-rest,io.confluent.kafkarest.unit,JsonSchemaConverterTest,testPrimitiveTypesToJson,Magic Number,The method contains a magic number: 0.1,29
confluentinc_kafka-rest,io.confluent.kafkarest.unit,JsonSchemaConverterTest,testRecordToJson,Long Statement,The length of the statement "String json="{\n" + " \"null\": null`\n" + " \"boolean\": true`\n"+ " \"number\": 12`\n"+ " \"string\": \"string\"\n"+ "}";" is 123.,57
confluentinc_kafka-rest,io.confluent.kafkarest.unit,JsonSchemaConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 12,57
confluentinc_kafka-rest,io.confluent.kafkarest.unit,JsonSchemaConverterTest,testArrayToJson,Magic Number,The method contains a magic number: 3,79
confluentinc_kafka-rest,io.confluent.kafkarest.unit,JsonSchemaConverterTest,testArrayToJson,Magic Number,The method contains a magic number: 2,79
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 800.25,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 23.4f,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 64L,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 64L,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 64L,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 64L,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 64L,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 800.25,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 0.01,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 23.4f,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 0.1,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 32,92
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testArrayToJson,Magic Number,The method contains a magic number: 3,163
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testArrayToJson,Magic Number,The method contains a magic number: 2,163
confluentinc_kafka-rest,io.confluent.kafkarest.unit,ProtobufConverterTest,testMapToJson,Magic Number,The method contains a magic number: 2,181
confluentinc_kafka-rest,io.confluent.kafkarest.unit,UriUtilsTest,testAbsoluteUriBuilderWithPort,Magic Number,The method contains a magic number: 5000,62
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testPrimitiveTypesToJson,Magic Number,The method contains a magic number: 0.1f,87
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testPrimitiveTypesToJson,Magic Number,The method contains a magic number: 0.1,87
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Long Statement,The length of the statement "GenericRecord data=new GenericRecordBuilder(recordSchema).set("null"`null).set("boolean"`true).set("int"`12).set("long"`5000000000L).set("float"`23.4f).set("double"`800.25).set("bytes"`ByteBuffer.wrap("bytes".getBytes())).set("string"`"string").build();" is 253.,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 12,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 5000000000L,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 23.4f,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 800.25,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 12,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 5000000000L,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 23.4f,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 0.1,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 800.25,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testRecordToJson,Magic Number,The method contains a magic number: 0.01,126
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testArrayToJson,Magic Number,The method contains a magic number: 3,162
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testArrayToJson,Magic Number,The method contains a magic number: 2,162
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,testMapToJson,Magic Number,The method contains a magic number: 2,176
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,expectConversionException,Empty catch clause,The method has an empty catch block.,201
confluentinc_kafka-rest,io.confluent.kafkarest.unit,AvroConverterTest,expectConversionException,Long Statement,The length of the statement "fail("Expected conversion of " + (obj == null ? "null" : (obj.toString() + " (" + obj.getClass().getName()+ ")")) + " to fail");" is 128.,201
confluentinc_kafka-rest,io.confluent.kafkarest.unit,DefaultKafkaRestContextTest,testGetKafkaConsumerManagerThreadSafety,Magic Number,The method contains a magic number: 100,37
confluentinc_kafka-rest,io.confluent.kafkarest.unit,DefaultKafkaRestContextTest,testGetKafkaConsumerManagerThreadSafety,Magic Number,The method contains a magic number: 100,37
confluentinc_kafka-rest,io.confluent.kafkarest.unit,DefaultKafkaRestContextTest,testGetKafkaConsumerManagerThreadSafety,Magic Number,The method contains a magic number: 60,37
