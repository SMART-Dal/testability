Project Name,Package Name,Type Name,Method Name,Implementation Smell,Cause of the Smell,Method start line no
LucidWorks_spark-solr,com.lucidworks.spark,ShardIndexPartitioner,getPartition,Long Statement,The length of the statement "if (!(docId instanceof String)) throw new IllegalArgumentException("Only String document IDs are supported by this Partitioner!");" is 130.,52
LucidWorks_spark-solr,com.lucidworks.spark,ShardIndexPartitioner,getShardIndex,Magic Number,The method contains a magic number: 20,73
LucidWorks_spark-solr,com.lucidworks.spark,ShardIndexPartitioner,getDocCollection,Long Statement,The length of the statement "if (docRouter instanceof ImplicitDocRouter) throw new IllegalStateException("Implicit document routing not supported by this Partitioner!");" is 140.,92
LucidWorks_spark-solr,com.lucidworks.spark,ShardIndexPartitioner,getDocCollection,Long Statement,The length of the statement "if (shards == null || shards.size() == 0) throw new IllegalStateException("Collection '" + collection + "' does not have any shards!");" is 135.,92
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,main,Complex Conditional,The conditional expression args == null || args.length == 0 || args[0] == null || args[0].trim().length() == 0 is complex.,107
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,main,Long Statement,The length of the statement "System.err.println("Invalid command-line args! Must pass the name of a processor to run.\n" + "Supported processors:\n");" is 121.,107
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,setupSolrAuthenticationProps,Long Identifier,The length of the field sparkExecutorExtraJavaOptionsParam is 34.,158
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,setupSolrAuthenticationProps,Long Statement,The length of the statement "String solrJaasOpts=String.format(Locale.ROOT`"-D%s=%s -Dsolr.kerberos.jaas.appname=%s"`LOGIN_CONFIG_PROP`solrJaasAuthConfig`solrJaasAppName);" is 142.,158
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,setupSolrAuthenticationProps,Long Statement,The length of the statement "String sparkExecutorExtraJavaOptions=sparkConf.contains(sparkExecutorExtraJavaOptionsParam) ? sparkConf.get(sparkExecutorExtraJavaOptionsParam) : null;" is 151.,158
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,getCommonOptions,Long Statement,The length of the statement "return new Option[]{Option.builder().hasArg().required(false).desc("Batch interval (seconds) for streaming applications; default is 1 second").longOpt("batchInterval").build()`Option.builder().hasArg().required(false).desc("The master URL to connect to` such as \"local\" to run locally with one thread` \"local[4]\" to run locally with 4 cores` or \"spark://master:7077\" to run on a Spark standalone cluster.").longOpt("master").build()`Option.builder().hasArg().required(false).desc("Address of the Zookeeper ensemble; defaults to: localhost:9983").longOpt("zkHost").build()`Option.builder().hasArg().required(false).desc("Name of collection; no default").longOpt("collection").build()`Option.builder().hasArg().required(false).desc("Number of docs to queue up on the client before sending to Solr; default is 10").longOpt("batchSize").build()`Option.builder().hasArg().required(false).desc("For authenticating to Solr using JAAS` sets the '" + LOGIN_CONFIG_PROP + "' system property.").longOpt("solrJaasAuthConfig").build()`Option.builder().hasArg().required(false).desc("For authenticating to Solr using JAAS` sets the 'solr.kerberos.jaas.appname' system property; default is Client").longOpt("solrJaasAppName").build()};" is 1226.,181
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,newProcessor,Complex Method,Cyclomatic complexity of the method is 12,232
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,newProcessor,Long Statement,The length of the statement "System.err.println("\n\n " + streamProcType + " not supported! Please check your command-line arguments and re-try. \n\n");" is 123.,232
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,processCommandLineArgs,Complex Method,Cyclomatic complexity of the method is 8,320
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,findClasses,Complex Method,Cyclomatic complexity of the method is 10,391
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,assertSerializable,Long Statement,The length of the statement "throw new IllegalArgumentException("Object of type [" + obj.getClass().getName() + "] is not Serializable due to: "+ exc);" is 122.,427
LucidWorks_spark-solr,com.lucidworks.spark,SparkApp,ser2bytes,Empty catch clause,The method has an empty catch block.,445
LucidWorks_spark-solr,com.lucidworks.spark,StreamProcessorTestBase,setupSparkStreamingContext,Magic Number,The method contains a magic number: 500,18
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,readSolrXml,Empty catch clause,The method has an empty catch block.,51
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,stopCluster,Long Statement,The length of the statement "log.error("No CloudSolrClient available for this test! " + "Typically this means there was a failure to start the MiniSolrCloudCluster` check logs for more details.");" is 167.,100
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,stopCluster,Long Statement,The length of the statement "log.error("No MiniSolrCloudCluster available for this test! " + "Typically this means there was a failure to start the MiniSolrCloudCluster` check logs for more details.");" is 172.,100
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,createCollection,Long Parameter List,The method has 5 parameters. ,132
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,createCollection,Long Parameter List,The method has 6 parameters. ,136
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,createCollection,Magic Number,The method contains a magic number: 20,136
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Complex Method,Cyclomatic complexity of the method is 8,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Long Statement,The length of the statement "log.info("Found " + replicas.size() + " replicas and leader on "+ leader.getNodeName()+ " for "+ shardId+ " in "+ testCollectionName);" is 134.,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Long Statement,The length of the statement "if (!allReplicasUp) fail("Didn't see all replicas for " + testCollectionName + " come up within "+ maxWaitMs+ " ms! ClusterState: "+ printClusterStateInfo(testCollectionName));" is 176.,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Magic Number,The method contains a magic number: 1000L,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Magic Number,The method contains a magic number: 2000,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Magic Number,The method contains a magic number: 500L,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,ensureAllReplicasAreActive,Magic Number,The method contains a magic number: 500L,165
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,printClusterStateInfo,Magic Number,The method contains a magic number: 2,224
LucidWorks_spark-solr,com.lucidworks.spark,TestSolrCloudClusterSupport,dumpSolrCollection,Magic Number,The method contains a magic number: 100,241
LucidWorks_spark-solr,com.lucidworks.spark,SolrSqlTest,testSQLQueries,Magic Number,The method contains a magic number: 2,19
LucidWorks_spark-solr,com.lucidworks.spark,SolrSqlTest,testSQLQueries,Magic Number,The method contains a magic number: 1000,19
LucidWorks_spark-solr,com.lucidworks.spark,SolrSqlTest,testSQLQueries,Magic Number,The method contains a magic number: 21,19
LucidWorks_spark-solr,com.lucidworks.spark,SolrSqlTest,testSQLQueries,Magic Number,The method contains a magic number: 21,19
LucidWorks_spark-solr,com.lucidworks.spark,SolrSqlTest,testSQLQueries,Magic Number,The method contains a magic number: 567,19
LucidWorks_spark-solr,com.lucidworks.spark,SolrSqlTest,testSQLQueries,Magic Number,The method contains a magic number: 1000,19
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testSampleIndex,Magic Number,The method contains a magic number: 3,30
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testSampleIndex,Magic Number,The method contains a magic number: 100,30
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testSampleIndex,Magic Number,The method contains a magic number: 8,30
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testSampleIndex,Magic Number,The method contains a magic number: 12,30
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testMultiValuedExport,Long Statement,The length of the statement "Dataset df=sparkSession.read().format(Constants.SOLR_FORMAT()).options(options).option(ConfigurationConstants.SOLR_FIELD_PARAM()`"out_clicks_ss").load();" is 153.,58
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testMultiValuedExport,Magic Number,The method contains a magic number: 5,58
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testMultiValuedExport,Magic Number,The method contains a magic number: 100,58
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testIndexOneusagovDataFrame,Magic Number,The method contains a magic number: 1000,97
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,call,Magic Number,The method contains a magic number: 1000,106
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFlattenMultivalued,Magic Number,The method contains a magic number: 100,127
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFlattenMultivalued,Magic Number,The method contains a magic number: 2,127
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testEventsDataFrame,Long Statement,The length of the statement "eventsDF=eventsDF.select("id"`"count_l"`"doc_id_s"`"flag_s"`"session_id_s"`"type_s"`"tz_timestamp_txt"`"user_id_s"`"`params.title_s`");" is 135.,218
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testEventsDataFrame,Magic Number,The method contains a magic number: 2,218
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testAggDataFrame,Long Statement,The length of the statement "aggDF=aggDF.select("id"`"aggr_count_l"`"aggr_id_s"`"aggr_job_id_s"`"aggr_type_s"`"co_occurring_docIds_counts_ls"`"co_occurring_docIds_ss"`"entity_id_s"`"entity_type_s"`"flag_s"`"grouping_key_s"`"in_session_ids_counts_ls"`"in_session_ids_ss"`"in_user_id_s"`"in_user_id_s_counts_ls"`"in_user_ids_counts_ls"`"in_user_ids_ss"`"out_clicks_counts_ls"`"out_clicks_ss"`"out_session_ids_counts_ls"`"out_session_ids_ss");" is 411.,251
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testMVDateHandling,Long Statement,The length of the statement "String[] testData=new String[]{"1`a`x`1000`[a;x]`[1000]`[2016-01-02T03:04:05.006Z`2016-02-02T03:04:05.006Z]"`"2`b`y`2000`[b;y]`[2000]`[2016-01-02T03:04:05.006Z`2016-02-02T03:04:05.006Z]"`"3`c`z`3000`[c;z]`[3000]`[2016-01-02T03:04:05.006Z`2016-02-02T03:04:05.006Z]"`"4`a`x`4000`[a;x]`[4000]`[2016-01-02T03:04:05.006Z`2016-02-02T03:04:05.006Z]"};" is 344.,278
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testMVDateHandling,Magic Number,The method contains a magic number: 100,278
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testMVDateHandling,Magic Number,The method contains a magic number: 4,278
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Long Statement,The length of the statement "String[] testData=new String[]{"1`a`x`1000`[a;x]`[1000]"`"2`b`y`2000`[b;y]`[2000]"`"3`c`z`3000`[c;z]`[3000]"`"4`a`x`4000`[a;x]`[4000]"};" is 136.,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 3000,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 3000,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2000,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 1000,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2000,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2000,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 4,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 4,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 2,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,testFilterSupport,Magic Number,The method contains a magic number: 4,313
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateDataFrameStoreLoad,Long Statement,The length of the statement "assertTrue("expected " + col + " in Solr DataFrame` but only found: "+ solrCols+ "` source cols: "+ Arrays.asList(cols)`solrCols.contains(col));" is 144.,422
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateDataFrameStoreLoad,Long Statement,The length of the statement "assertTrue("Expected " + testData.size() + " docs from Solr` but found: "+ actualEvents`actualEvents == testData.size());" is 121.,422
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateDataFrameStoreLoad,Magic Number,The method contains a magic number: 100,422
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateSchema,Complex Method,Cyclomatic complexity of the method is 8,484
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateSchema,Long Statement,The length of the statement "assertEquals("Field '" + fieldName + "' should be a string but has type '"+ type+ "' instead!"`"string"`type.typeName());" is 121.,484
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateSchema,Long Statement,The length of the statement "assertEquals("Field '" + fieldName + "' should be an integer but has type '"+ type+ "' instead!"`"long"`type.typeName());" is 121.,484
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateSchema,Long Statement,The length of the statement "assertEquals("Field '" + fieldName + "' should have a string element type but has '"+ arrayType.elementType()+ "' instead!"`"string"`arrayType.elementType().typeName());" is 169.,484
LucidWorks_spark-solr,com.lucidworks.spark,SolrRelationTest,validateSchema,Long Statement,The length of the statement "assertEquals("Field '" + fieldName + "' should have an integer element type but has '"+ arrayType.elementType()+ "' instead!"`"long"`arrayType.elementType().typeName());" is 169.,484
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,setupSparkSession,Long Statement,The length of the statement "sparkSession=SparkSession.builder().appName("test").master("local").config("spark.ui.enabled"`"false").config("spark.default.parallelism"`"1").getOrCreate();" is 157.,35
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,buildCollection,Long Statement,The length of the statement "String[] inputDocs=new String[]{collection + "-1`foo`bar`1`[a;b]`[1;2]"`collection + "-2`foo`baz`2`[c;d]`[3;4]"`collection + "-3`bar`baz`3`[e;f]`[5;6]"};" is 153.,56
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,buildCollection,Magic Number,The method contains a magic number: 2,56
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,buildCollection,Magic Number,The method contains a magic number: 2,65
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,buildCollection,Long Statement,The length of the statement "assertTrue("expected " + numDocsIndexed + " docs in query results from "+ collection+ "` but got "+ numFound`numFound == (long)numDocsIndexed);" is 143.,76
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Long Statement,The length of the statement "if (fields.length < 6) throw new IllegalArgumentException("Each test input doc should have at least 6 fields! invalid doc: " + row);" is 132.,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 6,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 2,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 3,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 4,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 4,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 5,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 5,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 6,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 6,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,indexDocs,Magic Number,The method contains a magic number: 6,95
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Long Statement,The length of the statement "if (fields.length < 6) throw new IllegalArgumentException("Each test input doc should have at least 6 fields! invalid doc: " + row);" is 132.,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 6,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 2,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 3,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 4,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 4,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 5,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 5,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 6,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 6,98
LucidWorks_spark-solr,com.lucidworks.spark,RDDProcessorTestBase,call,Magic Number,The method contains a magic number: 6,98
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testCollectionAliasSupport,Long Statement,The length of the statement "assertTrue("expected " + expectedNumDocs + " docs in query results from alias "+ aliasName+ "` but got "+ numFound`numFound == expectedNumDocs);" is 144.,26
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testCollectionAliasSupport,Magic Number,The method contains a magic number: 6,26
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testQueryShards,Magic Number,The method contains a magic number: 2000,55
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testQueryShards,Magic Number,The method contains a magic number: 3,55
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testQueryShards,Magic Number,The method contains a magic number: 57,55
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testSolrQuery,Long Statement,The length of the statement "String[] inputDocs=new String[]{testCollection + "-1`foo`bar`1`[a;b]`[1;2]"`testCollection + "-2`foo`baz`2`[c;d]`[3;4]"`testCollection + "-3`bar`baz`3`[e;f]`[5;6]"};" is 165.,96
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testSolrQuery,Magic Number,The method contains a magic number: 2,96
LucidWorks_spark-solr,com.lucidworks.spark,SolrRDDTest,testSolrQuery,Magic Number,The method contains a magic number: 2,96
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,HdfsToSolrRDDProcessor,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder("hdfsPath").argName("PATH").hasArg().required(false).desc("HDFS path identifying the directories / files to index").build()`Option.builder("queueSize").argName("INT").hasArg().required(false).desc("Queue size for ConcurrentUpdateSolrClient; default is 1000").build()`Option.builder("numRunners").argName("INT").hasArg().required(false).desc("Number of runner threads per ConcurrentUpdateSolrClient instance; default is 2").build()`Option.builder("pollQueueTime").argName("INT").hasArg().required(false).desc("Number of millis to wait until CUSS sees a doc on the queue before it closes the current request and starts another; default is 20 ms").build()};" is 689.,26
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,HdfsToSolrRDDProcessor,run,Magic Number,The method contains a magic number: 100,60
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder("hdfsPath").argName("PATH").hasArg().required(false).desc("HDFS path identifying the directories / files to index").build()};" is 160.,33
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,run,Complex Method,Cyclomatic complexity of the method is 9,44
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,run,Empty catch clause,The method has an empty catch block.,44
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,run,Long Statement,The length of the statement "if (batch.size() >= batchSize) SolrSupport.sendBatchToSolr(solrServer`collection`JavaConverters.collectionAsScalaIterable(batch));" is 130.,44
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,run,Long Statement,The length of the statement "if (!batch.isEmpty()) SolrSupport.sendBatchToSolr(solrServer`collection`JavaConverters.collectionAsScalaIterable(batch));" is 121.,44
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,run,Magic Number,The method contains a magic number: 10000,44
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,call,Empty catch clause,The method has an empty catch block.,51
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,call,Long Statement,The length of the statement "if (batch.size() >= batchSize) SolrSupport.sendBatchToSolr(solrServer`collection`JavaConverters.collectionAsScalaIterable(batch));" is 130.,51
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,call,Long Statement,The length of the statement "if (!batch.isEmpty()) SolrSupport.sendBatchToSolr(solrServer`collection`JavaConverters.collectionAsScalaIterable(batch));" is 121.,51
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessor,call,Magic Number,The method contains a magic number: 10000,51
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,HdfsToSolrRDDProcessorTest,testRDDProcessor,Long Statement,The length of the statement "String[] args=new String[]{"hdfs-to-solr"`"-zkHost"`"localhost:9983"`"-collection"`"gettingstarted"`"-hdfsPath"`"hdfs://localhost:9000/user/timpotter/perf"`"-master"`"local[2]"`"-v"};" is 183.,11
LucidWorks_spark-solr,com.lucidworks.spark.example.hadoop,Logs2SolrRDDProcessorTest,testRDDProcessor,Long Statement,The length of the statement "String[] args=new String[]{"logs2solr"`"-zkHost"`"localhost:9983"`"-collection"`"gettingstarted"`"-hdfsPath"`"hdfs://localhost:9000/user/timpotter/gc_logs"`"-master"`"local[2]"`"-v"};" is 183.,11
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,TwitterToSolrStreamProcessor,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder("tweetFilters").argName("LIST").hasArg().required(false).desc("List of Twitter keywords to filter on` separated by commas").build()`Option.builder("fusion").argName("URL(s)").hasArg().required(false).desc("Fusion endpoint").build()`Option.builder("fusionCredentials").argName("user:password:realm").hasArg().required(false).desc("Fusion credentials user:password:realm").build()};" is 415.,77
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,DocumentFilteringStreamProcessor,setup,Long Statement,The length of the statement "DStream<SolrInputDocument> enriched=SolrSupport.filterDocuments(docFilterContext`zkHost`filterCollection`docs.dstream());" is 121.,71
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,DocumentFilteringStreamProcessor,loadDocFilterContext,Long Statement,The length of the statement "Class<DocFilterContext> implClass=(Class<DocFilterContext>)getClass().getClassLoader().loadClass(docFilterContextImplClass);" is 124.,104
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,DocumentFilteringStreamProcessor,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder("tweetFilters").argName("LIST").hasArg().required(false).desc("List of Twitter keywords to filter on` separated by commas").build()`Option.builder("filterCollection").argName("NAME").hasArg().required(false).desc("Collection to pull configuration files to create an " + "EmbeddedSolrServer for document matching; defaults to the value of the collection option.").build()`Option.builder("docFilterContextImplClass").argName("CLASS").hasArg().required(false).desc("Name of the DocFilterContext implementation class; defaults to an internal example impl: " + ExampleDocFilterContextImpl.class.getName()).build()};" is 645.,120
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,DocumentFilteringStreamProcessorTest,testIndexing,Long Statement,The length of the statement "String[] args=new String[]{"docfilter"`"-zkHost"`"localhost:9983"`"-collection"`"gettingstarted"`"-master"`"local[2]"`"-v"};" is 124.,11
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,BasicIndexingTest,testIndexing,Magic Number,The method contains a magic number: 2,28
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,BasicIndexingTest,testIndexing,Magic Number,The method contains a magic number: 2000,28
LucidWorks_spark-solr,com.lucidworks.spark.example.streaming,BasicIndexingTest,call,Magic Number,The method contains a magic number: 2,54
LucidWorks_spark-solr,com.lucidworks.spark.example.query,ReadTermVectors,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder("query").argName("QUERY").hasArg().required(false).desc("URL encoded Solr query to send to Solr; default is *:*").build()`Option.builder("field").argName("FIELD").hasArg().required(true).desc("Field to generate term vectors from").build()`Option.builder("numFeatures").argName("NUM").hasArg().required(false).desc("Number of features; defaults to 500").build()`Option.builder("numIterations").argName("NUM").hasArg().required(false).desc("Number of iterations for K-Means clustering; defaults to 20").build()`Option.builder("numClusters").argName("NUM").hasArg().required(false).desc("Number of clusters (k) for K-Means clustering; defaults to 5").build()};" is 692.,23
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder("query").argName("QUERY").hasArg().required(false).desc("URL encoded Solr query to send to Solr").build()`Option.builder("aggregationSQL").argName("SQL").hasArg().required(false).desc("File containing a SQL query to execute to generate the aggregated data.").build()};" is 303.,42
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Long Statement,The length of the statement "String getLogsQuery="+clientip_s:[* TO *] +timestamp_tdt:[* TO *] +bytes_s:[* TO *] +verb_s:[* TO *] +response_s:[* TO *]";" is 123.,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Long Statement,The length of the statement "options.put(ConfigurationConstants.SOLR_FIELD_PARAM()`"id`_version_`" + UID_FIELD + "`"+ TS_FIELD+ "`bytes_s`response_s`verb_s");" is 129.,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Long Statement,The length of the statement "PivotField[] pivotFields=new PivotField[]{new PivotField("verb_s"`"http_method_")`new PivotField("response_s"`"http_code_")};" is 125.,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Long Statement,The length of the statement "String lagSql="SELECT *` sum(IF(diff_ms > " + maxGapMs + "` 1` 0)) OVER "+ lagWindowSpec+ " session_id FROM (SELECT *` ts2ms("+ TS_FIELD+ ") - lag(ts2ms("+ TS_FIELD+ ")) OVER "+ lagWindowSpec+ " as diff_ms FROM logs) tmp";" is 222.,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Long Statement,The length of the statement "Dataset sessionsAgg=sparkSession.sql("SELECT concat_ws('||'` clientip_s`session_id) as id` " + " first(clientip_s) as clientip_s` " + " min(timestamp_tdt) as session_start_tdt` "+ " max(timestamp_tdt) as session_end_tdt` "+ " (ts2ms(max(timestamp_tdt)) - ts2ms(min(timestamp_tdt))) as session_len_ms_l` "+ " sum(asInt(bytes_s)) as total_bytes_l` "+ " count(*) as total_requests_l` "+ " sum(http_method_get) as num_get_l` "+ " sum(http_method_head) as num_head_l` "+ " sum(http_method_post) as num_post_l"+ " FROM sessions "+ "GROUP BY clientip_s`session_id");" is 559.,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Magic Number,The method contains a magic number: 30,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Magic Number,The method contains a magic number: 1000,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Magic Number,The method contains a magic number: 8,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,KMeansAnomaly,run,Magic Number,The method contains a magic number: 20,59
LucidWorks_spark-solr,com.lucidworks.spark.example.query,ReadTermVectorsTest,testQueryProcessor,Long Statement,The length of the statement "String[] args=new String[]{"term-vectors"`"-zkHost"`"localhost:9983"`"-collection"`"gettingstarted"`"-query"`"*:*"`"-field"`"name"`"-master"`"local[2]"`"-v"};" is 158.,11
LucidWorks_spark-solr,com.lucidworks.spark.example.query,WordCountTest,testQueryProcessor,Long Statement,The length of the statement "String[] args=new String[]{"com.lucidworks.spark.example.query.WordCount"`"-zkHost"`"localhost:9983"`"-collection"`"gettingstarted"`"-query"`"*:*"`"-master"`"local[2]"};" is 169.,11
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,getOptions,Long Statement,The length of the statement "return new Option[]{Option.builder().hasArg().required(false).desc("Query to identify documents in the training set").longOpt("query").build()`Option.builder().hasArg().required(false).desc("Field in Solr containing the label for each document in the training set").longOpt("labelField").build()`Option.builder().hasArg().required(false).desc("Comma-separated list of field(s) in Solr containing the text content for each document in the training set").longOpt("contentFields").build()`Option.builder().hasArg().required(false).desc("Classifier type: either NaiveBayes or LogisticRegression").longOpt("classifier").build()`Option.builder().hasArg().required(false).desc("Fraction (0 to 1) of full dataset to sample from Solr` default is 1").longOpt("sample").build()};" is 768.,39
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "String whitespaceTokSchema=json("{ 'analyzers': [{ 'name': 'ws_tok'` 'tokenizer': { 'type': 'whitespace' }}]`\n" + "'fields': [{ 'regex': '.+'` 'analyzer': 'ws_tok' }]}\n");" is 173.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "String stdTokLowerSchema=json("{ 'analyzers': [{ 'name': 'std_tok_lower'` 'tokenizer': { 'type': 'standard' }`\n" + " 'filters': [{ 'type': 'lowercase' }]}]`\n" + " 'fields': [{ 'regex': '.+'` 'analyzer': 'std_tok_lower' }]}\n");" is 229.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setInputCols(inputCols).setOutputCol("words");" is 121.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "IndexToString labelConverter=new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(labelIndexer.labels());" is 139.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "Pipeline pipeline=new Pipeline().setStages(new PipelineStage[]{labelIndexer`analyzer`hashingTF`estimatorStage`labelConverter});" is 127.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "MulticlassClassificationEvaluator evaluator=new MulticlassClassificationEvaluator().setLabelCol("label").setPredictionCol("prediction").setMetricName("precision");" is 163.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "ParamGridBuilder paramGridBuilder=new ParamGridBuilder().addGrid(hashingTF.numFeatures()`new int[]{1000`5000}).addGrid(analyzer.analysisSchema()`JavaConverters$.MODULE$.collectionAsScalaIterable(analysisSchemas)).addGrid(analyzer.prefixTokensWithInputCol());" is 258.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Long Statement,The length of the statement "CrossValidator cv=new CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(3);" is 134.,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Magic Number,The method contains a magic number: 10,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Magic Number,The method contains a magic number: 3,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Magic Number,The method contains a magic number: 0.1,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,MLPipeline,run,Magic Number,The method contains a magic number: 2,75
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,UseML,run,Magic Number,The method contains a magic number: 0.1d,30
LucidWorks_spark-solr,com.lucidworks.spark.example.ml,UseML,run,Magic Number,The method contains a magic number: 5150,30
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Long Parameter List,The method has 6 parameters. ,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Long Statement,The length of the statement "throw new IllegalArgumentException("Expected 'trustedRealmGroups' array to contain 2 elements: group header name and group header value! Found " + Arrays.asList(trustedRealmGroups) + " instead!");" is 196.,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Long Statement,The length of the statement "globalConfig=RequestConfig.custom().setCookieSpec(CookieSpecs.STANDARD).setConnectTimeout(30 * 1000).setSocketTimeout(90 * 1000).build();" is 137.,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 1000,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 1000,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 2,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 30,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 1000,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 90,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,FusionPipelineClient,Magic Number,The method contains a magic number: 1000,134
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSessions,Long Statement,The length of the statement "log.info("Established sessions with " + map.size() + " of "+ hostAndPortList.size()+ " Fusion hosts for user "+ user+ " in realm "+ realm);" is 139.,216
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Complex Conditional,The conditional expression !isKerberos && trustedRealmHeader == null && realm != null is complex.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Complex Conditional,The conditional expression statusCode != 200 && statusCode != 201 && statusCode != 204 is complex.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Complex Conditional,The conditional expression statusCode != 200 && statusCode != 201 && statusCode != 204 is complex.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Complex Method,Cyclomatic complexity of the method is 8,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Long Statement,The length of the statement "throw new SolrException(SolrException.ErrorCode.getErrorCode(statusCode)`"POST credentials to Fusion Session API [" + sessionApi + "] failed due to: "+ response.getStatusLine()+ ": "+ body);" is 190.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Long Statement,The length of the statement "log.warn("Received session-idle-timeout error from Fusion Session API` re-trying to establish a new session to " + sessionKey);" is 127.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Long Statement,The length of the statement "throw new SolrException(SolrException.ErrorCode.getErrorCode(statusCode)`"POST credentials to Fusion Session API [" + sessionApi + "] failed due to: "+ response.getStatusLine()+ ": "+ body);" is 190.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Long Statement,The length of the statement "log.info("Established secure session with Fusion Session API on " + sessionKey + " for user "+ user+ " in realm "+ realm);" is 122.,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 200,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 201,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 204,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 401,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 200,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 201,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,establishSession,Magic Number,The method contains a magic number: 204,248
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,clearCookieForHost,Complex Conditional,The conditional expression sessionHost.equals(cookieDomain) || sessionHost.contains(cookieDomain) || cookieDomain.contains(sessionHost) is complex.,323
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,getSession,Long Statement,The length of the statement "log.debug("Fusion session is likely expired (or soon will be) for " + url + "` "+ "pre-emptively re-setting this session before processing request "+ requestId);" is 161.,356
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,getSession,Long Statement,The length of the statement "if (fusionSession == null) throw new IllegalStateException("Failed to re-connect to " + url + " after session loss when processing request "+ requestId);" is 153.,356
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,checkCommunicationError,Long Statement,The length of the statement "return (rootCause instanceof ConnectException || rootCause instanceof ConnectTimeoutException || rootCause instanceof NoHttpResponseException|| rootCause instanceof SocketException);" is 182.,400
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,getAvailableServers,Long Statement,The length of the statement "if (mutable.isEmpty()) throw new IllegalStateException("No available endpoints! " + "Check log for previous errors as to why there are no more endpoints available. This is a fatal error.");" is 189.,428
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,getAvailableServers,Magic Number,The method contains a magic number: 2000,428
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postBatchToPipeline,Complex Method,Cyclomatic complexity of the method is 11,458
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postBatchToPipeline,Long Statement,The length of the statement "throw new RuntimeException("No Fusion hosts available to process request " + requestId + "! Check logs for previous errors.");" is 126.,458
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postBatchToPipeline,Long Statement,The length of the statement "if (log.isDebugEnabled()) log.debug("POSTing batch of " + numDocs + " input docs to "+ hostAndPort+ pipelinePath+ " as request "+ requestId);" is 141.,458
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postBatchToPipeline,Long Statement,The length of the statement "Exception retryAfterException=postJsonToPipelineWithRetry(hostAndPort`pipelinePath`docs`mutable`lastExc`requestId`contentType);" is 127.,458
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postBatchToPipeline,Long Statement,The length of the statement "if (log.isDebugEnabled()) log.debug("POSTing batch of " + numDocs + " input docs to "+ hostAndPort+ pipelinePath+ " as request "+ requestId);" is 141.,458
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipelineWithRetry,Long Parameter List,The method has 7 parameters. ,513
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipelineWithRetry,Long Statement,The length of the statement "if (lastExc != null) log.info("Re-try request " + requestId + " to "+ url+ " succeeded after seeing a "+ lastExc.getMessage());" is 127.,513
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipelineWithRetry,Long Statement,The length of the statement "log.warn("No more Fusion servers available to try ... will retry to send request " + requestId + " to "+ url+ " after waiting 1 sec");" is 134.,513
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipelineWithRetry,Magic Number,The method contains a magic number: 1000,513
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Complex Method,Cyclomatic complexity of the method is 14,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Empty catch clause,The method has an empty catch block.,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Empty catch clause,The method has an empty catch block.,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Long Parameter List,The method has 5 parameters. ,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Long Statement,The length of the statement "log.warn("Unauthorized error (401) when trying to send request " + requestId + " to Fusion at "+ hostAndPort+ "` will re-try to establish session");" is 148.,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Long Statement,The length of the statement "if (fusionSession == null) throw new IllegalStateException("After re-establishing session when processing request " + requestId + "` hostAndPort "+ hostAndPort+ " is no longer active! Try another hostAndPort.");" is 211.,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Magic Number,The method contains a magic number: 401,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Magic Number,The method contains a magic number: 200,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Magic Number,The method contains a magic number: 204,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Magic Number,The method contains a magic number: 200,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,postJsonToPipeline,Magic Number,The method contains a magic number: 204,573
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,queryFusion,Complex Method,Cyclomatic complexity of the method is 9,759
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Complex Method,Cyclomatic complexity of the method is 14,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Empty catch clause,The method has an empty catch block.,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Long Statement,The length of the statement "log.warn("Unauthorized error (401) when trying to send request " + requestId + " to Fusion at "+ endpoint+ "` will re-try to establish session");" is 145.,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Long Statement,The length of the statement "if (fusionSession == null) throw new IllegalStateException("After re-establishing session when processing request " + requestId + "` Fusion host "+ sessionKey+ " is no longer active! Try another server.");" is 205.,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 200,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 204,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 401,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 200,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 204,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 200,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,sendRequestToFusion,Magic Number,The method contains a magic number: 204,816
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,raiseFusionServerException,Empty catch clause,The method has an empty catch block.,906
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,raiseFusionServerException,Long Parameter List,The method has 5 parameters. ,906
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,raiseFusionServerException,Long Statement,The length of the statement "throw new SolrException(SolrException.ErrorCode.getErrorCode(statusCode)`"Request " + requestId + " to ["+ endpoint+ "] failed due to: ("+ statusCode+ ")"+ statusLine+ ": "+ body);" is 180.,906
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClient,extractResponseBodyText,Empty catch clause,The method has an empty catch block.,925
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Identifier,The length of the identifier fusionPipelineUrlWithoutHostAndPort is 35.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Identifier,The length of the identifier fusionSolrProxyWithoutHostAndPort is 33.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Identifier,The length of the field fusionIndexingPipelineUrlExtension is 34.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Identifier,The length of the field fusionCollectionApiStrValForUrl is 31.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Identifier,The length of the field defaultFusionIndexingPipelineUrlTerminatingString is 49.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Statement,The length of the statement "String fusionPipelineUrlWithoutHostAndPort=fusionProxyBaseUrl + fusionIndexingPipelineUrlExtension + fusionIndexingPipeline+ fusionCollectionApiStrValForUrl+ fusionCollectionForUrl+ defaultFusionIndexingPipelineUrlTerminatingString;" is 232.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Statement,The length of the statement "log.info("testHappyPath running with: fusionSolrProxyWithoutHostAndPort=" + fusionSolrProxyWithoutHostAndPort + " fusionPipelineUrlWithoutHostAndPort="+ fusionPipelineUrlWithoutHostAndPort+ " wireMockRulePort="+ wireMockRulePort+ " useWireMockRule="+ useWireMockRule);" is 268.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Statement,The length of the statement "stubFor(get(urlEqualTo(fusionProxyBaseUrl + fusionIndexingPipelineUrlExtension)).willReturn(aResponse().withStatus(200).withBody("hello")));" is 140.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Long Statement,The length of the statement "String fusionEndpoints=useWireMockRule ? fusionUrl + "`http://localhost:" + wireMockRulePort+ "/not_and_endpoint/api"+ "`http://localhost:"+ wireMockRulePort+ badPath+ "`http://localhost:"+ wireMockRulePort+ unauthPath : fusionUrl;" is 231.,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 200,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 200,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 500,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 401,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 200,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 3,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 10,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 30,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 30,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,testHappyPath,Magic Number,The method contains a magic number: 6000,119
LucidWorks_spark-solr,com.lucidworks.spark.fusion,FusionPipelineClientTest,call,Magic Number,The method contains a magic number: 10,169
LucidWorks_spark-solr,com.lucidworks.spark.util,SQLQuerySupport,getsqlDataType,Complex Method,Cyclomatic complexity of the method is 13,10
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,visitArray,Missing default,The following switch statement is missing a default case: !org.eclipse.jdt.core.dom.SwitchStatement@3bead9b5,195
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getPrimitiveFieldSize,Magic Number,The method contains a magic number: 2,312
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getPrimitiveFieldSize,Magic Number,The method contains a magic number: 4,312
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getPrimitiveFieldSize,Magic Number,The method contains a magic number: 8,312
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Complex Conditional,The conditional expression vmName == null || !(vmName.startsWith("Java HotSpot(TM) ") || vmName.startsWith("OpenJDK") || vmName.startsWith("TwitterJDK")) is complex.,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Long Statement,The length of the statement "if (vmName == null || !(vmName.startsWith("Java HotSpot(TM) ") || vmName.startsWith("OpenJDK") || vmName.startsWith("TwitterJDK"))) {" is 133.,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Long Statement,The length of the statement "throw new UnsupportedOperationException("Unrecognized value '" + dataModel + "' of sun.arch.data.model system property");" is 121.,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 12,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 8,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 8,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 4,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 4,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 17,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 30L,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 1024,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 1024,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 1024,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 16,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 12,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 8,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 4,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 4,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 24,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 16,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 8,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 8,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getEffectiveMemoryLayoutSpecification,Magic Number,The method contains a magic number: 8,329
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getArrayHeaderSize,Magic Number,The method contains a magic number: 12,342
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getObjectHeaderSize,Magic Number,The method contains a magic number: 8,345
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getObjectPadding,Magic Number,The method contains a magic number: 8,348
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getReferenceSize,Magic Number,The method contains a magic number: 4,351
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getSuperclassFieldPadding,Magic Number,The method contains a magic number: 4,354
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getArrayHeaderSize,Magic Number,The method contains a magic number: 16,375
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getObjectHeaderSize,Magic Number,The method contains a magic number: 12,378
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getObjectPadding,Magic Number,The method contains a magic number: 8,381
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getReferenceSize,Magic Number,The method contains a magic number: 4,384
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getSuperclassFieldPadding,Magic Number,The method contains a magic number: 4,387
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getArrayHeaderSize,Magic Number,The method contains a magic number: 24,396
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getObjectHeaderSize,Magic Number,The method contains a magic number: 16,399
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getObjectPadding,Magic Number,The method contains a magic number: 8,402
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getReferenceSize,Magic Number,The method contains a magic number: 8,405
LucidWorks_spark-solr,com.lucidworks.spark.util,ObjectSizeCalculator,getSuperclassFieldPadding,Magic Number,The method contains a magic number: 8,408
LucidWorks_spark-solr,com.lucidworks.spark.util,EmbeddedSolrServerFactory,bootstrapEmbeddedSolrServer,Long Statement,The length of the statement "if (!zkStateReader.getClusterState().hasCollection(collection)) throw new IllegalStateException("Collection '" + collection + "' not found!");" is 142.,54
LucidWorks_spark-solr,com.lucidworks.spark.util,EmbeddedSolrServerFactory,writeClasspathResourceToLocalFile,Magic Number,The method contains a magic number: 1024,116
LucidWorks_spark-solr,com.lucidworks.spark.util,ScalaUtil,getFieldTypeMapping,Long Statement,The length of the statement "return (f.dataType().typeName() + ":" + (getFieldTypeMapping((ArrayType)(((ArrayType)f.dataType()).elementType())`fieldName)));" is 127.,78
LucidWorks_spark-solr,com.lucidworks.spark.util,ScalaUtil,convertToMatrix,Long Statement,The length of the statement "String[] items=dataArray.replaceFirst("\\["`"").substring(0`dataArray.replaceFirst("\\["`"").lastIndexOf("]")).split("`");" is 122.,168
LucidWorks_spark-solr,com.lucidworks.spark.util,ScalaUtil,convertToMatrix,Magic Number,The method contains a magic number: 2,168
LucidWorks_spark-solr,com.lucidworks.spark.util,ScalaUtil,getArrayFromString,Complex Method,Cyclomatic complexity of the method is 9,179
LucidWorks_spark-solr,com.lucidworks.spark.util,EventsimUtil,loadEventSimDataSet,Long Statement,The length of the statement "Dataset newDF=sparkSession.sql("SELECT userAgent` userId` artist` auth` firstName` gender` itemInSession` lastName` " + "length` level` location` method` page` sessionId` song` " + "ts2iso(registration) AS registration` ts2iso(ts) AS ts` status from jdbcDF");" is 259.,25
LucidWorks_spark-solr,com.lucidworks.spark.util,EventsimUtil,loadEventSimDataSet,Long Statement,The length of the statement "throw new Exception("All eventsim documents did not get indexed. Expected '1000'. Actual docs in Solr '" + docsInSolr + "'");" is 125.,25
LucidWorks_spark-solr,com.lucidworks.spark.util,EventsimUtil,loadEventSimDataSet,Magic Number,The method contains a magic number: 1000,25
LucidWorks_spark-solr,com.lucidworks.spark.util,EventsimUtil,defineTextFields,Long Statement,The length of the statement "SchemaRequest.MultiUpdate addFieldsMultiUpdate=new SchemaRequest.MultiUpdate(Collections.singletonList(addField)`solrParams);" is 125.,64
LucidWorks_spark-solr,com.lucidworks.spark.util,EventsimUtil,defineTextFields,Long Statement,The length of the statement "throw new SolrException(SolrException.ErrorCode.getErrorCode(response.getStatus())`"Error indexing fields to the Schema");" is 122.,64
LucidWorks_spark-solr,com.lucidworks.spark.util,EventsimUtil,defineTextFields,Magic Number,The method contains a magic number: 400,64
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,hasNext,Complex Conditional,The conditional expression totalDocs == 0 || (totalDocs != -1 && numDocs >= totalDocs) || (maxSampleDocs != null && maxSampleDocs >= 0 && numDocs >= maxSampleDocs) is complex.,72
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,hasNext,Long Statement,The length of the statement "if (totalDocs == 0 || (totalDocs != -1 && numDocs >= totalDocs) || (maxSampleDocs != null && maxSampleDocs >= 0 && numDocs >= maxSampleDocs)) return false;" is 155.,72
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,hasNext,Long Statement,The length of the statement "log.error("Fetch next page ({}) from Solr {} using query [{}]` cursorMarks? {}` " + "cursorMarkOfCurrentPage={} failed due to: {}"`iterPos`solrId`solrQuery`usingCursors`cursorMarkOfCurrentPage`e);" is 196.,72
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,fetchNextPage,Long Statement,The length of the statement "Option<QueryResponse> resp=SolrQuerySupport.querySolr(solrServer`solrQuery`start`cursorMarkOfCurrentPage`responseCallback);" is 123.,102
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,next,Long Statement,The length of the statement "if (iterPos >= currentPageSize) throw new NoSuchElementException("No more docs available from " + solrId + "! Please call hasNext before calling next!");" is 153.,132
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,next,Long Statement,The length of the statement "throw new RuntimeException("No SolrDocument in queue (waited 60 seconds) while processing cursorMark=" + cursorMarkOfCurrentPage + "` read "+ numDocs+ " of "+ totalDocs+ " so far from "+ solrId+ ". Most likely this means your query's sort criteria is not generating stable results for computing deep-paging cursors` has the index changed? "+ "If so` try using a filter criteria the bounds the results to non-changing data.");" is 425.,132
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIterator,next,Magic Number,The method contains a magic number: 60,132
LucidWorks_spark-solr,com.lucidworks.spark.query,SolrStreamIterator,SolrStreamIterator,Long Parameter List,The method has 6 parameters. ,36
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Empty catch clause,The method has an empty catch block.,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 5150,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 100,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 50,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 10,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 10L,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 10,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 5,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 2000,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 500,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 10,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,testCursorsWithUnstableIdSort,Magic Number,The method contains a magic number: 5L,25
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,run,Magic Number,The method contains a magic number: 50,43
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,run,Magic Number,The method contains a magic number: 10,43
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,run,Magic Number,The method contains a magic number: 10L,43
LucidWorks_spark-solr,com.lucidworks.spark.query,StreamingResultsIteratorTest,run,Magic Number,The method contains a magic number: 10,43
LucidWorks_spark-solr,com.lucidworks.spark.query.sql,SolrSQLSupport,parseColumns,Complex Method,Cyclomatic complexity of the method is 8,17
LucidWorks_spark-solr,com.lucidworks.spark.query.sql,SolrSQLSupport,parseColumns,Long Statement,The length of the statement "if (!lc.startsWith(SELECT)) throw new IllegalArgumentException("Expected SQL to start with '" + SELECT + "' but found ["+ sqlStmt+ "] instead!");" is 145.,17
LucidWorks_spark-solr,com.lucidworks.spark.query.sql,SolrSQLSupportTest,testSQLParse,Long Statement,The length of the statement "String sqlStmt="SELECT DISTINCT movie_id` COUNT(*) as agg_count` avg(rating) as avg_rating` sum(rating) as sum_rating` min(rating) as min_rating` max(rating) as max_rating " + "FROM ratings GROUP BY movie_id ORDER BY movie_id asc";" is 231.,12
LucidWorks_spark-solr,com.lucidworks.spark.query.sql,SolrSQLSupportTest,testSQLParse,Magic Number,The method contains a magic number: 6,12
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testStandardTokenizer,Long Statement,The length of the statement "String stdTokMax10Schema=json("{'analyzers': [{'name': 'StdTok_max10'`\n" + " 'tokenizer': {'type': 'standard'` 'maxTokenLength': '10'}\n}]`\n" + "'fields': [{'regex': '.+'` 'analyzer': 'StdTok_max10'}] }\n");" is 209.,36
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testStandardTokenizer,Long Statement,The length of the statement "String stdTokMax3Schema=json("{'defaultLuceneMatchVersion': '7.0.0'`\n" + " 'analyzers': [{'name': 'StdTok_max3'`\n" + " 'tokenizer': {'type': 'standard'` 'maxTokenLength': '3'} }]`\n"+ "'fields': [{'regex': '.+'` 'analyzer': 'StdTok_max3'}] }\n");" is 248.,36
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testCharFilters,Long Statement,The length of the statement "String schema1=json("{\n" + "'analyzers': [{\n" + " 'name': 'strip_alpha_std_tok'`\n"+ " 'charFilters': [{\n"+ " 'type': 'patternreplace'`\n"+ " 'pattern': '[A-Za-z]+'`\n"+ " 'replacement': ''\n"+ " }]`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'strip_alpha_std_tok'\n"+ "}]}\n");" is 358.,65
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testCharFilters,Long Statement,The length of the statement "String schema2=json("{\n" + "'analyzers': [{\n" + " 'name': 'htmlstrip_drop_removeme_std_tok'`\n"+ " 'charFilters': [{\n"+ " 'type': 'htmlstrip'\n"+ " }` {\n"+ " 'type': 'patternreplace'`\n"+ " 'pattern': 'removeme'`\n"+ " 'replacement': ''\n"+ " }]`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'name': 'rawText'`\n"+ " 'analyzer': 'htmlstrip_drop_removeme_std_tok'\n"+ "}]}\n");" is 422.,65
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testCharFilters,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`"rawText"`"<html><body>remove<b>me</b> but leave<div>the&nbsp;rest.</div></body></html>"`Arrays.asList("but"`"leave"`"the"`"rest"));" is 163.,65
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testTokenFilters,Long Statement,The length of the statement "String schema=json("{\n" + "'analyzers': [{\n" + " 'name': 'std_tok_possessive_stop_lower'`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'\n"+ " }`\n"+ " 'filters': [{\n"+ " 'type': 'englishpossessive'\n"+ " }` {\n"+ " 'type': 'stop'`\n"+ " 'ignoreCase': 'true'`\n"+ " 'format': 'snowball'`\n"+ " 'words': 'org/apache/lucene/analysis/snowball/english_stop.txt'\n"+ " }` {\n"+ " 'type': 'lowercase'\n"+ " }]\n"+ "}]`\n"+ "'fields': [{\n"+ " 'name': 'rawText'`\n"+ " 'analyzer': 'std_tok_possessive_stop_lower'\n"+ "}]}\n");" is 521.,113
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testUAX29URLEmailTokenizer,Long Statement,The length of the statement "String schema=json("{\n" + "'analyzers': [{\n" + " 'name': 'uax29urlemail_2000'`\n"+ " 'tokenizer': {\n"+ " 'type': 'uax29urlemail'`\n"+ " 'maxTokenLength': '2000'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'uax29urlemail_2000'\n"+ "}]}\n");" is 272.,141
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testUAX29URLEmailTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer`"Click on https://www.google.com/#q=spark+lucene"`Arrays.asList("Click"`"on"`"https://www.google.com/#q=spark+lucene"));" is 150.,141
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testUAX29URLEmailTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer`"Email caffeine@coffee.biz for tips on staying@alert"`Arrays.asList("Email"`"caffeine@coffee.biz"`"for"`"tips"`"on"`"staying"`"alert"));" is 166.,141
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testPrebuiltAnalyzer,Long Statement,The length of the statement "String schema=json("{\n" + "'fields': [{\n" + " 'regex': '.+'`\n"+ " 'analyzer': 'org.apache.lucene.analysis.core.WhitespaceAnalyzer'\n"+ "}]}\n");" is 147.,162
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testMultivaluedInput,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Arrays.asList("Harold's not around."`"The dog's nose KNOWS!")`Arrays.asList("harold's"`"not"`"around"`"the"`"dog's"`"nose"`"knows"));" is 163.,175
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testMultipleFields,Long Statement,The length of the statement "String schema=json("{\n" + "'analyzers': [{\n" + " 'name': 'std_tok_lower'`\n"+ " 'tokenizer': { 'type': 'standard' }`\n"+ " 'filters':[{ 'type': 'lowercase' }]\n"+ " }` {\n"+ " 'name': 'std_tok'`\n"+ " 'tokenizer': { 'type': 'standard' }\n"+ " }` {\n"+ " 'name': 'htmlstrip_std_tok_lower'`\n"+ " 'charFilters': [{ 'type': 'htmlstrip' }]`\n"+ " 'tokenizer': { 'type': 'standard' }`\n"+ " 'filters': [{ 'type': 'lowercase' }]\n"+ "}]`\n"+ "'fields': [{\n"+ " 'name': 'rawText1'`\n"+ " 'analyzer': 'std_tok_lower'\n"+ " }` {\n"+ " 'name': 'rawText2'`\n"+ " 'analyzer': 'std_tok'\n"+ " }` {\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'htmlstrip_std_tok_lower'\n"+ "}]}\n");" is 666.,182
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testMissingValues,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Arrays.asList(null`"Harold's not around."`null`"The dog's nose KNOWS!"`"")`Arrays.asList("harold's"`"not"`"around"`"the"`"dog's"`"nose"`"knows"));" is 176.,260
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testAnalyzeReader,Long Statement,The length of the statement "String stdTokMax3Schema=json("{'defaultLuceneMatchVersion': '7.0.0'`\n" + " 'analyzers': [{'name': 'StdTok_max3'`\n" + " 'tokenizer': {'type': 'standard'` 'maxTokenLength': '3'} }]`\n"+ "'fields': [{'regex': '.+'` 'analyzer': 'StdTok_max3'}] }\n");" is 248.,280
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testAnalyzeReader,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`new StringReader("Test for tokenization.")`Arrays.asList("Tes"`"t"`"for"`"tok"`"eni"`"zat"`"ion"));" is 130.,280
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testPreAnalyzedJson,Long Statement,The length of the statement "String jsonWithStringVal=json("{'v':'1'`'str':'" + text + "'`'tokens':["+ "{'t':'test'`'s':0`'e':4`'i':1}`"+ "{'t':'for'`'s':5`'e':8`'i':1}`"+ "{'t':'tokenization'`'s':9`'e':21`'i':1}]}");" is 188.,299
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,testPreAnalyzedJson,Long Statement,The length of the statement "String jsonNoStringVal=json("{'v':'1'`'tokens':[" + "{'t':'test'`'s':0`'e':4`'i':1}`" + "{'t':'for'`'s':5`'e':8`'i':1}`"+ "{'t':'tokenization'`'s':9`'e':21`'i':1}]}");" is 167.,299
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,assertExpectedJson,Long Parameter List,The method has 5 parameters. ,359
LucidWorks_spark-solr,com.lucidworks.spark.analysis,LuceneTextAnalyzerTest,assertExpectedJson,Long Parameter List,The method has 5 parameters. ,366
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,setupJavaSparkContext,Long Statement,The length of the statement "SparkConf conf=new SparkConf().setMaster("local").setAppName("JavaLuceneAnalyzerTest").set("spark.default.parallelism"`"1");" is 124.,41
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer1=new LuceneTextAnalyzerTransformer().setInputCol("rawText").setOutputCol("tokens");" is 122.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer1`Arrays.asList(new TokenizerTestData("Test for tokenization."`new String[]{"test"`"for"`"tokenization"})`new TokenizerTestData("Te`st. punct"`new String[]{"te"`"st"`"punct"})));" is 207.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer1`Arrays.asList(new TokenizerTestData("Test for tokenization."`new String[]{"test"`"for"`"tokenization"})`new TokenizerTestData("Te`st. punct"`new String[]{"te"`"st"`"punct"})));" is 207.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "String analysisSchema1=json("{\n" + "'analyzers': [{\n" + " 'name': 'StdTok_max10'`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'`\n"+ " 'maxTokenLength': '10'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'StdTok_max10'\n"+ "}]}\n");" is 262.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer1`Arrays.asList(new TokenizerTestData("我是中国人。 １２３４ Ｔｅｓｔｓ "`new String[]{"我"`"是"`"中"`"国"`"人"`"１２３４"`"Ｔｅｓｔｓ"})`new TokenizerTestData("some-dashed-phrase"`new String[]{"some"`"dashed"`"phrase"})));" is 223.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "String analysisSchema2=json("{\n" + "'defaultLuceneMatchVersion': '7.0.0'`\n" + "'analyzers': [{\n"+ " 'name': 'StdTok_max3'`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'`\n"+ " 'maxTokenLength': '3'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'StdTok_max3'\n"+ "}]}\n");" is 302.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer2=new LuceneTextAnalyzerTransformer().setAnalysisSchema(analysisSchema2).setInputCol("rawText").setOutputCol("tokens");" is 157.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testStandardTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`Arrays.asList(new TokenizerTestData("Test for tokenization."`new String[]{"Tes"`"t"`"for"`"tok"`"eni"`"zat"`"ion"})`new TokenizerTestData("Te`st. punct"`new String[]{"Te"`"st"`"pun"`"ct"})));" is 222.,57
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testCharFilters,Long Statement,The length of the statement "String analysisSchema1=json("{\n" + "'analyzers': [{\n" + " 'name': 'strip_alpha_std_tok'`\n"+ " 'charFilters': [{\n"+ " 'type': 'patternreplace'`\n"+ " 'pattern': '[A-Za-z]+'`\n"+ " 'replacement': ''\n"+ " }]`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'strip_alpha_std_tok'\n"+ "}]}\n");" is 366.,112
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testCharFilters,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setAnalysisSchema(analysisSchema1).setInputCol("rawText").setOutputCol("tokens");" is 156.,112
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testCharFilters,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Arrays.asList(new TokenizerTestData("Test for 9983` tokenization."`new String[]{"9983"})`new TokenizerTestData("Te`st. punct"`new String[]{})));" is 174.,112
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testCharFilters,Long Statement,The length of the statement "String analysisSchema2=json("{\n" + "'analyzers': [{\n" + " 'name': 'htmlstrip_drop_removeme_std_tok'`\n"+ " 'charFilters': [{\n"+ " 'type': 'htmlstrip'\n"+ " }` {\n"+ " 'type': 'patternreplace'`\n"+ " 'pattern': 'removeme'`\n"+ " 'replacement': ''\n"+ " }]`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'name': 'rawText'`\n"+ " 'analyzer': 'htmlstrip_drop_removeme_std_tok'\n"+ "}]}\n");" is 430.,112
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testCharFilters,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Collections.singletonList(new TokenizerTestData("<html><body>remove<b>me</b> but leave<div>the&nbsp;rest.</div></body></html>"`new String[]{"but"`"leave"`"the"`"rest"})));" is 201.,112
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testTokenFilters,Long Statement,The length of the statement "String analysisSchema=json("{\n" + "'analyzers': [{\n" + " 'name': 'std_tok_possessive_stop_lower'`\n"+ " 'tokenizer': {\n"+ " 'type': 'standard'\n"+ " }`\n"+ " 'filters': [{\n"+ " 'type': 'englishpossessive'\n"+ " }` {\n"+ " 'type': 'stop'`\n"+ " 'ignoreCase': 'true'`\n"+ " 'format': 'snowball'`\n"+ " 'words': 'org/apache/lucene/analysis/snowball/english_stop.txt'\n"+ " }` {\n"+ " 'type': 'lowercase'\n"+ " }]\n"+ "}]`\n"+ "'fields': [{\n"+ " 'name': 'rawText'`\n"+ " 'analyzer': 'std_tok_possessive_stop_lower'\n"+ "}]}\n");" is 529.,165
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testTokenFilters,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setAnalysisSchema(analysisSchema).setInputCol("rawText").setOutputCol("tokens");" is 155.,165
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testTokenFilters,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Arrays.asList(new TokenizerTestData("Harold's not around."`new String[]{"harold"`"around"})`new TokenizerTestData("The dog's nose KNOWS!"`new String[]{"dog"`"nose"`"knows"})));" is 206.,165
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testUAX29URLEmailTokenizer,Long Statement,The length of the statement "String analysisSchema=json("{\n" + "'analyzers': [{\n" + " 'name': 'uax29urlemail_2000'`\n"+ " 'tokenizer': {\n"+ " 'type': 'uax29urlemail'`\n"+ " 'maxTokenLength': '2000'\n"+ " }\n"+ "}]`\n"+ "'fields': [{\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'uax29urlemail_2000'\n"+ "}]}\n");" is 280.,197
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testUAX29URLEmailTokenizer,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setAnalysisSchema(analysisSchema).setInputCol("rawText").setOutputCol("tokens");" is 155.,197
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testUAX29URLEmailTokenizer,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Arrays.asList(new TokenizerTestData("Click on https://www.google.com/#q=spark+lucene"`new String[]{"Click"`"on"`"https://www.google.com/#q=spark+lucene"})`new TokenizerTestData("Email caffeine@coffee.biz for tips on staying@alert"`new String[]{"Email"`"caffeine@coffee.biz"`"for"`"tips"`"on"`"staying"`"alert"})));" is 344.,197
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testPrebuiltAnalyzer,Long Statement,The length of the statement "String analyzerConfig=json("{\n" + "'fields': [{\n" + " 'regex': '.+'`\n"+ " 'analyzer': 'org.apache.lucene.analysis.core.WhitespaceAnalyzer'\n"+ "}]}\n");" is 155.,222
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testPrebuiltAnalyzer,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setAnalysisSchema(analyzerConfig).setInputCol("rawText").setOutputCol("tokens");" is 155.,222
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testPrebuiltAnalyzer,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Arrays.asList(new TokenizerTestData("Test for tokenization."`new String[]{"Test"`"for"`"tokenization."})`new TokenizerTestData("Te`st. punct"`new String[]{"Te`st."`"punct"})));" is 206.,222
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultivaluedInputCol,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setInputCols(new String[]{"rawText"}).setOutputCol("tokens");" is 136.,239
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultivaluedInputCol,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Collections.singletonList(new MV_TokenizerTestData(new String[]{"Harold's not around."`"The dog's nose KNOWS!"}`new String[]{"harold's"`"not"`"around"`"the"`"dog's"`"nose"`"knows"})));" is 214.,239
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer1=new LuceneTextAnalyzerTransformer().setInputCols(new String[]{"rawText1"`"rawText2"}).setOutputCol("tokens");" is 149.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "assertExpectedTokens(analyzer1`Collections.singletonList(new SV_SV_TokenizerTestData("Harold's not around."`"The dog's nose KNOWS!"`new String[]{"harold's"`"not"`"around"`"the"`"dog's"`"nose"`"knows"})));" is 204.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "String analysisSchema=json("{\n" + "'analyzers': [{\n" + " 'name': 'std_tok_lower'`\n"+ " 'tokenizer': { 'type': 'standard' }`\n"+ " 'filters':[{ 'type': 'lowercase' }]\n"+ " }` {\n"+ " 'name': 'std_tok'`\n"+ " 'tokenizer': { 'type': 'standard' }\n"+ " }` {\n"+ " 'name': 'htmlstrip_std_tok_lower'`\n"+ " 'charFilters': [{ 'type': 'htmlstrip' }]`\n"+ " 'tokenizer': { 'type': 'standard' }`\n"+ " 'filters': [{ 'type': 'lowercase' }]\n"+ "}]`\n"+ "'fields': [{\n"+ " 'name': 'rawText1'`\n"+ " 'analyzer': 'std_tok_lower'\n"+ " }` {\n"+ " 'name': 'rawText2'`\n"+ " 'analyzer': 'std_tok'\n"+ " }` {\n"+ " 'regex': '.+'`\n"+ " 'analyzer': 'htmlstrip_std_tok_lower'\n"+ "}]}\n");" is 674.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer2=new LuceneTextAnalyzerTransformer().setAnalysisSchema(analysisSchema).setInputCols(new String[]{"rawText1"`"rawText2"}).setOutputCol("tokens");" is 183.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`Collections.singletonList(new SV_SV_TokenizerTestData("Harold's NOT around."`"The dog's nose KNOWS!"`new String[]{"harold's"`"not"`"around"`"The"`"dog's"`"nose"`"KNOWS"})));" is 204.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`Collections.singletonList(new SV_MV_TokenizerTestData("Harold's NOT around."`new String[]{"The dog's nose KNOWS!"`"Good` fine` great..."}`new String[]{"harold's"`"not"`"around"`"The"`"dog's"`"nose"`"KNOWS"`"Good"`"fine"`"great"})));" is 263.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`Collections.singletonList(new MV_MV_TokenizerTestData(new String[]{"Harold's NOT around."`"Anymore` I mean."}`new String[]{"The dog's nose KNOWS!"`"Good` fine` great..."}`new String[]{"harold's"`"not"`"around"`"anymore"`"i"`"mean"`"The"`"dog's"`"nose"`"KNOWS"`"Good"`"fine"`"great"})));" is 317.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMultipleInputCols,Long Statement,The length of the statement "assertExpectedTokens(analyzer2`Collections.singletonList(new SV_SV_SV_TokenizerTestData("Harold's NOT around."`"The dog's nose KNOWS!"`"<html><body>Content</body></html>"`new String[]{"harold's"`"not"`"around"`"The"`"dog's"`"nose"`"KNOWS"`"content"})));" is 253.,249
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testPrefixTokensWithInputCol,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setInputCols(new String[]{"rawText1"`"rawText2"}).setOutputCol("tokens");" is 148.,307
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMissingValues,Long Statement,The length of the statement "LuceneTextAnalyzerTransformer analyzer=new LuceneTextAnalyzerTransformer().setInputCol("rawText").setOutputCol("tokens");" is 121.,341
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMissingValues,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Collections.singletonList(new MV_TokenizerTestData(new String[]{null`"Harold's not around."`null`"The dog's nose KNOWS!"`""}`new String[]{"harold's"`"not"`"around"`"the"`"dog's"`"nose"`"knows"})));" is 227.,341
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,testMissingValues,Long Statement,The length of the statement "assertExpectedTokens(analyzer`Collections.singletonList(new SV_SV_SV_TokenizerTestData(""`"The dog's nose KNOWS!"`null`new String[]{"the"`"dog's"`"nose"`"knows"})));" is 165.,341
LucidWorks_spark-solr,com.lucidworks.spark.ml.feature,LuceneTextAnalyzerTransformerTest,assertExpectedTokens,Long Statement,The length of the statement "List<Row> pairs=analyzer.transform(sparkSession.createDataFrame(rdd`testData.get(0).getClass())).select("wantedTokens"`"tokens").collectAsList();" is 145.,359
LucidWorks_spark-solr,com.lucidworks.spark.solr,TestEmbeddedSolrServer,testEmbeddedSolrServerUseNumDocsAsBatchSize,Magic Number,The method contains a magic number: 3,13
LucidWorks_spark-solr,com.lucidworks.spark.solr,TestEmbeddedSolrServer,testEmbeddedSolrServerUseNumDocsAsBatchSize,Magic Number,The method contains a magic number: 10,13
LucidWorks_spark-solr,com.lucidworks.spark.solr,TestEmbeddedSolrServer,testEmbeddedSolrServerUseNumBytesAsBatchSize,Magic Number,The method contains a magic number: 1000,20
LucidWorks_spark-solr,com.lucidworks.spark.solr,TestEmbeddedSolrServer,testEmbeddedSolrServerUseNumBytesAsBatchSize,Magic Number,The method contains a magic number: 100,20
LucidWorks_spark-solr,com.lucidworks.spark.solr,TestEmbeddedSolrServer,testEmbeddedSolrServerCustomConfig,Long Statement,The length of the statement "embeddedSolrServer=EmbeddedSolrServerFactory.singleton.getEmbeddedSolrServer(zkHost`testCollection`"custom-solrconfig.xml"`null);" is 129.,43
LucidWorks_spark-solr,com.lucidworks.spark.solr,TestEmbeddedSolrServer,testEmbeddedSolrServerCustomConfig,Magic Number,The method contains a magic number: 10,43
